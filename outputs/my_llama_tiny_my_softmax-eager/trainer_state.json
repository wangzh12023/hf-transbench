{
  "best_metric": 6.942963600158691,
  "best_model_checkpoint": "outputs/my_llama_tiny_my_softmax-eager/checkpoint-1400",
  "epoch": 1.0,
  "eval_steps": 200,
  "global_step": 17003,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.002940657531023937,
      "grad_norm": 2.1848273277282715,
      "learning_rate": 5.859375e-05,
      "loss": 9.8239,
      "step": 50
    },
    {
      "epoch": 0.005881315062047874,
      "grad_norm": 0.8061211705207825,
      "learning_rate": 0.0001171875,
      "loss": 7.9918,
      "step": 100
    },
    {
      "epoch": 0.008821972593071811,
      "grad_norm": 0.5323799848556519,
      "learning_rate": 0.00017578125,
      "loss": 7.1442,
      "step": 150
    },
    {
      "epoch": 0.011762630124095747,
      "grad_norm": 0.7617616057395935,
      "learning_rate": 0.000234375,
      "loss": 7.1383,
      "step": 200
    },
    {
      "epoch": 0.011762630124095747,
      "eval_accuracy": 0.04431865154874437,
      "eval_loss": 7.119934558868408,
      "eval_runtime": 4.1657,
      "eval_samples_per_second": 34.328,
      "eval_steps_per_second": 2.16,
      "step": 200
    },
    {
      "epoch": 0.014703287655119685,
      "grad_norm": 0.551177442073822,
      "learning_rate": 0.00029296875,
      "loss": 7.1091,
      "step": 250
    },
    {
      "epoch": 0.017643945186143623,
      "grad_norm": 0.6066583395004272,
      "learning_rate": 0.00029999489036526523,
      "loss": 7.1275,
      "step": 300
    },
    {
      "epoch": 0.02058460271716756,
      "grad_norm": 0.5630118250846863,
      "learning_rate": 0.00029997667984557944,
      "loss": 7.0868,
      "step": 350
    },
    {
      "epoch": 0.023525260248191494,
      "grad_norm": 0.581611692905426,
      "learning_rate": 0.00029994527502862664,
      "loss": 7.0557,
      "step": 400
    },
    {
      "epoch": 0.023525260248191494,
      "eval_accuracy": 0.045965270684371805,
      "eval_loss": 7.042042255401611,
      "eval_runtime": 3.8919,
      "eval_samples_per_second": 36.743,
      "eval_steps_per_second": 2.312,
      "step": 400
    },
    {
      "epoch": 0.026465917779215434,
      "grad_norm": 0.5390020608901978,
      "learning_rate": 0.0002999006786772662,
      "loss": 7.0658,
      "step": 450
    },
    {
      "epoch": 0.02940657531023937,
      "grad_norm": 0.5556271076202393,
      "learning_rate": 0.00029984289471489167,
      "loss": 7.0903,
      "step": 500
    },
    {
      "epoch": 0.032347232841263306,
      "grad_norm": 0.6492946743965149,
      "learning_rate": 0.0002997719282250851,
      "loss": 7.0638,
      "step": 550
    },
    {
      "epoch": 0.035287890372287245,
      "grad_norm": 0.6283262968063354,
      "learning_rate": 0.0002996877854511703,
      "loss": 7.0543,
      "step": 600
    },
    {
      "epoch": 0.035287890372287245,
      "eval_accuracy": 0.04655969335988877,
      "eval_loss": 6.996749401092529,
      "eval_runtime": 3.8924,
      "eval_samples_per_second": 36.738,
      "eval_steps_per_second": 2.312,
      "step": 600
    },
    {
      "epoch": 0.03822854790331118,
      "grad_norm": 0.6680499315261841,
      "learning_rate": 0.00029959047379566326,
      "loss": 7.0084,
      "step": 650
    },
    {
      "epoch": 0.04116920543433512,
      "grad_norm": 0.9313408732414246,
      "learning_rate": 0.000299480001819621,
      "loss": 7.0154,
      "step": 700
    },
    {
      "epoch": 0.044109862965359056,
      "grad_norm": 0.7116155028343201,
      "learning_rate": 0.00029935637924188835,
      "loss": 7.0016,
      "step": 750
    },
    {
      "epoch": 0.04705052049638299,
      "grad_norm": 0.5959978103637695,
      "learning_rate": 0.0002992196169382432,
      "loss": 6.998,
      "step": 800
    },
    {
      "epoch": 0.04705052049638299,
      "eval_accuracy": 0.04275743796994408,
      "eval_loss": 6.975284576416016,
      "eval_runtime": 3.8937,
      "eval_samples_per_second": 36.726,
      "eval_steps_per_second": 2.311,
      "step": 800
    },
    {
      "epoch": 0.04999117802740693,
      "grad_norm": 0.7788853049278259,
      "learning_rate": 0.00029906972694043933,
      "loss": 6.978,
      "step": 850
    },
    {
      "epoch": 0.05293183555843087,
      "grad_norm": 1.4969865083694458,
      "learning_rate": 0.00029890672243514804,
      "loss": 6.998,
      "step": 900
    },
    {
      "epoch": 0.0558724930894548,
      "grad_norm": 4.822102069854736,
      "learning_rate": 0.00029873061776279815,
      "loss": 6.9903,
      "step": 950
    },
    {
      "epoch": 0.05881315062047874,
      "grad_norm": 12.730936050415039,
      "learning_rate": 0.00029854142841631435,
      "loss": 6.985,
      "step": 1000
    },
    {
      "epoch": 0.05881315062047874,
      "eval_accuracy": 0.04711653759040178,
      "eval_loss": 6.952558517456055,
      "eval_runtime": 3.8539,
      "eval_samples_per_second": 37.105,
      "eval_steps_per_second": 2.335,
      "step": 1000
    },
    {
      "epoch": 0.06175380815150268,
      "grad_norm": 25.912235260009766,
      "learning_rate": 0.00029833917103975403,
      "loss": 6.9771,
      "step": 1050
    },
    {
      "epoch": 0.06469446568252661,
      "grad_norm": 8.47004222869873,
      "learning_rate": 0.0002981238634268432,
      "loss": 7.0008,
      "step": 1100
    },
    {
      "epoch": 0.06763512321355054,
      "grad_norm": 24.733718872070312,
      "learning_rate": 0.00029789552451941115,
      "loss": 6.9631,
      "step": 1150
    },
    {
      "epoch": 0.07057578074457449,
      "grad_norm": 23.953781127929688,
      "learning_rate": 0.0002976541744057236,
      "loss": 6.9781,
      "step": 1200
    },
    {
      "epoch": 0.07057578074457449,
      "eval_accuracy": 0.04643670935805767,
      "eval_loss": 6.9480085372924805,
      "eval_runtime": 3.8526,
      "eval_samples_per_second": 37.118,
      "eval_steps_per_second": 2.336,
      "step": 1200
    },
    {
      "epoch": 0.07351643827559842,
      "grad_norm": 23.24275016784668,
      "learning_rate": 0.00029739983431871606,
      "loss": 6.9795,
      "step": 1250
    },
    {
      "epoch": 0.07645709580662235,
      "grad_norm": 15.74886703491211,
      "learning_rate": 0.00029713252663412517,
      "loss": 6.9955,
      "step": 1300
    },
    {
      "epoch": 0.0793977533376463,
      "grad_norm": 28.936004638671875,
      "learning_rate": 0.00029685227486852075,
      "loss": 6.9439,
      "step": 1350
    },
    {
      "epoch": 0.08233841086867023,
      "grad_norm": 45.11975860595703,
      "learning_rate": 0.00029655910367723667,
      "loss": 6.9807,
      "step": 1400
    },
    {
      "epoch": 0.08233841086867023,
      "eval_accuracy": 0.04707212670085167,
      "eval_loss": 6.942963600158691,
      "eval_runtime": 3.8593,
      "eval_samples_per_second": 37.054,
      "eval_steps_per_second": 2.332,
      "step": 1400
    },
    {
      "epoch": 0.08527906839969417,
      "grad_norm": 52.85319137573242,
      "learning_rate": 0.0002962530388522016,
      "loss": 6.9864,
      "step": 1450
    },
    {
      "epoch": 0.08821972593071811,
      "grad_norm": 79.07356262207031,
      "learning_rate": 0.0002959341073196704,
      "loss": 6.9718,
      "step": 1500
    },
    {
      "epoch": 0.09116038346174204,
      "grad_norm": 59.342132568359375,
      "learning_rate": 0.00029560233713785475,
      "loss": 6.9736,
      "step": 1550
    },
    {
      "epoch": 0.09410104099276598,
      "grad_norm": 80.36256408691406,
      "learning_rate": 0.0002952577574944552,
      "loss": 6.9817,
      "step": 1600
    },
    {
      "epoch": 0.09410104099276598,
      "eval_accuracy": 0.04555532401160149,
      "eval_loss": 6.961811065673828,
      "eval_runtime": 3.8203,
      "eval_samples_per_second": 37.432,
      "eval_steps_per_second": 2.356,
      "step": 1600
    },
    {
      "epoch": 0.09704169852378992,
      "grad_norm": 75.62600708007812,
      "learning_rate": 0.0002949003987040929,
      "loss": 6.9835,
      "step": 1650
    },
    {
      "epoch": 0.09998235605481386,
      "grad_norm": 48.2358283996582,
      "learning_rate": 0.0002945302922056431,
      "loss": 6.9652,
      "step": 1700
    },
    {
      "epoch": 0.10292301358583779,
      "grad_norm": 142.64442443847656,
      "learning_rate": 0.0002941474705594688,
      "loss": 7.0032,
      "step": 1750
    },
    {
      "epoch": 0.10586367111686174,
      "grad_norm": 481.4616394042969,
      "learning_rate": 0.0002937519674445568,
      "loss": 6.9408,
      "step": 1800
    },
    {
      "epoch": 0.10586367111686174,
      "eval_accuracy": 0.045784210903898254,
      "eval_loss": 6.954930305480957,
      "eval_runtime": 3.8213,
      "eval_samples_per_second": 37.422,
      "eval_steps_per_second": 2.355,
      "step": 1800
    },
    {
      "epoch": 0.10880432864788567,
      "grad_norm": 144.10098266601562,
      "learning_rate": 0.00029334381765555427,
      "loss": 6.9722,
      "step": 1850
    },
    {
      "epoch": 0.1117449861789096,
      "grad_norm": 249.42823791503906,
      "learning_rate": 0.00029292305709970794,
      "loss": 7.0085,
      "step": 1900
    },
    {
      "epoch": 0.11468564370993355,
      "grad_norm": 242.62803649902344,
      "learning_rate": 0.0002924897227937051,
      "loss": 6.995,
      "step": 1950
    },
    {
      "epoch": 0.11762630124095748,
      "grad_norm": 783.1405029296875,
      "learning_rate": 0.0002920438528604169,
      "loss": 7.0089,
      "step": 2000
    },
    {
      "epoch": 0.11762630124095748,
      "eval_accuracy": 0.04632739024531892,
      "eval_loss": 6.9647216796875,
      "eval_runtime": 3.8326,
      "eval_samples_per_second": 37.311,
      "eval_steps_per_second": 2.348,
      "step": 2000
    },
    {
      "epoch": 0.12056695877198141,
      "grad_norm": 864.2501831054688,
      "learning_rate": 0.0002915854865255446,
      "loss": 7.0127,
      "step": 2050
    },
    {
      "epoch": 0.12350761630300536,
      "grad_norm": 504.46600341796875,
      "learning_rate": 0.0002911146641141687,
      "loss": 6.9757,
      "step": 2100
    },
    {
      "epoch": 0.1264482738340293,
      "grad_norm": 881.03076171875,
      "learning_rate": 0.00029063142704720117,
      "loss": 6.9775,
      "step": 2150
    },
    {
      "epoch": 0.12938893136505322,
      "grad_norm": 466.909423828125,
      "learning_rate": 0.0002901358178377415,
      "loss": 6.9963,
      "step": 2200
    },
    {
      "epoch": 0.12938893136505322,
      "eval_accuracy": 0.046610936693985056,
      "eval_loss": 6.953946113586426,
      "eval_runtime": 3.8301,
      "eval_samples_per_second": 37.336,
      "eval_steps_per_second": 2.35,
      "step": 2200
    },
    {
      "epoch": 0.13232958889607715,
      "grad_norm": 576.4473876953125,
      "learning_rate": 0.00028962788008733654,
      "loss": 7.0075,
      "step": 2250
    },
    {
      "epoch": 0.1352702464271011,
      "grad_norm": 899.20751953125,
      "learning_rate": 0.0002891076584821447,
      "loss": 6.9662,
      "step": 2300
    },
    {
      "epoch": 0.13821090395812505,
      "grad_norm": 892.380859375,
      "learning_rate": 0.00028857519878900474,
      "loss": 6.987,
      "step": 2350
    },
    {
      "epoch": 0.14115156148914898,
      "grad_norm": 468.42388916015625,
      "learning_rate": 0.0002880305478514089,
      "loss": 6.9884,
      "step": 2400
    },
    {
      "epoch": 0.14115156148914898,
      "eval_accuracy": 0.0464777040253347,
      "eval_loss": 6.9505228996276855,
      "eval_runtime": 3.8706,
      "eval_samples_per_second": 36.945,
      "eval_steps_per_second": 2.325,
      "step": 2400
    },
    {
      "epoch": 0.1440922190201729,
      "grad_norm": 1915.437744140625,
      "learning_rate": 0.00028747375358538263,
      "loss": 6.9591,
      "step": 2450
    },
    {
      "epoch": 0.14703287655119684,
      "grad_norm": 2140.24169921875,
      "learning_rate": 0.0002869048649752683,
      "loss": 7.0137,
      "step": 2500
    },
    {
      "epoch": 0.14997353408222078,
      "grad_norm": 1421.2379150390625,
      "learning_rate": 0.00028632393206941655,
      "loss": 7.0053,
      "step": 2550
    },
    {
      "epoch": 0.1529141916132447,
      "grad_norm": 2778.711669921875,
      "learning_rate": 0.00028573100597578265,
      "loss": 7.0004,
      "step": 2600
    },
    {
      "epoch": 0.1529141916132447,
      "eval_accuracy": 0.045821789348902194,
      "eval_loss": 6.953977584838867,
      "eval_runtime": 3.9117,
      "eval_samples_per_second": 36.557,
      "eval_steps_per_second": 2.301,
      "step": 2600
    },
    {
      "epoch": 0.15585484914426867,
      "grad_norm": 2678.601318359375,
      "learning_rate": 0.00028512613885743046,
      "loss": 7.0188,
      "step": 2650
    },
    {
      "epoch": 0.1587955066752926,
      "grad_norm": 2162.47705078125,
      "learning_rate": 0.00028450938392794343,
      "loss": 6.979,
      "step": 2700
    },
    {
      "epoch": 0.16173616420631654,
      "grad_norm": 1661.9888916015625,
      "learning_rate": 0.00028388079544674306,
      "loss": 7.0027,
      "step": 2750
    },
    {
      "epoch": 0.16467682173734047,
      "grad_norm": 481.2806091308594,
      "learning_rate": 0.00028324042871431533,
      "loss": 6.9885,
      "step": 2800
    },
    {
      "epoch": 0.16467682173734047,
      "eval_accuracy": 0.04527519378520844,
      "eval_loss": 6.947835922241211,
      "eval_runtime": 3.9149,
      "eval_samples_per_second": 36.527,
      "eval_steps_per_second": 2.299,
      "step": 2800
    },
    {
      "epoch": 0.1676174792683644,
      "grad_norm": 1120.843017578125,
      "learning_rate": 0.00028258834006734555,
      "loss": 6.9914,
      "step": 2850
    },
    {
      "epoch": 0.17055813679938833,
      "grad_norm": 1951.0909423828125,
      "learning_rate": 0.00028192458687376234,
      "loss": 6.982,
      "step": 2900
    },
    {
      "epoch": 0.1734987943304123,
      "grad_norm": 1077.1964111328125,
      "learning_rate": 0.00028124922752769034,
      "loss": 7.0301,
      "step": 2950
    },
    {
      "epoch": 0.17643945186143623,
      "grad_norm": 709.5512084960938,
      "learning_rate": 0.0002805623214443132,
      "loss": 7.0089,
      "step": 3000
    },
    {
      "epoch": 0.17643945186143623,
      "eval_accuracy": 0.04461586288650285,
      "eval_loss": 6.962298393249512,
      "eval_runtime": 3.9227,
      "eval_samples_per_second": 36.455,
      "eval_steps_per_second": 2.294,
      "step": 3000
    },
    {
      "epoch": 0.17938010939246016,
      "grad_norm": 1216.927978515625,
      "learning_rate": 0.0002798639290546465,
      "loss": 6.9781,
      "step": 3050
    },
    {
      "epoch": 0.1823207669234841,
      "grad_norm": 4309.5146484375,
      "learning_rate": 0.00027915411180022093,
      "loss": 6.9662,
      "step": 3100
    },
    {
      "epoch": 0.18526142445450802,
      "grad_norm": 4583.63330078125,
      "learning_rate": 0.0002784329321276774,
      "loss": 6.9852,
      "step": 3150
    },
    {
      "epoch": 0.18820208198553195,
      "grad_norm": 12436.3037109375,
      "learning_rate": 0.00027770045348327293,
      "loss": 7.0022,
      "step": 3200
    },
    {
      "epoch": 0.18820208198553195,
      "eval_accuracy": 0.04515562600565043,
      "eval_loss": 6.950199604034424,
      "eval_runtime": 3.9114,
      "eval_samples_per_second": 36.56,
      "eval_steps_per_second": 2.301,
      "step": 3200
    },
    {
      "epoch": 0.19114273951655592,
      "grad_norm": 5595.0146484375,
      "learning_rate": 0.0002769567403072991,
      "loss": 6.9941,
      "step": 3250
    },
    {
      "epoch": 0.19408339704757985,
      "grad_norm": 4293.455078125,
      "learning_rate": 0.0002762018580284128,
      "loss": 6.9694,
      "step": 3300
    },
    {
      "epoch": 0.19702405457860378,
      "grad_norm": 3205.794677734375,
      "learning_rate": 0.0002754358730578801,
      "loss": 7.0025,
      "step": 3350
    },
    {
      "epoch": 0.1999647121096277,
      "grad_norm": 9189.9248046875,
      "learning_rate": 0.00027465885278373366,
      "loss": 6.9799,
      "step": 3400
    },
    {
      "epoch": 0.1999647121096277,
      "eval_accuracy": 0.04495406889153836,
      "eval_loss": 6.950388431549072,
      "eval_runtime": 3.9173,
      "eval_samples_per_second": 36.505,
      "eval_steps_per_second": 2.298,
      "step": 3400
    },
    {
      "epoch": 0.20290536964065164,
      "grad_norm": 3942.213623046875,
      "learning_rate": 0.0002738708655648442,
      "loss": 6.9754,
      "step": 3450
    },
    {
      "epoch": 0.20584602717167558,
      "grad_norm": 6628.20458984375,
      "learning_rate": 0.0002730719807249069,
      "loss": 6.9879,
      "step": 3500
    },
    {
      "epoch": 0.2087866847026995,
      "grad_norm": 7664.07275390625,
      "learning_rate": 0.00027226226854634196,
      "loss": 7.0139,
      "step": 3550
    },
    {
      "epoch": 0.21172734223372347,
      "grad_norm": 18183.841796875,
      "learning_rate": 0.00027144180026411206,
      "loss": 7.0146,
      "step": 3600
    },
    {
      "epoch": 0.21172734223372347,
      "eval_accuracy": 0.04487549577925738,
      "eval_loss": 6.951397895812988,
      "eval_runtime": 3.9237,
      "eval_samples_per_second": 36.445,
      "eval_steps_per_second": 2.294,
      "step": 3600
    },
    {
      "epoch": 0.2146679997647474,
      "grad_norm": 5170.58935546875,
      "learning_rate": 0.0002706106480594552,
      "loss": 6.9641,
      "step": 3650
    },
    {
      "epoch": 0.21760865729577133,
      "grad_norm": 10206.697265625,
      "learning_rate": 0.0002697688850535344,
      "loss": 6.9678,
      "step": 3700
    },
    {
      "epoch": 0.22054931482679527,
      "grad_norm": 22602.880859375,
      "learning_rate": 0.000268916585301005,
      "loss": 6.9864,
      "step": 3750
    },
    {
      "epoch": 0.2234899723578192,
      "grad_norm": 8716.8994140625,
      "learning_rate": 0.0002680538237834994,
      "loss": 7.0074,
      "step": 3800
    },
    {
      "epoch": 0.2234899723578192,
      "eval_accuracy": 0.04426057577010191,
      "eval_loss": 6.975872993469238,
      "eval_runtime": 3.9204,
      "eval_samples_per_second": 36.476,
      "eval_steps_per_second": 2.296,
      "step": 3800
    },
    {
      "epoch": 0.22643062988884313,
      "grad_norm": 8389.55859375,
      "learning_rate": 0.0002671806764030309,
      "loss": 6.9874,
      "step": 3850
    },
    {
      "epoch": 0.2293712874198671,
      "grad_norm": 4048.43115234375,
      "learning_rate": 0.0002662972199753159,
      "loss": 6.983,
      "step": 3900
    },
    {
      "epoch": 0.23231194495089103,
      "grad_norm": 4077.219970703125,
      "learning_rate": 0.0002654035322230158,
      "loss": 6.9916,
      "step": 3950
    },
    {
      "epoch": 0.23525260248191496,
      "grad_norm": 2356.351806640625,
      "learning_rate": 0.0002644996917688998,
      "loss": 6.9847,
      "step": 4000
    },
    {
      "epoch": 0.23525260248191496,
      "eval_accuracy": 0.04639571469078064,
      "eval_loss": 6.947784423828125,
      "eval_runtime": 3.9138,
      "eval_samples_per_second": 36.537,
      "eval_steps_per_second": 2.3,
      "step": 4000
    },
    {
      "epoch": 0.2381932600129389,
      "grad_norm": 3966.318603515625,
      "learning_rate": 0.0002635857781289275,
      "loss": 6.9891,
      "step": 4050
    },
    {
      "epoch": 0.24113391754396282,
      "grad_norm": 7104.78125,
      "learning_rate": 0.00026266187170525396,
      "loss": 7.0076,
      "step": 4100
    },
    {
      "epoch": 0.24407457507498675,
      "grad_norm": 11237.58203125,
      "learning_rate": 0.0002617280537791557,
      "loss": 7.0055,
      "step": 4150
    },
    {
      "epoch": 0.24701523260601072,
      "grad_norm": 5154.6982421875,
      "learning_rate": 0.00026078440650388027,
      "loss": 6.9841,
      "step": 4200
    },
    {
      "epoch": 0.24701523260601072,
      "eval_accuracy": 0.04677491536309319,
      "eval_loss": 6.955687046051025,
      "eval_runtime": 3.9113,
      "eval_samples_per_second": 36.561,
      "eval_steps_per_second": 2.301,
      "step": 4200
    },
    {
      "epoch": 0.24995589013703465,
      "grad_norm": 7687.77880859375,
      "learning_rate": 0.0002598310128974188,
      "loss": 6.9812,
      "step": 4250
    },
    {
      "epoch": 0.2528965476680586,
      "grad_norm": 2423.057861328125,
      "learning_rate": 0.00025886795683520214,
      "loss": 7.0142,
      "step": 4300
    },
    {
      "epoch": 0.25583720519908254,
      "grad_norm": 4345.5107421875,
      "learning_rate": 0.0002578953230427223,
      "loss": 7.0147,
      "step": 4350
    },
    {
      "epoch": 0.25877786273010644,
      "grad_norm": 4821.3515625,
      "learning_rate": 0.0002569131970880782,
      "loss": 6.9834,
      "step": 4400
    },
    {
      "epoch": 0.25877786273010644,
      "eval_accuracy": 0.04584911912708688,
      "eval_loss": 6.959104061126709,
      "eval_runtime": 3.9135,
      "eval_samples_per_second": 36.54,
      "eval_steps_per_second": 2.3,
      "step": 4400
    },
    {
      "epoch": 0.2617185202611304,
      "grad_norm": 13372.5068359375,
      "learning_rate": 0.000255921665374448,
      "loss": 7.015,
      "step": 4450
    },
    {
      "epoch": 0.2646591777921543,
      "grad_norm": 8111.7392578125,
      "learning_rate": 0.00025492081513248804,
      "loss": 6.9867,
      "step": 4500
    },
    {
      "epoch": 0.26759983532317827,
      "grad_norm": 5045.982421875,
      "learning_rate": 0.0002539107344126578,
      "loss": 6.997,
      "step": 4550
    },
    {
      "epoch": 0.2705404928542022,
      "grad_norm": 10144.6396484375,
      "learning_rate": 0.00025289151207747454,
      "loss": 7.0188,
      "step": 4600
    },
    {
      "epoch": 0.2705404928542022,
      "eval_accuracy": 0.04600968157392193,
      "eval_loss": 6.9652934074401855,
      "eval_runtime": 3.9401,
      "eval_samples_per_second": 36.294,
      "eval_steps_per_second": 2.284,
      "step": 4600
    },
    {
      "epoch": 0.27348115038522613,
      "grad_norm": 10338.728515625,
      "learning_rate": 0.00025186323779369496,
      "loss": 7.031,
      "step": 4650
    },
    {
      "epoch": 0.2764218079162501,
      "grad_norm": 24558.302734375,
      "learning_rate": 0.000250826002024427,
      "loss": 7.0082,
      "step": 4700
    },
    {
      "epoch": 0.279362465447274,
      "grad_norm": 5674.55322265625,
      "learning_rate": 0.0002497798960211711,
      "loss": 7.0209,
      "step": 4750
    },
    {
      "epoch": 0.28230312297829796,
      "grad_norm": 8084.8515625,
      "learning_rate": 0.0002487250118157925,
      "loss": 7.0121,
      "step": 4800
    },
    {
      "epoch": 0.28230312297829796,
      "eval_accuracy": 0.04530252356339313,
      "eval_loss": 6.974196910858154,
      "eval_runtime": 3.9293,
      "eval_samples_per_second": 36.393,
      "eval_steps_per_second": 2.29,
      "step": 4800
    },
    {
      "epoch": 0.28524378050932186,
      "grad_norm": 10359.3388671875,
      "learning_rate": 0.00024766144221242454,
      "loss": 7.0278,
      "step": 4850
    },
    {
      "epoch": 0.2881844380403458,
      "grad_norm": 9087.142578125,
      "learning_rate": 0.0002465892807793041,
      "loss": 7.0214,
      "step": 4900
    },
    {
      "epoch": 0.2911250955713698,
      "grad_norm": 4820.15576171875,
      "learning_rate": 0.0002455086218405399,
      "loss": 7.0038,
      "step": 4950
    },
    {
      "epoch": 0.2940657531023937,
      "grad_norm": 21165.23046875,
      "learning_rate": 0.0002444195604678145,
      "loss": 7.0395,
      "step": 5000
    },
    {
      "epoch": 0.2940657531023937,
      "eval_accuracy": 0.04473543066606086,
      "eval_loss": 6.977938652038574,
      "eval_runtime": 3.9325,
      "eval_samples_per_second": 36.364,
      "eval_steps_per_second": 2.289,
      "step": 5000
    },
    {
      "epoch": 0.29700641063341765,
      "grad_norm": 31006.3515625,
      "learning_rate": 0.00024332219247201998,
      "loss": 7.0444,
      "step": 5050
    },
    {
      "epoch": 0.29994706816444155,
      "grad_norm": 12114.701171875,
      "learning_rate": 0.0002422166143948291,
      "loss": 7.0123,
      "step": 5100
    },
    {
      "epoch": 0.3028877256954655,
      "grad_norm": 12983.5830078125,
      "learning_rate": 0.00024110292350020194,
      "loss": 7.0238,
      "step": 5150
    },
    {
      "epoch": 0.3058283832264894,
      "grad_norm": 11578.958984375,
      "learning_rate": 0.00023998121776582903,
      "loss": 6.9878,
      "step": 5200
    },
    {
      "epoch": 0.3058283832264894,
      "eval_accuracy": 0.04512488000519266,
      "eval_loss": 6.969000816345215,
      "eval_runtime": 3.9236,
      "eval_samples_per_second": 36.446,
      "eval_steps_per_second": 2.294,
      "step": 5200
    },
    {
      "epoch": 0.3087690407575134,
      "grad_norm": 26485.0703125,
      "learning_rate": 0.00023885159587451178,
      "loss": 6.9661,
      "step": 5250
    },
    {
      "epoch": 0.31170969828853734,
      "grad_norm": 35377.99609375,
      "learning_rate": 0.00023771415720548068,
      "loss": 7.0199,
      "step": 5300
    },
    {
      "epoch": 0.31465035581956124,
      "grad_norm": 11300.724609375,
      "learning_rate": 0.00023656900182565232,
      "loss": 7.0326,
      "step": 5350
    },
    {
      "epoch": 0.3175910133505852,
      "grad_norm": 22894.50390625,
      "learning_rate": 0.00023541623048082609,
      "loss": 7.0147,
      "step": 5400
    },
    {
      "epoch": 0.3175910133505852,
      "eval_accuracy": 0.0453810966756741,
      "eval_loss": 6.964467525482178,
      "eval_runtime": 3.9326,
      "eval_samples_per_second": 36.363,
      "eval_steps_per_second": 2.289,
      "step": 5400
    },
    {
      "epoch": 0.3205316708816091,
      "grad_norm": 33982.15234375,
      "learning_rate": 0.00023425594458682095,
      "loss": 6.9875,
      "step": 5450
    },
    {
      "epoch": 0.32347232841263307,
      "grad_norm": 26422.056640625,
      "learning_rate": 0.00023308824622055323,
      "loss": 6.9733,
      "step": 5500
    },
    {
      "epoch": 0.326412985943657,
      "grad_norm": 41372.8046875,
      "learning_rate": 0.0002319132381110563,
      "loss": 6.9745,
      "step": 5550
    },
    {
      "epoch": 0.32935364347468093,
      "grad_norm": 23911.177734375,
      "learning_rate": 0.00023073102363044322,
      "loss": 7.0229,
      "step": 5600
    },
    {
      "epoch": 0.32935364347468093,
      "eval_accuracy": 0.04599943290710267,
      "eval_loss": 6.954164981842041,
      "eval_runtime": 3.951,
      "eval_samples_per_second": 36.193,
      "eval_steps_per_second": 2.278,
      "step": 5600
    },
    {
      "epoch": 0.3322943010057049,
      "grad_norm": 22314.884765625,
      "learning_rate": 0.00022954170678481212,
      "loss": 6.9753,
      "step": 5650
    },
    {
      "epoch": 0.3352349585367288,
      "grad_norm": 23245.734375,
      "learning_rate": 0.00022834539220509644,
      "loss": 7.0004,
      "step": 5700
    },
    {
      "epoch": 0.33817561606775276,
      "grad_norm": 29268.90625,
      "learning_rate": 0.00022714218513785988,
      "loss": 7.0002,
      "step": 5750
    },
    {
      "epoch": 0.34111627359877666,
      "grad_norm": 54072.6015625,
      "learning_rate": 0.0002259321914360373,
      "loss": 7.0029,
      "step": 5800
    },
    {
      "epoch": 0.34111627359877666,
      "eval_accuracy": 0.044161505324182414,
      "eval_loss": 6.971738338470459,
      "eval_runtime": 3.9287,
      "eval_samples_per_second": 36.399,
      "eval_steps_per_second": 2.291,
      "step": 5800
    },
    {
      "epoch": 0.3440569311298006,
      "grad_norm": 40877.3359375,
      "learning_rate": 0.0002247155175496222,
      "loss": 6.997,
      "step": 5850
    },
    {
      "epoch": 0.3469975886608246,
      "grad_norm": 39717.31640625,
      "learning_rate": 0.00022349227051630168,
      "loss": 6.9729,
      "step": 5900
    },
    {
      "epoch": 0.3499382461918485,
      "grad_norm": 30272.51171875,
      "learning_rate": 0.00022226255795203986,
      "loss": 6.9931,
      "step": 5950
    },
    {
      "epoch": 0.35287890372287245,
      "grad_norm": 56966.140625,
      "learning_rate": 0.00022102648804161006,
      "loss": 7.002,
      "step": 6000
    },
    {
      "epoch": 0.35287890372287245,
      "eval_accuracy": 0.04374814242913901,
      "eval_loss": 6.973164081573486,
      "eval_runtime": 3.9159,
      "eval_samples_per_second": 36.518,
      "eval_steps_per_second": 2.298,
      "step": 6000
    },
    {
      "epoch": 0.35581956125389635,
      "grad_norm": 53473.25390625,
      "learning_rate": 0.00021978416952907748,
      "loss": 7.0095,
      "step": 6050
    },
    {
      "epoch": 0.3587602187849203,
      "grad_norm": 90583.96875,
      "learning_rate": 0.00021853571170823207,
      "loss": 7.0192,
      "step": 6100
    },
    {
      "epoch": 0.3617008763159442,
      "grad_norm": 141603.28125,
      "learning_rate": 0.00021728122441297363,
      "loss": 6.9992,
      "step": 6150
    },
    {
      "epoch": 0.3646415338469682,
      "grad_norm": 66152.2421875,
      "learning_rate": 0.0002160208180076488,
      "loss": 6.9998,
      "step": 6200
    },
    {
      "epoch": 0.3646415338469682,
      "eval_accuracy": 0.043249373977268454,
      "eval_loss": 6.981423854827881,
      "eval_runtime": 3.9252,
      "eval_samples_per_second": 36.431,
      "eval_steps_per_second": 2.293,
      "step": 6200
    },
    {
      "epoch": 0.36758219137799214,
      "grad_norm": 98055.1171875,
      "learning_rate": 0.0002147546033773419,
      "loss": 7.0171,
      "step": 6250
    },
    {
      "epoch": 0.37052284890901604,
      "grad_norm": 58258.859375,
      "learning_rate": 0.0002134826919181197,
      "loss": 7.0414,
      "step": 6300
    },
    {
      "epoch": 0.37346350644004,
      "grad_norm": 93583.765625,
      "learning_rate": 0.00021220519552723116,
      "loss": 7.0046,
      "step": 6350
    },
    {
      "epoch": 0.3764041639710639,
      "grad_norm": 106753.9375,
      "learning_rate": 0.00021092222659326336,
      "loss": 7.0095,
      "step": 6400
    },
    {
      "epoch": 0.3764041639710639,
      "eval_accuracy": 0.04322546042135685,
      "eval_loss": 6.980575084686279,
      "eval_runtime": 3.9264,
      "eval_samples_per_second": 36.42,
      "eval_steps_per_second": 2.292,
      "step": 6400
    },
    {
      "epoch": 0.37934482150208787,
      "grad_norm": 62015.6640625,
      "learning_rate": 0.0002096338979862539,
      "loss": 7.0326,
      "step": 6450
    },
    {
      "epoch": 0.38228547903311183,
      "grad_norm": 20752.431640625,
      "learning_rate": 0.00020834032304776129,
      "loss": 7.0225,
      "step": 6500
    },
    {
      "epoch": 0.38522613656413573,
      "grad_norm": 58443.23046875,
      "learning_rate": 0.0002070416155808933,
      "loss": 7.0397,
      "step": 6550
    },
    {
      "epoch": 0.3881667940951597,
      "grad_norm": 38144.65234375,
      "learning_rate": 0.0002057378898402954,
      "loss": 7.0228,
      "step": 6600
    },
    {
      "epoch": 0.3881667940951597,
      "eval_accuracy": 0.04429132177055968,
      "eval_loss": 6.9852519035339355,
      "eval_runtime": 3.9321,
      "eval_samples_per_second": 36.367,
      "eval_steps_per_second": 2.289,
      "step": 6600
    },
    {
      "epoch": 0.3911074516261836,
      "grad_norm": 39439.04296875,
      "learning_rate": 0.00020442926052209896,
      "loss": 7.0456,
      "step": 6650
    },
    {
      "epoch": 0.39404810915720756,
      "grad_norm": 34033.8046875,
      "learning_rate": 0.00020311584275383088,
      "loss": 7.0245,
      "step": 6700
    },
    {
      "epoch": 0.39698876668823146,
      "grad_norm": 76055.5703125,
      "learning_rate": 0.0002017977520842851,
      "loss": 7.0474,
      "step": 6750
    },
    {
      "epoch": 0.3999294242192554,
      "grad_norm": 25985.6640625,
      "learning_rate": 0.00020047510447335703,
      "loss": 7.0253,
      "step": 6800
    },
    {
      "epoch": 0.3999294242192554,
      "eval_accuracy": 0.044632943997868275,
      "eval_loss": 6.988582611083984,
      "eval_runtime": 3.928,
      "eval_samples_per_second": 36.405,
      "eval_steps_per_second": 2.291,
      "step": 6800
    },
    {
      "epoch": 0.4028700817502794,
      "grad_norm": 43292.25,
      "learning_rate": 0.00019914801628184207,
      "loss": 7.0298,
      "step": 6850
    },
    {
      "epoch": 0.4058107392813033,
      "grad_norm": 43491.96484375,
      "learning_rate": 0.00019781660426119863,
      "loss": 7.0271,
      "step": 6900
    },
    {
      "epoch": 0.40875139681232725,
      "grad_norm": 26901.103515625,
      "learning_rate": 0.00019648098554327686,
      "loss": 7.0418,
      "step": 6950
    },
    {
      "epoch": 0.41169205434335115,
      "grad_norm": 27993.310546875,
      "learning_rate": 0.00019514127763001378,
      "loss": 7.0351,
      "step": 7000
    },
    {
      "epoch": 0.41169205434335115,
      "eval_accuracy": 0.0455040806775052,
      "eval_loss": 6.98525333404541,
      "eval_runtime": 3.9208,
      "eval_samples_per_second": 36.472,
      "eval_steps_per_second": 2.295,
      "step": 7000
    },
    {
      "epoch": 0.4146327118743751,
      "grad_norm": 27579.244140625,
      "learning_rate": 0.00019379759838309622,
      "loss": 7.0136,
      "step": 7050
    },
    {
      "epoch": 0.417573369405399,
      "grad_norm": 26421.748046875,
      "learning_rate": 0.00019245006601359155,
      "loss": 7.0364,
      "step": 7100
    },
    {
      "epoch": 0.420514026936423,
      "grad_norm": 14588.0673828125,
      "learning_rate": 0.00019109879907154825,
      "loss": 7.0366,
      "step": 7150
    },
    {
      "epoch": 0.42345468446744694,
      "grad_norm": 24390.92578125,
      "learning_rate": 0.00018974391643556624,
      "loss": 7.0,
      "step": 7200
    },
    {
      "epoch": 0.42345468446744694,
      "eval_accuracy": 0.04594818957300638,
      "eval_loss": 6.97941780090332,
      "eval_runtime": 3.9262,
      "eval_samples_per_second": 36.422,
      "eval_steps_per_second": 2.292,
      "step": 7200
    },
    {
      "epoch": 0.42639534199847084,
      "grad_norm": 17846.125,
      "learning_rate": 0.00018838553730233845,
      "loss": 7.0191,
      "step": 7250
    },
    {
      "epoch": 0.4293359995294948,
      "grad_norm": 18868.294921875,
      "learning_rate": 0.00018702378117616458,
      "loss": 7.0227,
      "step": 7300
    },
    {
      "epoch": 0.4322766570605187,
      "grad_norm": 6172.40576171875,
      "learning_rate": 0.00018565876785843735,
      "loss": 6.9949,
      "step": 7350
    },
    {
      "epoch": 0.43521731459154267,
      "grad_norm": 6524.76904296875,
      "learning_rate": 0.00018429061743710314,
      "loss": 7.0492,
      "step": 7400
    },
    {
      "epoch": 0.43521731459154267,
      "eval_accuracy": 0.045787627126171335,
      "eval_loss": 6.971140384674072,
      "eval_runtime": 3.9274,
      "eval_samples_per_second": 36.411,
      "eval_steps_per_second": 2.292,
      "step": 7400
    },
    {
      "epoch": 0.43815797212256663,
      "grad_norm": 8294.498046875,
      "learning_rate": 0.0001829194502760972,
      "loss": 6.9954,
      "step": 7450
    },
    {
      "epoch": 0.44109862965359053,
      "grad_norm": 9324.8857421875,
      "learning_rate": 0.00018154538700475422,
      "loss": 6.9833,
      "step": 7500
    },
    {
      "epoch": 0.4440392871846145,
      "grad_norm": 9402.0322265625,
      "learning_rate": 0.00018016854850719623,
      "loss": 7.0293,
      "step": 7550
    },
    {
      "epoch": 0.4469799447156384,
      "grad_norm": 11910.7421875,
      "learning_rate": 0.0001787890559116977,
      "loss": 6.9848,
      "step": 7600
    },
    {
      "epoch": 0.4469799447156384,
      "eval_accuracy": 0.047174613369044244,
      "eval_loss": 6.971545696258545,
      "eval_runtime": 3.9256,
      "eval_samples_per_second": 36.427,
      "eval_steps_per_second": 2.293,
      "step": 7600
    },
    {
      "epoch": 0.44992060224666236,
      "grad_norm": 3861.317626953125,
      "learning_rate": 0.00017740703058002888,
      "loss": 7.0104,
      "step": 7650
    },
    {
      "epoch": 0.45286125977768626,
      "grad_norm": 4985.744140625,
      "learning_rate": 0.00017602259409677933,
      "loss": 7.0264,
      "step": 7700
    },
    {
      "epoch": 0.4558019173087102,
      "grad_norm": 14894.4072265625,
      "learning_rate": 0.0001746358682586613,
      "loss": 7.0252,
      "step": 7750
    },
    {
      "epoch": 0.4587425748397342,
      "grad_norm": 7800.0849609375,
      "learning_rate": 0.00017324697506379436,
      "loss": 7.028,
      "step": 7800
    },
    {
      "epoch": 0.4587425748397342,
      "eval_accuracy": 0.04546650223250125,
      "eval_loss": 6.9813971519470215,
      "eval_runtime": 3.9214,
      "eval_samples_per_second": 36.467,
      "eval_steps_per_second": 2.295,
      "step": 7800
    },
    {
      "epoch": 0.4616832323707581,
      "grad_norm": 17087.603515625,
      "learning_rate": 0.00017185603670097284,
      "loss": 7.0969,
      "step": 7850
    },
    {
      "epoch": 0.46462388990178205,
      "grad_norm": 18490.578125,
      "learning_rate": 0.00017046317553891612,
      "loss": 7.0883,
      "step": 7900
    },
    {
      "epoch": 0.46756454743280595,
      "grad_norm": 7768.49365234375,
      "learning_rate": 0.00016906851411550294,
      "loss": 7.0376,
      "step": 7950
    },
    {
      "epoch": 0.4705052049638299,
      "grad_norm": 9216.19921875,
      "learning_rate": 0.00016767217512699147,
      "loss": 7.0227,
      "step": 8000
    },
    {
      "epoch": 0.4705052049638299,
      "eval_accuracy": 0.046846656030827986,
      "eval_loss": 6.9687933921813965,
      "eval_runtime": 3.9272,
      "eval_samples_per_second": 36.412,
      "eval_steps_per_second": 2.292,
      "step": 8000
    },
    {
      "epoch": 0.4734458624948539,
      "grad_norm": 10857.9453125,
      "learning_rate": 0.00016627428141722443,
      "loss": 7.0275,
      "step": 8050
    },
    {
      "epoch": 0.4763865200258778,
      "grad_norm": 4168.1357421875,
      "learning_rate": 0.00016487495596682254,
      "loss": 6.9821,
      "step": 8100
    },
    {
      "epoch": 0.47932717755690174,
      "grad_norm": 8361.8037109375,
      "learning_rate": 0.00016347432188236455,
      "loss": 7.004,
      "step": 8150
    },
    {
      "epoch": 0.48226783508792564,
      "grad_norm": 12009.5205078125,
      "learning_rate": 0.00016207250238555737,
      "loss": 7.018,
      "step": 8200
    },
    {
      "epoch": 0.48226783508792564,
      "eval_accuracy": 0.04606092490801821,
      "eval_loss": 6.966592788696289,
      "eval_runtime": 3.9233,
      "eval_samples_per_second": 36.449,
      "eval_steps_per_second": 2.294,
      "step": 8200
    },
    {
      "epoch": 0.4852084926189496,
      "grad_norm": 8872.66796875,
      "learning_rate": 0.0001606696208023951,
      "loss": 7.0121,
      "step": 8250
    },
    {
      "epoch": 0.4881491501499735,
      "grad_norm": 25691.92578125,
      "learning_rate": 0.00015926580055230987,
      "loss": 7.0129,
      "step": 8300
    },
    {
      "epoch": 0.49108980768099747,
      "grad_norm": 9513.19140625,
      "learning_rate": 0.00015786116513731346,
      "loss": 6.995,
      "step": 8350
    },
    {
      "epoch": 0.49403046521202143,
      "grad_norm": 33721.79296875,
      "learning_rate": 0.00015645583813113237,
      "loss": 7.0106,
      "step": 8400
    },
    {
      "epoch": 0.49403046521202143,
      "eval_accuracy": 0.04702429958902846,
      "eval_loss": 6.964229106903076,
      "eval_runtime": 3.9269,
      "eval_samples_per_second": 36.416,
      "eval_steps_per_second": 2.292,
      "step": 8400
    },
    {
      "epoch": 0.49697112274304533,
      "grad_norm": 19340.9375,
      "learning_rate": 0.00015504994316833636,
      "loss": 6.9807,
      "step": 8450
    },
    {
      "epoch": 0.4999117802740693,
      "grad_norm": 55773.6328125,
      "learning_rate": 0.00015364360393346137,
      "loss": 7.0224,
      "step": 8500
    },
    {
      "epoch": 0.5028524378050933,
      "grad_norm": 6738.9833984375,
      "learning_rate": 0.0001522369441501287,
      "loss": 7.0168,
      "step": 8550
    },
    {
      "epoch": 0.5057930953361172,
      "grad_norm": 21910.740234375,
      "learning_rate": 0.00015083008757015985,
      "loss": 7.0166,
      "step": 8600
    },
    {
      "epoch": 0.5057930953361172,
      "eval_accuracy": 0.04624540091076486,
      "eval_loss": 6.965299606323242,
      "eval_runtime": 3.935,
      "eval_samples_per_second": 36.34,
      "eval_steps_per_second": 2.287,
      "step": 8600
    },
    {
      "epoch": 0.5087337528671411,
      "grad_norm": 23185.12109375,
      "learning_rate": 0.00014942315796268992,
      "loss": 6.9724,
      "step": 8650
    },
    {
      "epoch": 0.5116744103981651,
      "grad_norm": 7266.5458984375,
      "learning_rate": 0.0001480162791032784,
      "loss": 7.0146,
      "step": 8700
    },
    {
      "epoch": 0.514615067929189,
      "grad_norm": 15459.8818359375,
      "learning_rate": 0.00014660957476302043,
      "loss": 7.0076,
      "step": 8750
    },
    {
      "epoch": 0.5175557254602129,
      "grad_norm": 10085.1953125,
      "learning_rate": 0.00014520316869765743,
      "loss": 6.9607,
      "step": 8800
    },
    {
      "epoch": 0.5175557254602129,
      "eval_accuracy": 0.044868663334711206,
      "eval_loss": 6.9744038581848145,
      "eval_runtime": 3.9286,
      "eval_samples_per_second": 36.4,
      "eval_steps_per_second": 2.291,
      "step": 8800
    },
    {
      "epoch": 0.5204963829912368,
      "grad_norm": 6358.294921875,
      "learning_rate": 0.0001437971846366901,
      "loss": 6.9873,
      "step": 8850
    },
    {
      "epoch": 0.5234370405222608,
      "grad_norm": 21780.271484375,
      "learning_rate": 0.000142391746272493,
      "loss": 6.9621,
      "step": 8900
    },
    {
      "epoch": 0.5263776980532847,
      "grad_norm": 21774.3046875,
      "learning_rate": 0.00014098697724943256,
      "loss": 7.0392,
      "step": 8950
    },
    {
      "epoch": 0.5293183555843086,
      "grad_norm": 5560.66845703125,
      "learning_rate": 0.0001395830011529896,
      "loss": 7.0156,
      "step": 9000
    },
    {
      "epoch": 0.5293183555843086,
      "eval_accuracy": 0.04503947444836551,
      "eval_loss": 6.9809346199035645,
      "eval_runtime": 3.9287,
      "eval_samples_per_second": 36.398,
      "eval_steps_per_second": 2.291,
      "step": 9000
    },
    {
      "epoch": 0.5322590131153326,
      "grad_norm": 24025.462890625,
      "learning_rate": 0.00013817994149888655,
      "loss": 7.0304,
      "step": 9050
    },
    {
      "epoch": 0.5351996706463565,
      "grad_norm": 5071.16455078125,
      "learning_rate": 0.00013677792172222137,
      "loss": 6.9893,
      "step": 9100
    },
    {
      "epoch": 0.5381403281773804,
      "grad_norm": 11320.4619140625,
      "learning_rate": 0.00013537706516660811,
      "loss": 7.0227,
      "step": 9150
    },
    {
      "epoch": 0.5410809857084043,
      "grad_norm": 20696.509765625,
      "learning_rate": 0.0001339774950733255,
      "loss": 6.9737,
      "step": 9200
    },
    {
      "epoch": 0.5410809857084043,
      "eval_accuracy": 0.04552116178887063,
      "eval_loss": 6.979348182678223,
      "eval_runtime": 3.9284,
      "eval_samples_per_second": 36.402,
      "eval_steps_per_second": 2.291,
      "step": 9200
    },
    {
      "epoch": 0.5440216432394284,
      "grad_norm": 9418.810546875,
      "learning_rate": 0.00013257933457047518,
      "loss": 7.0135,
      "step": 9250
    },
    {
      "epoch": 0.5469623007704523,
      "grad_norm": 20122.443359375,
      "learning_rate": 0.00013118270666214886,
      "loss": 7.0216,
      "step": 9300
    },
    {
      "epoch": 0.5499029583014762,
      "grad_norm": 18724.451171875,
      "learning_rate": 0.00012978773421760744,
      "loss": 6.9921,
      "step": 9350
    },
    {
      "epoch": 0.5528436158325002,
      "grad_norm": 24384.83203125,
      "learning_rate": 0.00012839453996047118,
      "loss": 6.991,
      "step": 9400
    },
    {
      "epoch": 0.5528436158325002,
      "eval_accuracy": 0.046873985809012676,
      "eval_loss": 6.955165386199951,
      "eval_runtime": 3.9325,
      "eval_samples_per_second": 36.364,
      "eval_steps_per_second": 2.289,
      "step": 9400
    },
    {
      "epoch": 0.5557842733635241,
      "grad_norm": 22282.27734375,
      "learning_rate": 0.00012700324645792318,
      "loss": 7.0163,
      "step": 9450
    },
    {
      "epoch": 0.558724930894548,
      "grad_norm": 13960.6220703125,
      "learning_rate": 0.00012561397610992645,
      "loss": 6.9924,
      "step": 9500
    },
    {
      "epoch": 0.5616655884255719,
      "grad_norm": 34501.0234375,
      "learning_rate": 0.00012422685113845563,
      "loss": 7.0103,
      "step": 9550
    },
    {
      "epoch": 0.5646062459565959,
      "grad_norm": 21172.92578125,
      "learning_rate": 0.00012284199357674432,
      "loss": 6.9988,
      "step": 9600
    },
    {
      "epoch": 0.5646062459565959,
      "eval_accuracy": 0.046019930240741184,
      "eval_loss": 6.963393211364746,
      "eval_runtime": 3.9289,
      "eval_samples_per_second": 36.397,
      "eval_steps_per_second": 2.291,
      "step": 9600
    },
    {
      "epoch": 0.5675469034876198,
      "grad_norm": 28339.642578125,
      "learning_rate": 0.00012145952525854939,
      "loss": 7.0238,
      "step": 9650
    },
    {
      "epoch": 0.5704875610186437,
      "grad_norm": 53941.9609375,
      "learning_rate": 0.0001200795678074324,
      "loss": 7.0316,
      "step": 9700
    },
    {
      "epoch": 0.5734282185496677,
      "grad_norm": 32783.41796875,
      "learning_rate": 0.00011870224262605968,
      "loss": 7.0821,
      "step": 9750
    },
    {
      "epoch": 0.5763688760806917,
      "grad_norm": 11540.4599609375,
      "learning_rate": 0.00011732767088552198,
      "loss": 7.0786,
      "step": 9800
    },
    {
      "epoch": 0.5763688760806917,
      "eval_accuracy": 0.04602334646301427,
      "eval_loss": 7.052241325378418,
      "eval_runtime": 3.9234,
      "eval_samples_per_second": 36.448,
      "eval_steps_per_second": 2.294,
      "step": 9800
    },
    {
      "epoch": 0.5793095336117156,
      "grad_norm": 11325.0087890625,
      "learning_rate": 0.00011595597351467419,
      "loss": 7.1174,
      "step": 9850
    },
    {
      "epoch": 0.5822501911427396,
      "grad_norm": 110244.2421875,
      "learning_rate": 0.00011458727118949665,
      "loss": 7.0496,
      "step": 9900
    },
    {
      "epoch": 0.5851908486737635,
      "grad_norm": 57493.71484375,
      "learning_rate": 0.00011322168432247867,
      "loss": 7.0267,
      "step": 9950
    },
    {
      "epoch": 0.5881315062047874,
      "grad_norm": 29524.541015625,
      "learning_rate": 0.00011185933305202495,
      "loss": 7.0665,
      "step": 10000
    },
    {
      "epoch": 0.5881315062047874,
      "eval_accuracy": 0.045104382671554144,
      "eval_loss": 7.021131992340088,
      "eval_runtime": 3.9289,
      "eval_samples_per_second": 36.397,
      "eval_steps_per_second": 2.291,
      "step": 10000
    },
    {
      "epoch": 0.5910721637358113,
      "grad_norm": 29598.73046875,
      "learning_rate": 0.00011050033723188653,
      "loss": 7.0923,
      "step": 10050
    },
    {
      "epoch": 0.5940128212668353,
      "grad_norm": 13870.7890625,
      "learning_rate": 0.00010914481642061645,
      "loss": 7.0689,
      "step": 10100
    },
    {
      "epoch": 0.5969534787978592,
      "grad_norm": 49068.16796875,
      "learning_rate": 0.00010779288987105163,
      "loss": 7.069,
      "step": 10150
    },
    {
      "epoch": 0.5998941363288831,
      "grad_norm": 52101.82421875,
      "learning_rate": 0.00010644467651982131,
      "loss": 7.0675,
      "step": 10200
    },
    {
      "epoch": 0.5998941363288831,
      "eval_accuracy": 0.04529227489657387,
      "eval_loss": 7.040545463562012,
      "eval_runtime": 3.919,
      "eval_samples_per_second": 36.489,
      "eval_steps_per_second": 2.297,
      "step": 10200
    },
    {
      "epoch": 0.6028347938599071,
      "grad_norm": 31818.111328125,
      "learning_rate": 0.00010510029497688383,
      "loss": 7.0817,
      "step": 10250
    },
    {
      "epoch": 0.605775451390931,
      "grad_norm": 39412.40234375,
      "learning_rate": 0.00010375986351509155,
      "loss": 7.0977,
      "step": 10300
    },
    {
      "epoch": 0.6087161089219549,
      "grad_norm": 4347.6015625,
      "learning_rate": 0.00010242350005978581,
      "loss": 7.1281,
      "step": 10350
    },
    {
      "epoch": 0.6116567664529788,
      "grad_norm": 3899.885498046875,
      "learning_rate": 0.00010109132217842253,
      "loss": 7.1032,
      "step": 10400
    },
    {
      "epoch": 0.6116567664529788,
      "eval_accuracy": 0.0452615288961161,
      "eval_loss": 7.0501708984375,
      "eval_runtime": 3.9223,
      "eval_samples_per_second": 36.458,
      "eval_steps_per_second": 2.295,
      "step": 10400
    },
    {
      "epoch": 0.6145974239840029,
      "grad_norm": 15659.76953125,
      "learning_rate": 9.976344707022895e-05,
      "loss": 7.0854,
      "step": 10450
    },
    {
      "epoch": 0.6175380815150268,
      "grad_norm": 62108.5078125,
      "learning_rate": 9.843999155589296e-05,
      "loss": 7.0608,
      "step": 10500
    },
    {
      "epoch": 0.6204787390460507,
      "grad_norm": 34490.41796875,
      "learning_rate": 9.712107206728578e-05,
      "loss": 7.0447,
      "step": 10550
    },
    {
      "epoch": 0.6234193965770747,
      "grad_norm": 16025.97265625,
      "learning_rate": 9.580680463721883e-05,
      "loss": 7.0261,
      "step": 10600
    },
    {
      "epoch": 0.6234193965770747,
      "eval_accuracy": 0.04482766866743418,
      "eval_loss": 7.011406898498535,
      "eval_runtime": 4.4308,
      "eval_samples_per_second": 32.274,
      "eval_steps_per_second": 2.031,
      "step": 10600
    },
    {
      "epoch": 0.6263600541080986,
      "grad_norm": 31184.572265625,
      "learning_rate": 9.44973048892355e-05,
      "loss": 7.0761,
      "step": 10650
    },
    {
      "epoch": 0.6293007116391225,
      "grad_norm": 92775.4453125,
      "learning_rate": 9.319268802743935e-05,
      "loss": 7.0255,
      "step": 10700
    },
    {
      "epoch": 0.6322413691701464,
      "grad_norm": 48215.8828125,
      "learning_rate": 9.18930688263587e-05,
      "loss": 7.2,
      "step": 10750
    },
    {
      "epoch": 0.6351820267011704,
      "grad_norm": 3935.387939453125,
      "learning_rate": 9.059856162084942e-05,
      "loss": 7.1922,
      "step": 10800
    },
    {
      "epoch": 0.6351820267011704,
      "eval_accuracy": 0.04326645508863389,
      "eval_loss": 7.079089641571045,
      "eval_runtime": 3.9076,
      "eval_samples_per_second": 36.596,
      "eval_steps_per_second": 2.303,
      "step": 10800
    },
    {
      "epoch": 0.6381226842321943,
      "grad_norm": 17099.677734375,
      "learning_rate": 8.930928029603623e-05,
      "loss": 7.1208,
      "step": 10850
    },
    {
      "epoch": 0.6410633417632182,
      "grad_norm": 7604.8642578125,
      "learning_rate": 8.802533827729344e-05,
      "loss": 7.1699,
      "step": 10900
    },
    {
      "epoch": 0.6440039992942422,
      "grad_norm": 74216.9765625,
      "learning_rate": 8.674684852026654e-05,
      "loss": 7.5985,
      "step": 10950
    },
    {
      "epoch": 0.6469446568252661,
      "grad_norm": 773248.6875,
      "learning_rate": 8.54739235009346e-05,
      "loss": 7.7978,
      "step": 11000
    },
    {
      "epoch": 0.6469446568252661,
      "eval_accuracy": 0.03788590500852348,
      "eval_loss": 7.680957794189453,
      "eval_runtime": 3.9053,
      "eval_samples_per_second": 36.617,
      "eval_steps_per_second": 2.305,
      "step": 11000
    },
    {
      "epoch": 0.64988531435629,
      "grad_norm": 13077.4072265625,
      "learning_rate": 8.420667520571518e-05,
      "loss": 7.5193,
      "step": 11050
    },
    {
      "epoch": 0.652825971887314,
      "grad_norm": 32860.95703125,
      "learning_rate": 8.294521512161247e-05,
      "loss": 7.1561,
      "step": 11100
    },
    {
      "epoch": 0.655766629418338,
      "grad_norm": 38710.76953125,
      "learning_rate": 8.168965422640883e-05,
      "loss": 7.1071,
      "step": 11150
    },
    {
      "epoch": 0.6587072869493619,
      "grad_norm": 70187.34375,
      "learning_rate": 8.044010297890155e-05,
      "loss": 7.1217,
      "step": 11200
    },
    {
      "epoch": 0.6587072869493619,
      "eval_accuracy": 0.04186922017894172,
      "eval_loss": 7.094144344329834,
      "eval_runtime": 3.9215,
      "eval_samples_per_second": 36.465,
      "eval_steps_per_second": 2.295,
      "step": 11200
    },
    {
      "epoch": 0.6616479444803858,
      "grad_norm": 13730.4541015625,
      "learning_rate": 7.919667130918534e-05,
      "loss": 7.1336,
      "step": 11250
    },
    {
      "epoch": 0.6645886020114098,
      "grad_norm": 1102.6312255859375,
      "learning_rate": 7.795946860898101e-05,
      "loss": 7.1039,
      "step": 11300
    },
    {
      "epoch": 0.6675292595424337,
      "grad_norm": 18923.609375,
      "learning_rate": 7.672860372201154e-05,
      "loss": 7.1247,
      "step": 11350
    },
    {
      "epoch": 0.6704699170734576,
      "grad_norm": 64976.58984375,
      "learning_rate": 7.550418493442667e-05,
      "loss": 7.1463,
      "step": 11400
    },
    {
      "epoch": 0.6704699170734576,
      "eval_accuracy": 0.04235090751944685,
      "eval_loss": 7.06882381439209,
      "eval_runtime": 3.9262,
      "eval_samples_per_second": 36.422,
      "eval_steps_per_second": 2.292,
      "step": 11400
    },
    {
      "epoch": 0.6734105746044816,
      "grad_norm": 37733.28515625,
      "learning_rate": 7.42863199652764e-05,
      "loss": 7.1151,
      "step": 11450
    },
    {
      "epoch": 0.6763512321355055,
      "grad_norm": 107058.59375,
      "learning_rate": 7.307511595703411e-05,
      "loss": 7.1249,
      "step": 11500
    },
    {
      "epoch": 0.6792918896665294,
      "grad_norm": 106192.0625,
      "learning_rate": 7.18706794661708e-05,
      "loss": 7.1279,
      "step": 11550
    },
    {
      "epoch": 0.6822325471975533,
      "grad_norm": 653552.375,
      "learning_rate": 7.067311645378057e-05,
      "loss": 7.0854,
      "step": 11600
    },
    {
      "epoch": 0.6822325471975533,
      "eval_accuracy": 0.04251488618855497,
      "eval_loss": 7.069903373718262,
      "eval_runtime": 3.9255,
      "eval_samples_per_second": 36.429,
      "eval_steps_per_second": 2.293,
      "step": 11600
    },
    {
      "epoch": 0.6851732047285773,
      "grad_norm": 414988.46875,
      "learning_rate": 6.948253227625897e-05,
      "loss": 7.1038,
      "step": 11650
    },
    {
      "epoch": 0.6881138622596012,
      "grad_norm": 2513126.25,
      "learning_rate": 6.829903167603372e-05,
      "loss": 7.1259,
      "step": 11700
    },
    {
      "epoch": 0.6910545197906252,
      "grad_norm": 6650245.5,
      "learning_rate": 6.712271877235016e-05,
      "loss": 7.6563,
      "step": 11750
    },
    {
      "epoch": 0.6939951773216492,
      "grad_norm": 82992.5703125,
      "learning_rate": 6.59536970521115e-05,
      "loss": 7.1952,
      "step": 11800
    },
    {
      "epoch": 0.6939951773216492,
      "eval_accuracy": 0.04199903662531899,
      "eval_loss": 7.072369575500488,
      "eval_runtime": 3.9267,
      "eval_samples_per_second": 36.417,
      "eval_steps_per_second": 2.292,
      "step": 11800
    },
    {
      "epoch": 0.6969358348526731,
      "grad_norm": 50074.7421875,
      "learning_rate": 6.47920693607741e-05,
      "loss": 7.0904,
      "step": 11850
    },
    {
      "epoch": 0.699876492383697,
      "grad_norm": 44795.91015625,
      "learning_rate": 6.363793789329969e-05,
      "loss": 7.0736,
      "step": 11900
    },
    {
      "epoch": 0.7028171499147209,
      "grad_norm": 76324.8203125,
      "learning_rate": 6.249140418516501e-05,
      "loss": 7.1094,
      "step": 11950
    },
    {
      "epoch": 0.7057578074457449,
      "grad_norm": 89473.8515625,
      "learning_rate": 6.135256910342873e-05,
      "loss": 7.1323,
      "step": 12000
    },
    {
      "epoch": 0.7057578074457449,
      "eval_accuracy": 0.04242264818718165,
      "eval_loss": 7.071073055267334,
      "eval_runtime": 3.9434,
      "eval_samples_per_second": 36.263,
      "eval_steps_per_second": 2.282,
      "step": 12000
    },
    {
      "epoch": 0.7086984649767688,
      "grad_norm": 97254.4375,
      "learning_rate": 6.022153283785782e-05,
      "loss": 7.0842,
      "step": 12050
    },
    {
      "epoch": 0.7116391225077927,
      "grad_norm": 192029.53125,
      "learning_rate": 5.909839489211321e-05,
      "loss": 7.1056,
      "step": 12100
    },
    {
      "epoch": 0.7145797800388167,
      "grad_norm": 180529.109375,
      "learning_rate": 5.7983254074996065e-05,
      "loss": 7.1205,
      "step": 12150
    },
    {
      "epoch": 0.7175204375698406,
      "grad_norm": 126234.4453125,
      "learning_rate": 5.687620849175486e-05,
      "loss": 7.1204,
      "step": 12200
    },
    {
      "epoch": 0.7175204375698406,
      "eval_accuracy": 0.0423372426303545,
      "eval_loss": 7.0952019691467285,
      "eval_runtime": 3.9266,
      "eval_samples_per_second": 36.418,
      "eval_steps_per_second": 2.292,
      "step": 12200
    },
    {
      "epoch": 0.7204610951008645,
      "grad_norm": 189965.515625,
      "learning_rate": 5.5777355535454435e-05,
      "loss": 7.1269,
      "step": 12250
    },
    {
      "epoch": 0.7234017526318884,
      "grad_norm": 237412.765625,
      "learning_rate": 5.46867918784079e-05,
      "loss": 7.1341,
      "step": 12300
    },
    {
      "epoch": 0.7263424101629125,
      "grad_norm": 149775.1875,
      "learning_rate": 5.360461346367194e-05,
      "loss": 7.1535,
      "step": 12350
    },
    {
      "epoch": 0.7292830676939364,
      "grad_norm": 248798.03125,
      "learning_rate": 5.2530915496605845e-05,
      "loss": 7.1555,
      "step": 12400
    },
    {
      "epoch": 0.7292830676939364,
      "eval_accuracy": 0.042477307743551025,
      "eval_loss": 7.0987043380737305,
      "eval_runtime": 3.921,
      "eval_samples_per_second": 36.47,
      "eval_steps_per_second": 2.295,
      "step": 12400
    },
    {
      "epoch": 0.7322237252249603,
      "grad_norm": 453127.65625,
      "learning_rate": 5.146579243649595e-05,
      "loss": 7.1268,
      "step": 12450
    },
    {
      "epoch": 0.7351643827559843,
      "grad_norm": 1036114.6875,
      "learning_rate": 5.040933798824564e-05,
      "loss": 7.1203,
      "step": 12500
    },
    {
      "epoch": 0.7381050402870082,
      "grad_norm": 557421.0,
      "learning_rate": 4.936164509413134e-05,
      "loss": 7.1524,
      "step": 12550
    },
    {
      "epoch": 0.7410456978180321,
      "grad_norm": 313783.0,
      "learning_rate": 4.832280592562599e-05,
      "loss": 7.1294,
      "step": 12600
    },
    {
      "epoch": 0.7410456978180321,
      "eval_accuracy": 0.04263103774583989,
      "eval_loss": 7.098153114318848,
      "eval_runtime": 3.9246,
      "eval_samples_per_second": 36.437,
      "eval_steps_per_second": 2.293,
      "step": 12600
    },
    {
      "epoch": 0.743986355349056,
      "grad_norm": 165524.515625,
      "learning_rate": 4.729291187529012e-05,
      "loss": 7.1523,
      "step": 12650
    },
    {
      "epoch": 0.74692701288008,
      "grad_norm": 888472.125,
      "learning_rate": 4.6272053548731794e-05,
      "loss": 7.1165,
      "step": 12700
    },
    {
      "epoch": 0.7498676704111039,
      "grad_norm": 465378.71875,
      "learning_rate": 4.5260320756635144e-05,
      "loss": 7.1437,
      "step": 12750
    },
    {
      "epoch": 0.7528083279421278,
      "grad_norm": 1001692.875,
      "learning_rate": 4.4257802506859366e-05,
      "loss": 7.1278,
      "step": 12800
    },
    {
      "epoch": 0.7528083279421278,
      "eval_accuracy": 0.042009285292138245,
      "eval_loss": 7.11345100402832,
      "eval_runtime": 3.9359,
      "eval_samples_per_second": 36.333,
      "eval_steps_per_second": 2.287,
      "step": 12800
    },
    {
      "epoch": 0.7557489854731518,
      "grad_norm": 338825.34375,
      "learning_rate": 4.326458699660842e-05,
      "loss": 7.1618,
      "step": 12850
    },
    {
      "epoch": 0.7586896430041757,
      "grad_norm": 323736.21875,
      "learning_rate": 4.228076160467145e-05,
      "loss": 7.2294,
      "step": 12900
    },
    {
      "epoch": 0.7616303005351996,
      "grad_norm": 213195.421875,
      "learning_rate": 4.13064128837358e-05,
      "loss": 7.2787,
      "step": 12950
    },
    {
      "epoch": 0.7645709580662237,
      "grad_norm": 1126762.5,
      "learning_rate": 4.034162655277234e-05,
      "loss": 7.3391,
      "step": 13000
    },
    {
      "epoch": 0.7645709580662237,
      "eval_accuracy": 0.04091951038702382,
      "eval_loss": 7.323109149932861,
      "eval_runtime": 3.9305,
      "eval_samples_per_second": 36.382,
      "eval_steps_per_second": 2.29,
      "step": 13000
    },
    {
      "epoch": 0.7675116155972476,
      "grad_norm": 5611969.5,
      "learning_rate": 3.9386487489494666e-05,
      "loss": 7.3762,
      "step": 13050
    },
    {
      "epoch": 0.7704522731282715,
      "grad_norm": 16052579.0,
      "learning_rate": 3.8441079722891374e-05,
      "loss": 7.5076,
      "step": 13100
    },
    {
      "epoch": 0.7733929306592954,
      "grad_norm": 52414968.0,
      "learning_rate": 3.750548642583389e-05,
      "loss": 7.7231,
      "step": 13150
    },
    {
      "epoch": 0.7763335881903194,
      "grad_norm": 183065120.0,
      "learning_rate": 3.657978990775916e-05,
      "loss": 7.9572,
      "step": 13200
    },
    {
      "epoch": 0.7763335881903194,
      "eval_accuracy": 0.032324295147939504,
      "eval_loss": 8.07272720336914,
      "eval_runtime": 3.9137,
      "eval_samples_per_second": 36.539,
      "eval_steps_per_second": 2.3,
      "step": 13200
    },
    {
      "epoch": 0.7792742457213433,
      "grad_norm": 172619008.0,
      "learning_rate": 3.566407160742866e-05,
      "loss": 8.1997,
      "step": 13250
    },
    {
      "epoch": 0.7822149032523672,
      "grad_norm": 139954576.0,
      "learning_rate": 3.475841208576338e-05,
      "loss": 8.4257,
      "step": 13300
    },
    {
      "epoch": 0.7851555607833912,
      "grad_norm": 219859600.0,
      "learning_rate": 3.3862891018756704e-05,
      "loss": 8.8987,
      "step": 13350
    },
    {
      "epoch": 0.7880962183144151,
      "grad_norm": 127043848.0,
      "learning_rate": 3.2977587190464844e-05,
      "loss": 9.1295,
      "step": 13400
    },
    {
      "epoch": 0.7880962183144151,
      "eval_accuracy": 0.023182484345161434,
      "eval_loss": 9.218737602233887,
      "eval_runtime": 3.9187,
      "eval_samples_per_second": 36.492,
      "eval_steps_per_second": 2.297,
      "step": 13400
    },
    {
      "epoch": 0.791036875845439,
      "grad_norm": 101100952.0,
      "learning_rate": 3.2102578486075616e-05,
      "loss": 9.3192,
      "step": 13450
    },
    {
      "epoch": 0.7939775333764629,
      "grad_norm": 95416920.0,
      "learning_rate": 3.1237941885056534e-05,
      "loss": 9.4347,
      "step": 13500
    },
    {
      "epoch": 0.796918190907487,
      "grad_norm": 160398896.0,
      "learning_rate": 3.0383753454382486e-05,
      "loss": 9.4549,
      "step": 13550
    },
    {
      "epoch": 0.7998588484385108,
      "grad_norm": 132799264.0,
      "learning_rate": 2.9540088341843764e-05,
      "loss": 9.466,
      "step": 13600
    },
    {
      "epoch": 0.7998588484385108,
      "eval_accuracy": 0.02215761766323564,
      "eval_loss": 9.45061206817627,
      "eval_runtime": 3.9127,
      "eval_samples_per_second": 36.548,
      "eval_steps_per_second": 2.3,
      "step": 13600
    },
    {
      "epoch": 0.8027995059695348,
      "grad_norm": 144745888.0,
      "learning_rate": 2.870702076943472e-05,
      "loss": 9.4501,
      "step": 13650
    },
    {
      "epoch": 0.8057401635005588,
      "grad_norm": 126595416.0,
      "learning_rate": 2.78846240268241e-05,
      "loss": 9.4225,
      "step": 13700
    },
    {
      "epoch": 0.8086808210315827,
      "grad_norm": 160377632.0,
      "learning_rate": 2.707297046490753e-05,
      "loss": 9.4074,
      "step": 13750
    },
    {
      "epoch": 0.8116214785626066,
      "grad_norm": 148845968.0,
      "learning_rate": 2.627213148944205e-05,
      "loss": 9.3831,
      "step": 13800
    },
    {
      "epoch": 0.8116214785626066,
      "eval_accuracy": 0.022547067002367444,
      "eval_loss": 9.353408813476562,
      "eval_runtime": 3.9225,
      "eval_samples_per_second": 36.456,
      "eval_steps_per_second": 2.294,
      "step": 13800
    },
    {
      "epoch": 0.8145621360936305,
      "grad_norm": 207581456.0,
      "learning_rate": 2.5482177554764376e-05,
      "loss": 9.3514,
      "step": 13850
    },
    {
      "epoch": 0.8175027936246545,
      "grad_norm": 154011264.0,
      "learning_rate": 2.4703178157592656e-05,
      "loss": 9.3221,
      "step": 13900
    },
    {
      "epoch": 0.8204434511556784,
      "grad_norm": 194444000.0,
      "learning_rate": 2.3935201830912376e-05,
      "loss": 9.2914,
      "step": 13950
    },
    {
      "epoch": 0.8233841086867023,
      "grad_norm": 232315536.0,
      "learning_rate": 2.317831613794705e-05,
      "loss": 9.2679,
      "step": 14000
    },
    {
      "epoch": 0.8233841086867023,
      "eval_accuracy": 0.02339087390381968,
      "eval_loss": 9.24087142944336,
      "eval_runtime": 3.9113,
      "eval_samples_per_second": 36.561,
      "eval_steps_per_second": 2.301,
      "step": 14000
    },
    {
      "epoch": 0.8263247662177263,
      "grad_norm": 254274560.0,
      "learning_rate": 2.2432587666214412e-05,
      "loss": 9.2441,
      "step": 14050
    },
    {
      "epoch": 0.8292654237487502,
      "grad_norm": 175799088.0,
      "learning_rate": 2.1698082021668284e-05,
      "loss": 9.2287,
      "step": 14100
    },
    {
      "epoch": 0.8322060812797741,
      "grad_norm": 207530832.0,
      "learning_rate": 2.097486382292697e-05,
      "loss": 9.2189,
      "step": 14150
    },
    {
      "epoch": 0.835146738810798,
      "grad_norm": 263935104.0,
      "learning_rate": 2.0262996695588157e-05,
      "loss": 9.1907,
      "step": 14200
    },
    {
      "epoch": 0.835146738810798,
      "eval_accuracy": 0.02365050679657421,
      "eval_loss": 9.171991348266602,
      "eval_runtime": 3.9286,
      "eval_samples_per_second": 36.4,
      "eval_steps_per_second": 2.291,
      "step": 14200
    },
    {
      "epoch": 0.838087396341822,
      "grad_norm": 232441568.0,
      "learning_rate": 1.95625432666316e-05,
      "loss": 9.1657,
      "step": 14250
    },
    {
      "epoch": 0.841028053872846,
      "grad_norm": 241352720.0,
      "learning_rate": 1.8873565158909475e-05,
      "loss": 9.169,
      "step": 14300
    },
    {
      "epoch": 0.8439687114038699,
      "grad_norm": 288623456.0,
      "learning_rate": 1.819612298572492e-05,
      "loss": 9.1352,
      "step": 14350
    },
    {
      "epoch": 0.8469093689348939,
      "grad_norm": 301159712.0,
      "learning_rate": 1.7530276345499618e-05,
      "loss": 9.119,
      "step": 14400
    },
    {
      "epoch": 0.8469093689348939,
      "eval_accuracy": 0.024173188804356368,
      "eval_loss": 9.121910095214844,
      "eval_runtime": 3.9075,
      "eval_samples_per_second": 36.596,
      "eval_steps_per_second": 2.303,
      "step": 14400
    },
    {
      "epoch": 0.8498500264659178,
      "grad_norm": 214644992.0,
      "learning_rate": 1.6876083816530694e-05,
      "loss": 9.1166,
      "step": 14450
    },
    {
      "epoch": 0.8527906839969417,
      "grad_norm": 341626944.0,
      "learning_rate": 1.6233602951837088e-05,
      "loss": 9.1063,
      "step": 14500
    },
    {
      "epoch": 0.8557313415279657,
      "grad_norm": 310530112.0,
      "learning_rate": 1.5602890274096354e-05,
      "loss": 9.1071,
      "step": 14550
    },
    {
      "epoch": 0.8586719990589896,
      "grad_norm": 270962176.0,
      "learning_rate": 1.4984001270672008e-05,
      "loss": 9.1,
      "step": 14600
    },
    {
      "epoch": 0.8586719990589896,
      "eval_accuracy": 0.023893058577963318,
      "eval_loss": 9.086315155029297,
      "eval_runtime": 3.9564,
      "eval_samples_per_second": 36.144,
      "eval_steps_per_second": 2.275,
      "step": 14600
    },
    {
      "epoch": 0.8616126565900135,
      "grad_norm": 309526880.0,
      "learning_rate": 1.4376990388732162e-05,
      "loss": 9.085,
      "step": 14650
    },
    {
      "epoch": 0.8645533141210374,
      "grad_norm": 244721328.0,
      "learning_rate": 1.3781911030459208e-05,
      "loss": 9.0551,
      "step": 14700
    },
    {
      "epoch": 0.8674939716520614,
      "grad_norm": 310056032.0,
      "learning_rate": 1.3198815548351933e-05,
      "loss": 9.0628,
      "step": 14750
    },
    {
      "epoch": 0.8704346291830853,
      "grad_norm": 257779184.0,
      "learning_rate": 1.262775524061973e-05,
      "loss": 9.0651,
      "step": 14800
    },
    {
      "epoch": 0.8704346291830853,
      "eval_accuracy": 0.02416977258208328,
      "eval_loss": 9.036436080932617,
      "eval_runtime": 3.9351,
      "eval_samples_per_second": 36.339,
      "eval_steps_per_second": 2.287,
      "step": 14800
    },
    {
      "epoch": 0.8733752867141092,
      "grad_norm": 199118656.0,
      "learning_rate": 1.2068780346669637e-05,
      "loss": 9.0357,
      "step": 14850
    },
    {
      "epoch": 0.8763159442451333,
      "grad_norm": 220110864.0,
      "learning_rate": 1.1521940042686361e-05,
      "loss": 9.0239,
      "step": 14900
    },
    {
      "epoch": 0.8792566017761572,
      "grad_norm": 313539840.0,
      "learning_rate": 1.0987282437306061e-05,
      "loss": 9.0207,
      "step": 14950
    },
    {
      "epoch": 0.8821972593071811,
      "grad_norm": 203632048.0,
      "learning_rate": 1.0464854567384062e-05,
      "loss": 9.0083,
      "step": 15000
    },
    {
      "epoch": 0.8821972593071811,
      "eval_accuracy": 0.024446486586203246,
      "eval_loss": 9.012503623962402,
      "eval_runtime": 3.9564,
      "eval_samples_per_second": 36.144,
      "eval_steps_per_second": 2.275,
      "step": 15000
    },
    {
      "epoch": 0.885137916838205,
      "grad_norm": 242012848.0,
      "learning_rate": 9.95470239385654e-06,
      "loss": 9.0147,
      "step": 15050
    },
    {
      "epoch": 0.888078574369229,
      "grad_norm": 288636864.0,
      "learning_rate": 9.456870797697246e-06,
      "loss": 8.9909,
      "step": 15100
    },
    {
      "epoch": 0.8910192319002529,
      "grad_norm": 235122160.0,
      "learning_rate": 8.97140357596896e-06,
      "loss": 8.9934,
      "step": 15150
    },
    {
      "epoch": 0.8939598894312768,
      "grad_norm": 289890656.0,
      "learning_rate": 8.498343437970561e-06,
      "loss": 8.9872,
      "step": 15200
    },
    {
      "epoch": 0.8939598894312768,
      "eval_accuracy": 0.02461046525531137,
      "eval_loss": 8.982064247131348,
      "eval_runtime": 3.9242,
      "eval_samples_per_second": 36.44,
      "eval_steps_per_second": 2.293,
      "step": 15200
    },
    {
      "epoch": 0.8969005469623008,
      "grad_norm": 267333680.0,
      "learning_rate": 8.03773200147949e-06,
      "loss": 8.9855,
      "step": 15250
    },
    {
      "epoch": 0.8998412044933247,
      "grad_norm": 242229984.0,
      "learning_rate": 7.589609789090478e-06,
      "loss": 8.9901,
      "step": 15300
    },
    {
      "epoch": 0.9027818620243486,
      "grad_norm": 198514560.0,
      "learning_rate": 7.154016224650544e-06,
      "loss": 8.9749,
      "step": 15350
    },
    {
      "epoch": 0.9057225195553725,
      "grad_norm": 275348448.0,
      "learning_rate": 6.730989629790656e-06,
      "loss": 8.9692,
      "step": 15400
    },
    {
      "epoch": 0.9057225195553725,
      "eval_accuracy": 0.02480860614715036,
      "eval_loss": 8.96341609954834,
      "eval_runtime": 3.9271,
      "eval_samples_per_second": 36.413,
      "eval_steps_per_second": 2.292,
      "step": 15400
    },
    {
      "epoch": 0.9086631770863965,
      "grad_norm": 157574048.0,
      "learning_rate": 6.320567220554329e-06,
      "loss": 8.9696,
      "step": 15450
    },
    {
      "epoch": 0.9116038346174204,
      "grad_norm": 205191024.0,
      "learning_rate": 5.922785104123523e-06,
      "loss": 8.9649,
      "step": 15500
    },
    {
      "epoch": 0.9145444921484444,
      "grad_norm": 278717824.0,
      "learning_rate": 5.537678275642171e-06,
      "loss": 8.9576,
      "step": 15550
    },
    {
      "epoch": 0.9174851496794684,
      "grad_norm": 178282960.0,
      "learning_rate": 5.1652806151373235e-06,
      "loss": 8.9409,
      "step": 15600
    },
    {
      "epoch": 0.9174851496794684,
      "eval_accuracy": 0.02511264992945501,
      "eval_loss": 8.944236755371094,
      "eval_runtime": 3.9248,
      "eval_samples_per_second": 36.435,
      "eval_steps_per_second": 2.293,
      "step": 15600
    },
    {
      "epoch": 0.9204258072104923,
      "grad_norm": 241314784.0,
      "learning_rate": 4.805624884538634e-06,
      "loss": 8.9482,
      "step": 15650
    },
    {
      "epoch": 0.9233664647415162,
      "grad_norm": 161357040.0,
      "learning_rate": 4.458742724796061e-06,
      "loss": 8.9406,
      "step": 15700
    },
    {
      "epoch": 0.9263071222725402,
      "grad_norm": 229268352.0,
      "learning_rate": 4.124664653096299e-06,
      "loss": 8.9466,
      "step": 15750
    },
    {
      "epoch": 0.9292477798035641,
      "grad_norm": 234791840.0,
      "learning_rate": 3.803420060177892e-06,
      "loss": 8.9501,
      "step": 15800
    },
    {
      "epoch": 0.9292477798035641,
      "eval_accuracy": 0.025105817484908838,
      "eval_loss": 8.938891410827637,
      "eval_runtime": 3.9354,
      "eval_samples_per_second": 36.337,
      "eval_steps_per_second": 2.287,
      "step": 15800
    },
    {
      "epoch": 0.932188437334588,
      "grad_norm": 235857120.0,
      "learning_rate": 3.4950372077456325e-06,
      "loss": 8.9345,
      "step": 15850
    },
    {
      "epoch": 0.9351290948656119,
      "grad_norm": 253048176.0,
      "learning_rate": 3.1995432259842523e-06,
      "loss": 8.9345,
      "step": 15900
    },
    {
      "epoch": 0.9380697523966359,
      "grad_norm": 263357280.0,
      "learning_rate": 2.916964111171566e-06,
      "loss": 8.931,
      "step": 15950
    },
    {
      "epoch": 0.9410104099276598,
      "grad_norm": 160459856.0,
      "learning_rate": 2.647324723391481e-06,
      "loss": 8.9436,
      "step": 16000
    },
    {
      "epoch": 0.9410104099276598,
      "eval_accuracy": 0.025160477041278214,
      "eval_loss": 8.916460990905762,
      "eval_runtime": 3.9282,
      "eval_samples_per_second": 36.403,
      "eval_steps_per_second": 2.291,
      "step": 16000
    },
    {
      "epoch": 0.9439510674586837,
      "grad_norm": 224277056.0,
      "learning_rate": 2.3906487843468324e-06,
      "loss": 8.9282,
      "step": 16050
    },
    {
      "epoch": 0.9468917249897078,
      "grad_norm": 201774976.0,
      "learning_rate": 2.146958875272586e-06,
      "loss": 8.9178,
      "step": 16100
    },
    {
      "epoch": 0.9498323825207317,
      "grad_norm": 184523712.0,
      "learning_rate": 1.9162764349491098e-06,
      "loss": 8.9153,
      "step": 16150
    },
    {
      "epoch": 0.9527730400517556,
      "grad_norm": 148716448.0,
      "learning_rate": 1.6986217578161154e-06,
      "loss": 8.9253,
      "step": 16200
    },
    {
      "epoch": 0.9527730400517556,
      "eval_accuracy": 0.02520488793082833,
      "eval_loss": 8.907922744750977,
      "eval_runtime": 3.9253,
      "eval_samples_per_second": 36.43,
      "eval_steps_per_second": 2.293,
      "step": 16200
    },
    {
      "epoch": 0.9557136975827795,
      "grad_norm": 425687712.0,
      "learning_rate": 1.4940139921873374e-06,
      "loss": 8.8987,
      "step": 16250
    },
    {
      "epoch": 0.9586543551138035,
      "grad_norm": 168902992.0,
      "learning_rate": 1.3024711385658137e-06,
      "loss": 8.907,
      "step": 16300
    },
    {
      "epoch": 0.9615950126448274,
      "grad_norm": 219051888.0,
      "learning_rate": 1.1240100480603197e-06,
      "loss": 8.9161,
      "step": 16350
    },
    {
      "epoch": 0.9645356701758513,
      "grad_norm": 152615920.0,
      "learning_rate": 9.586464209029533e-07,
      "loss": 8.9146,
      "step": 16400
    },
    {
      "epoch": 0.9645356701758513,
      "eval_accuracy": 0.0249691685939854,
      "eval_loss": 8.912444114685059,
      "eval_runtime": 3.9271,
      "eval_samples_per_second": 36.413,
      "eval_steps_per_second": 2.292,
      "step": 16400
    },
    {
      "epoch": 0.9674763277068753,
      "grad_norm": 165484480.0,
      "learning_rate": 8.06394805067806e-07,
      "loss": 8.9162,
      "step": 16450
    },
    {
      "epoch": 0.9704169852378992,
      "grad_norm": 207351536.0,
      "learning_rate": 6.672685949911383e-07,
      "loss": 8.9201,
      "step": 16500
    },
    {
      "epoch": 0.9733576427689231,
      "grad_norm": 200277024.0,
      "learning_rate": 5.41280030392971e-07,
      "loss": 8.9109,
      "step": 16550
    },
    {
      "epoch": 0.976298300299947,
      "grad_norm": 246790416.0,
      "learning_rate": 4.284401952003469e-07,
      "loss": 8.9241,
      "step": 16600
    },
    {
      "epoch": 0.976298300299947,
      "eval_accuracy": 0.024709535701230866,
      "eval_loss": 8.914315223693848,
      "eval_runtime": 3.9307,
      "eval_samples_per_second": 36.38,
      "eval_steps_per_second": 2.29,
      "step": 16600
    },
    {
      "epoch": 0.979238957830971,
      "grad_norm": 153213984.0,
      "learning_rate": 3.287590165721443e-07,
      "loss": 8.9198,
      "step": 16650
    },
    {
      "epoch": 0.9821796153619949,
      "grad_norm": 177774000.0,
      "learning_rate": 2.422452640257422e-07,
      "loss": 8.9359,
      "step": 16700
    },
    {
      "epoch": 0.9851202728930188,
      "grad_norm": 165472480.0,
      "learning_rate": 1.6890654866555386e-07,
      "loss": 8.9198,
      "step": 16750
    },
    {
      "epoch": 0.9880609304240429,
      "grad_norm": 215881520.0,
      "learning_rate": 1.0874932251339619e-07,
      "loss": 8.9086,
      "step": 16800
    },
    {
      "epoch": 0.9880609304240429,
      "eval_accuracy": 0.024658292367134575,
      "eval_loss": 8.91506576538086,
      "eval_runtime": 3.9344,
      "eval_samples_per_second": 36.346,
      "eval_steps_per_second": 2.288,
      "step": 16800
    },
    {
      "epoch": 0.9910015879550668,
      "grad_norm": 261960352.0,
      "learning_rate": 6.177887794091008e-08,
      "loss": 8.9205,
      "step": 16850
    },
    {
      "epoch": 0.9939422454860907,
      "grad_norm": 219282256.0,
      "learning_rate": 2.7999347203899736e-08,
      "loss": 8.9249,
      "step": 16900
    },
    {
      "epoch": 0.9968829030171146,
      "grad_norm": 156571472.0,
      "learning_rate": 7.4137020788567205e-09,
      "loss": 8.9175,
      "step": 16950
    },
    {
      "epoch": 0.9998235605481386,
      "grad_norm": 297398112.0,
      "learning_rate": 2.3753601485765327e-11,
      "loss": 8.9255,
      "step": 17000
    },
    {
      "epoch": 0.9998235605481386,
      "eval_accuracy": 0.024661708589407663,
      "eval_loss": 8.915322303771973,
      "eval_runtime": 3.9299,
      "eval_samples_per_second": 36.388,
      "eval_steps_per_second": 2.29,
      "step": 17000
    },
    {
      "epoch": 1.0,
      "step": 17003,
      "total_flos": 2.94794351345664e+16,
      "train_loss": 7.508884244839289,
      "train_runtime": 3961.0214,
      "train_samples_per_second": 17.17,
      "train_steps_per_second": 4.293
    }
  ],
  "logging_steps": 50,
  "max_steps": 17003,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.94794351345664e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
