{
  "best_metric": 3.381749391555786,
  "best_model_checkpoint": "outputs/my-llama-tiny_linear-2025-07-09-02/checkpoint-8400",
  "epoch": 0.9880028228652082,
  "eval_steps": 200,
  "global_step": 8400,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.005880969183721477,
      "grad_norm": 2.277846097946167,
      "learning_rate": 0.0001171875,
      "loss": 10.3591,
      "step": 50
    },
    {
      "epoch": 0.011761938367442954,
      "grad_norm": 0.3823238015174866,
      "learning_rate": 0.000234375,
      "loss": 7.6395,
      "step": 100
    },
    {
      "epoch": 0.017642907551164433,
      "grad_norm": 0.422933965921402,
      "learning_rate": 0.00029999489097542206,
      "loss": 7.1221,
      "step": 150
    },
    {
      "epoch": 0.023523876734885908,
      "grad_norm": 0.519098162651062,
      "learning_rate": 0.0002999452815631394,
      "loss": 7.1024,
      "step": 200
    },
    {
      "epoch": 0.023523876734885908,
      "eval_accuracy": 0.04243972929854708,
      "eval_loss": 7.078150749206543,
      "eval_runtime": 2.7277,
      "eval_samples_per_second": 52.426,
      "eval_steps_per_second": 3.3,
      "step": 200
    },
    {
      "epoch": 0.029404845918607387,
      "grad_norm": 0.38232943415641785,
      "learning_rate": 0.00029984291347213656,
      "loss": 7.1242,
      "step": 250
    },
    {
      "epoch": 0.035285815102328866,
      "grad_norm": 0.4818122088909149,
      "learning_rate": 0.0002996878227209207,
      "loss": 7.1167,
      "step": 300
    },
    {
      "epoch": 0.04116678428605034,
      "grad_norm": 0.5675044059753418,
      "learning_rate": 0.0002994800638786191,
      "loss": 7.0977,
      "step": 350
    },
    {
      "epoch": 0.047047753469771816,
      "grad_norm": 0.3894651234149933,
      "learning_rate": 0.00029921971004577796,
      "loss": 7.0887,
      "step": 400
    },
    {
      "epoch": 0.047047753469771816,
      "eval_accuracy": 0.041824809289391605,
      "eval_loss": 7.058218955993652,
      "eval_runtime": 2.7107,
      "eval_samples_per_second": 52.754,
      "eval_steps_per_second": 3.32,
      "step": 400
    },
    {
      "epoch": 0.0529287226534933,
      "grad_norm": 0.380887508392334,
      "learning_rate": 0.00029890685282864244,
      "loss": 7.0887,
      "step": 450
    },
    {
      "epoch": 0.058809691837214774,
      "grad_norm": 0.4016035497188568,
      "learning_rate": 0.0002985416023069246,
      "loss": 7.0797,
      "step": 500
    },
    {
      "epoch": 0.06469066102093625,
      "grad_norm": 0.38568001985549927,
      "learning_rate": 0.0002981240869950713,
      "loss": 7.0681,
      "step": 550
    },
    {
      "epoch": 0.07057163020465773,
      "grad_norm": 13.538993835449219,
      "learning_rate": 0.00029765445379704617,
      "loss": 7.0482,
      "step": 600
    },
    {
      "epoch": 0.07057163020465773,
      "eval_accuracy": 0.04475592799969937,
      "eval_loss": 7.031973838806152,
      "eval_runtime": 2.7109,
      "eval_samples_per_second": 52.751,
      "eval_steps_per_second": 3.32,
      "step": 600
    },
    {
      "epoch": 0.0764525993883792,
      "grad_norm": 0.46375134587287903,
      "learning_rate": 0.0002971328679546412,
      "loss": 7.0634,
      "step": 650
    },
    {
      "epoch": 0.08233356857210068,
      "grad_norm": 0.370964914560318,
      "learning_rate": 0.00029655951298933564,
      "loss": 7.0374,
      "step": 700
    },
    {
      "epoch": 0.08821453775582216,
      "grad_norm": 0.44534680247306824,
      "learning_rate": 0.0002959345906377236,
      "loss": 7.0436,
      "step": 750
    },
    {
      "epoch": 0.09409550693954363,
      "grad_norm": 0.3908637762069702,
      "learning_rate": 0.0002952583207805324,
      "loss": 7.0739,
      "step": 800
    },
    {
      "epoch": 0.09409550693954363,
      "eval_accuracy": 0.044837917334253435,
      "eval_loss": 7.004795074462891,
      "eval_runtime": 2.7124,
      "eval_samples_per_second": 52.721,
      "eval_steps_per_second": 3.318,
      "step": 800
    },
    {
      "epoch": 0.09997647612326512,
      "grad_norm": 0.35703760385513306,
      "learning_rate": 0.0002945309413652571,
      "loss": 7.0365,
      "step": 850
    },
    {
      "epoch": 0.1058574453069866,
      "grad_norm": 0.4226517081260681,
      "learning_rate": 0.00029375270832243753,
      "loss": 7.0243,
      "step": 900
    },
    {
      "epoch": 0.11173841449070807,
      "grad_norm": 0.43501025438308716,
      "learning_rate": 0.0002929238954756089,
      "loss": 7.005,
      "step": 950
    },
    {
      "epoch": 0.11761938367442955,
      "grad_norm": 0.39458566904067993,
      "learning_rate": 0.00029204479444495593,
      "loss": 7.0342,
      "step": 1000
    },
    {
      "epoch": 0.11761938367442955,
      "eval_accuracy": 0.04731126225996768,
      "eval_loss": 6.979305267333984,
      "eval_runtime": 3.5577,
      "eval_samples_per_second": 40.194,
      "eval_steps_per_second": 2.53,
      "step": 1000
    },
    {
      "epoch": 0.12350035285815103,
      "grad_norm": 0.3491083085536957,
      "learning_rate": 0.00029111571454470546,
      "loss": 7.0166,
      "step": 1050
    },
    {
      "epoch": 0.1293813220418725,
      "grad_norm": 0.4440600275993347,
      "learning_rate": 0.0002901369826742934,
      "loss": 7.0075,
      "step": 1100
    },
    {
      "epoch": 0.13526229122559397,
      "grad_norm": 0.3608132004737854,
      "learning_rate": 0.00028910894320334426,
      "loss": 7.0061,
      "step": 1150
    },
    {
      "epoch": 0.14114326040931546,
      "grad_norm": 0.5422120094299316,
      "learning_rate": 0.0002880319578505037,
      "loss": 7.0082,
      "step": 1200
    },
    {
      "epoch": 0.14114326040931546,
      "eval_accuracy": 0.04648453646988088,
      "eval_loss": 6.971288204193115,
      "eval_runtime": 2.7085,
      "eval_samples_per_second": 52.796,
      "eval_steps_per_second": 3.323,
      "step": 1200
    },
    {
      "epoch": 0.14702422959303693,
      "grad_norm": 0.4581961929798126,
      "learning_rate": 0.0002869064055561664,
      "loss": 6.9985,
      "step": 1250
    },
    {
      "epoch": 0.1529051987767584,
      "grad_norm": 0.5713799595832825,
      "learning_rate": 0.0002857326823491458,
      "loss": 7.0059,
      "step": 1300
    },
    {
      "epoch": 0.1587861679604799,
      "grad_norm": 0.4631884694099426,
      "learning_rate": 0.0002845112012073289,
      "loss": 7.0031,
      "step": 1350
    },
    {
      "epoch": 0.16466713714420136,
      "grad_norm": 0.34473916888237,
      "learning_rate": 0.00028324239191236975,
      "loss": 7.0008,
      "step": 1400
    },
    {
      "epoch": 0.16466713714420136,
      "eval_accuracy": 0.04658360691580037,
      "eval_loss": 6.959836959838867,
      "eval_runtime": 2.7071,
      "eval_samples_per_second": 52.824,
      "eval_steps_per_second": 3.325,
      "step": 1400
    },
    {
      "epoch": 0.17054810632792283,
      "grad_norm": 0.3799422085285187,
      "learning_rate": 0.00028192670089846936,
      "loss": 6.9855,
      "step": 1450
    },
    {
      "epoch": 0.17642907551164433,
      "grad_norm": 0.4217253625392914,
      "learning_rate": 0.0002805645910952961,
      "loss": 7.015,
      "step": 1500
    },
    {
      "epoch": 0.1823100446953658,
      "grad_norm": 0.38651809096336365,
      "learning_rate": 0.0002791565417651033,
      "loss": 6.9656,
      "step": 1550
    },
    {
      "epoch": 0.18819101387908727,
      "grad_norm": 0.4355747103691101,
      "learning_rate": 0.00027770304833409873,
      "loss": 6.9897,
      "step": 1600
    },
    {
      "epoch": 0.18819101387908727,
      "eval_accuracy": 0.04546650223250125,
      "eval_loss": 6.9474711418151855,
      "eval_runtime": 2.7036,
      "eval_samples_per_second": 52.893,
      "eval_steps_per_second": 3.329,
      "step": 1600
    },
    {
      "epoch": 0.19407198306280876,
      "grad_norm": 0.37561044096946716,
      "learning_rate": 0.0002762046222181279,
      "loss": 6.9667,
      "step": 1650
    },
    {
      "epoch": 0.19995295224653023,
      "grad_norm": 0.45090383291244507,
      "learning_rate": 0.00027466179064273075,
      "loss": 6.9794,
      "step": 1700
    },
    {
      "epoch": 0.2058339214302517,
      "grad_norm": 0.3569137454032898,
      "learning_rate": 0.000273075096457636,
      "loss": 6.9704,
      "step": 1750
    },
    {
      "epoch": 0.2117148906139732,
      "grad_norm": 0.35646724700927734,
      "learning_rate": 0.0002714450979457576,
      "loss": 7.0023,
      "step": 1800
    },
    {
      "epoch": 0.2117148906139732,
      "eval_accuracy": 0.045100966449281056,
      "eval_loss": 6.939759731292725,
      "eval_runtime": 2.7027,
      "eval_samples_per_second": 52.91,
      "eval_steps_per_second": 3.33,
      "step": 1800
    },
    {
      "epoch": 0.21759585979769466,
      "grad_norm": 0.44813746213912964,
      "learning_rate": 0.0002697723686267616,
      "loss": 6.9529,
      "step": 1850
    },
    {
      "epoch": 0.22347682898141613,
      "grad_norm": 0.4368535280227661,
      "learning_rate": 0.00026805749705527144,
      "loss": 6.9734,
      "step": 1900
    },
    {
      "epoch": 0.22935779816513763,
      "grad_norm": 0.4684351086616516,
      "learning_rate": 0.0002663010866137833,
      "loss": 6.9717,
      "step": 1950
    },
    {
      "epoch": 0.2352387673488591,
      "grad_norm": 0.3510397970676422,
      "learning_rate": 0.0002645037553003645,
      "loss": 6.9771,
      "step": 2000
    },
    {
      "epoch": 0.2352387673488591,
      "eval_accuracy": 0.04423324599191722,
      "eval_loss": 6.934809684753418,
      "eval_runtime": 2.7081,
      "eval_samples_per_second": 52.804,
      "eval_steps_per_second": 3.323,
      "step": 2000
    },
    {
      "epoch": 0.24111973653258056,
      "grad_norm": 0.35753679275512695,
      "learning_rate": 0.0002626661355112085,
      "loss": 6.9809,
      "step": 2050
    },
    {
      "epoch": 0.24700070571630206,
      "grad_norm": 0.389653742313385,
      "learning_rate": 0.0002607888738181251,
      "loss": 6.971,
      "step": 2100
    },
    {
      "epoch": 0.2528816749000235,
      "grad_norm": 0.3776067793369293,
      "learning_rate": 0.00025887263074104213,
      "loss": 6.9726,
      "step": 2150
    },
    {
      "epoch": 0.258762644083745,
      "grad_norm": 0.36765819787979126,
      "learning_rate": 0.0002569180805155993,
      "loss": 6.9665,
      "step": 2200
    },
    {
      "epoch": 0.258762644083745,
      "eval_accuracy": 0.04651186624806557,
      "eval_loss": 6.931105136871338,
      "eval_runtime": 2.7105,
      "eval_samples_per_second": 52.758,
      "eval_steps_per_second": 3.32,
      "step": 2200
    },
    {
      "epoch": 0.2646436132674665,
      "grad_norm": 0.4190370440483093,
      "learning_rate": 0.0002549259108559168,
      "loss": 6.9668,
      "step": 2250
    },
    {
      "epoch": 0.27052458245118793,
      "grad_norm": 0.43480807542800903,
      "learning_rate": 0.00025289682271262113,
      "loss": 6.9654,
      "step": 2300
    },
    {
      "epoch": 0.27640555163490943,
      "grad_norm": 0.41628435254096985,
      "learning_rate": 0.0002508315300262132,
      "loss": 6.9701,
      "step": 2350
    },
    {
      "epoch": 0.2822865208186309,
      "grad_norm": 0.46883201599121094,
      "learning_rate": 0.0002487307594758667,
      "loss": 6.9705,
      "step": 2400
    },
    {
      "epoch": 0.2822865208186309,
      "eval_accuracy": 0.045483583343866686,
      "eval_loss": 6.925139427185059,
      "eval_runtime": 2.7112,
      "eval_samples_per_second": 52.745,
      "eval_steps_per_second": 3.32,
      "step": 2400
    },
    {
      "epoch": 0.28816749000235237,
      "grad_norm": 0.5415472984313965,
      "learning_rate": 0.00024659525022374386,
      "loss": 6.9731,
      "step": 2450
    },
    {
      "epoch": 0.29404845918607386,
      "grad_norm": 0.3048804700374603,
      "learning_rate": 0.000244425753654919,
      "loss": 6.9629,
      "step": 2500
    },
    {
      "epoch": 0.29992942836979536,
      "grad_norm": 0.3482873737812042,
      "learning_rate": 0.0002422230331130017,
      "loss": 6.9606,
      "step": 2550
    },
    {
      "epoch": 0.3058103975535168,
      "grad_norm": 0.358808308839798,
      "learning_rate": 0.00023998786363155198,
      "loss": 6.9432,
      "step": 2600
    },
    {
      "epoch": 0.3058103975535168,
      "eval_accuracy": 0.04426399199237499,
      "eval_loss": 6.9229841232299805,
      "eval_runtime": 2.7042,
      "eval_samples_per_second": 52.881,
      "eval_steps_per_second": 3.328,
      "step": 2600
    },
    {
      "epoch": 0.3116913667372383,
      "grad_norm": 0.42038822174072266,
      "learning_rate": 0.00023772103166138265,
      "loss": 6.9288,
      "step": 2650
    },
    {
      "epoch": 0.3175723359209598,
      "grad_norm": 0.36194613575935364,
      "learning_rate": 0.0002354233347938441,
      "loss": 6.9627,
      "step": 2700
    },
    {
      "epoch": 0.32345330510468123,
      "grad_norm": 0.30251407623291016,
      "learning_rate": 0.00023309558148018996,
      "loss": 6.9285,
      "step": 2750
    },
    {
      "epoch": 0.32933427428840273,
      "grad_norm": 0.431888222694397,
      "learning_rate": 0.00023073859074712068,
      "loss": 6.9481,
      "step": 2800
    },
    {
      "epoch": 0.32933427428840273,
      "eval_accuracy": 0.04615316290939154,
      "eval_loss": 6.90793514251709,
      "eval_runtime": 2.7508,
      "eval_samples_per_second": 51.985,
      "eval_steps_per_second": 3.272,
      "step": 2800
    },
    {
      "epoch": 0.3352152434721242,
      "grad_norm": 0.3632020354270935,
      "learning_rate": 0.00022835319190860683,
      "loss": 6.9376,
      "step": 2850
    },
    {
      "epoch": 0.34109621265584567,
      "grad_norm": 0.39064234495162964,
      "learning_rate": 0.00022594022427409278,
      "loss": 6.9473,
      "step": 2900
    },
    {
      "epoch": 0.34697718183956716,
      "grad_norm": 0.450996071100235,
      "learning_rate": 0.000223500536853183,
      "loss": 6.9245,
      "step": 2950
    },
    {
      "epoch": 0.35285815102328866,
      "grad_norm": 0.35698312520980835,
      "learning_rate": 0.0002210349880569156,
      "loss": 6.9149,
      "step": 3000
    },
    {
      "epoch": 0.35285815102328866,
      "eval_accuracy": 0.046587023138073454,
      "eval_loss": 6.894154071807861,
      "eval_runtime": 2.7088,
      "eval_samples_per_second": 52.791,
      "eval_steps_per_second": 3.322,
      "step": 3000
    },
    {
      "epoch": 0.3587391202070101,
      "grad_norm": 0.3533638119697571,
      "learning_rate": 0.00021854444539572815,
      "loss": 6.9425,
      "step": 3050
    },
    {
      "epoch": 0.3646200893907316,
      "grad_norm": 0.3421465754508972,
      "learning_rate": 0.0002160297851742214,
      "loss": 6.9134,
      "step": 3100
    },
    {
      "epoch": 0.3705010585744531,
      "grad_norm": 0.5919554829597473,
      "learning_rate": 0.00021349189218282914,
      "loss": 6.946,
      "step": 3150
    },
    {
      "epoch": 0.37638202775817453,
      "grad_norm": 0.4360349774360657,
      "learning_rate": 0.00021093165938650208,
      "loss": 6.9246,
      "step": 3200
    },
    {
      "epoch": 0.37638202775817453,
      "eval_accuracy": 0.046494785136700134,
      "eval_loss": 6.895360469818115,
      "eval_runtime": 2.7073,
      "eval_samples_per_second": 52.82,
      "eval_steps_per_second": 3.324,
      "step": 3200
    },
    {
      "epoch": 0.382262996941896,
      "grad_norm": 0.43360623717308044,
      "learning_rate": 0.0002083499876105156,
      "loss": 6.9141,
      "step": 3250
    },
    {
      "epoch": 0.3881439661256175,
      "grad_norm": 0.5125669836997986,
      "learning_rate": 0.00020574778522351167,
      "loss": 6.9171,
      "step": 3300
    },
    {
      "epoch": 0.39402493530933896,
      "grad_norm": 0.3363298177719116,
      "learning_rate": 0.00020312596781788686,
      "loss": 6.9314,
      "step": 3350
    },
    {
      "epoch": 0.39990590449306046,
      "grad_norm": 0.393471896648407,
      "learning_rate": 0.00020048545788763853,
      "loss": 6.9335,
      "step": 3400
    },
    {
      "epoch": 0.39990590449306046,
      "eval_accuracy": 0.04609167090847599,
      "eval_loss": 6.883701324462891,
      "eval_runtime": 2.7165,
      "eval_samples_per_second": 52.641,
      "eval_steps_per_second": 3.313,
      "step": 3400
    },
    {
      "epoch": 0.40578687367678196,
      "grad_norm": 0.3505342900753021,
      "learning_rate": 0.00019782718450378248,
      "loss": 6.9246,
      "step": 3450
    },
    {
      "epoch": 0.4116678428605034,
      "grad_norm": 0.4164898991584778,
      "learning_rate": 0.00019515208298745686,
      "loss": 6.9334,
      "step": 3500
    },
    {
      "epoch": 0.4175488120442249,
      "grad_norm": 0.36528539657592773,
      "learning_rate": 0.00019246109458082668,
      "loss": 6.9211,
      "step": 3550
    },
    {
      "epoch": 0.4234297812279464,
      "grad_norm": 0.39667022228240967,
      "learning_rate": 0.00018975516611590494,
      "loss": 6.9111,
      "step": 3600
    },
    {
      "epoch": 0.4234297812279464,
      "eval_accuracy": 0.04691498047628971,
      "eval_loss": 6.878542423248291,
      "eval_runtime": 2.7194,
      "eval_samples_per_second": 52.585,
      "eval_steps_per_second": 3.31,
      "step": 3600
    },
    {
      "epoch": 0.42931075041166783,
      "grad_norm": 0.37948089838027954,
      "learning_rate": 0.0001870352496814071,
      "loss": 6.9246,
      "step": 3650
    },
    {
      "epoch": 0.4351917195953893,
      "grad_norm": 0.41705918312072754,
      "learning_rate": 0.00018430230228775606,
      "loss": 6.9197,
      "step": 3700
    },
    {
      "epoch": 0.4410726887791108,
      "grad_norm": 0.39701682329177856,
      "learning_rate": 0.00018155728553035513,
      "loss": 6.8951,
      "step": 3750
    },
    {
      "epoch": 0.44695365796283226,
      "grad_norm": 0.2826831638813019,
      "learning_rate": 0.00017880116525124804,
      "loss": 6.906,
      "step": 3800
    },
    {
      "epoch": 0.44695365796283226,
      "eval_accuracy": 0.046935477809928225,
      "eval_loss": 6.875244617462158,
      "eval_runtime": 2.7233,
      "eval_samples_per_second": 52.51,
      "eval_steps_per_second": 3.305,
      "step": 3800
    },
    {
      "epoch": 0.45283462714655376,
      "grad_norm": 0.3501051962375641,
      "learning_rate": 0.00017603491119928444,
      "loss": 6.931,
      "step": 3850
    },
    {
      "epoch": 0.45871559633027525,
      "grad_norm": 0.3594796061515808,
      "learning_rate": 0.0001732594966889113,
      "loss": 6.9319,
      "step": 3900
    },
    {
      "epoch": 0.4645965655139967,
      "grad_norm": 0.38374045491218567,
      "learning_rate": 0.00017047589825770908,
      "loss": 6.9194,
      "step": 3950
    },
    {
      "epoch": 0.4704775346977182,
      "grad_norm": 0.3322746157646179,
      "learning_rate": 0.00016768509532279438,
      "loss": 6.9177,
      "step": 4000
    },
    {
      "epoch": 0.4704775346977182,
      "eval_accuracy": 0.04709262403449018,
      "eval_loss": 6.871311664581299,
      "eval_runtime": 2.7132,
      "eval_samples_per_second": 52.705,
      "eval_steps_per_second": 3.317,
      "step": 4000
    },
    {
      "epoch": 0.4763585038814397,
      "grad_norm": 0.35172247886657715,
      "learning_rate": 0.00016488806983620924,
      "loss": 6.9133,
      "step": 4050
    },
    {
      "epoch": 0.48223947306516113,
      "grad_norm": 0.3921535313129425,
      "learning_rate": 0.0001620858059394183,
      "loss": 6.9085,
      "step": 4100
    },
    {
      "epoch": 0.4881204422488826,
      "grad_norm": 0.32639867067337036,
      "learning_rate": 0.00015927928961703588,
      "loss": 6.9203,
      "step": 4150
    },
    {
      "epoch": 0.4940014114326041,
      "grad_norm": 0.34730926156044006,
      "learning_rate": 0.0001564695083499046,
      "loss": 6.911,
      "step": 4200
    },
    {
      "epoch": 0.4940014114326041,
      "eval_accuracy": 0.04653236358170408,
      "eval_loss": 6.8626275062561035,
      "eval_runtime": 2.7203,
      "eval_samples_per_second": 52.567,
      "eval_steps_per_second": 3.308,
      "step": 4200
    },
    {
      "epoch": 0.49988238061632556,
      "grad_norm": 0.35962149500846863,
      "learning_rate": 0.00015365745076764724,
      "loss": 6.8902,
      "step": 4250
    },
    {
      "epoch": 0.505763349800047,
      "grad_norm": 0.5262112617492676,
      "learning_rate": 0.00015084410630081453,
      "loss": 6.8976,
      "step": 4300
    },
    {
      "epoch": 0.5116443189837685,
      "grad_norm": 0.31624835729599,
      "learning_rate": 0.00014803046483275131,
      "loss": 6.889,
      "step": 4350
    },
    {
      "epoch": 0.51752528816749,
      "grad_norm": 0.3077266812324524,
      "learning_rate": 0.00014521751635130324,
      "loss": 6.8861,
      "step": 4400
    },
    {
      "epoch": 0.51752528816749,
      "eval_accuracy": 0.04766313315409554,
      "eval_loss": 6.857439994812012,
      "eval_runtime": 2.7134,
      "eval_samples_per_second": 52.701,
      "eval_steps_per_second": 3.317,
      "step": 4400
    },
    {
      "epoch": 0.5234062573512115,
      "grad_norm": 0.38677945733070374,
      "learning_rate": 0.0001424062506004864,
      "loss": 6.8698,
      "step": 4450
    },
    {
      "epoch": 0.529287226534933,
      "grad_norm": 0.43642735481262207,
      "learning_rate": 0.00013959765673224358,
      "loss": 6.9251,
      "step": 4500
    },
    {
      "epoch": 0.5351681957186545,
      "grad_norm": 0.31457406282424927,
      "learning_rate": 0.00013679272295840763,
      "loss": 6.8952,
      "step": 4550
    },
    {
      "epoch": 0.5410491649023759,
      "grad_norm": 0.2974764108657837,
      "learning_rate": 0.00013399243620299702,
      "loss": 6.8846,
      "step": 4600
    },
    {
      "epoch": 0.5410491649023759,
      "eval_accuracy": 0.04793301471366933,
      "eval_loss": 6.85120153427124,
      "eval_runtime": 2.7231,
      "eval_samples_per_second": 52.513,
      "eval_steps_per_second": 3.305,
      "step": 4600
    },
    {
      "epoch": 0.5469301340860974,
      "grad_norm": 0.3255169093608856,
      "learning_rate": 0.00013119778175496314,
      "loss": 6.9209,
      "step": 4650
    },
    {
      "epoch": 0.5528111032698189,
      "grad_norm": 0.3370717763900757,
      "learning_rate": 0.00012840974292151395,
      "loss": 6.89,
      "step": 4700
    },
    {
      "epoch": 0.5586920724535404,
      "grad_norm": 0.3293874263763428,
      "learning_rate": 0.00012562930068213445,
      "loss": 6.9034,
      "step": 4750
    },
    {
      "epoch": 0.5645730416372619,
      "grad_norm": 0.29997703433036804,
      "learning_rate": 0.00012285743334342598,
      "loss": 6.9018,
      "step": 4800
    },
    {
      "epoch": 0.5645730416372619,
      "eval_accuracy": 0.047878355157299955,
      "eval_loss": 6.851935386657715,
      "eval_runtime": 2.7155,
      "eval_samples_per_second": 52.66,
      "eval_steps_per_second": 3.314,
      "step": 4800
    },
    {
      "epoch": 0.5704540108209833,
      "grad_norm": 0.30508553981781006,
      "learning_rate": 0.00012009511619488658,
      "loss": 6.874,
      "step": 4850
    },
    {
      "epoch": 0.5763349800047047,
      "grad_norm": 0.3522069752216339,
      "learning_rate": 0.00011734332116575224,
      "loss": 6.8738,
      "step": 4900
    },
    {
      "epoch": 0.5822159491884262,
      "grad_norm": 0.4715452492237091,
      "learning_rate": 0.00011460301648302114,
      "loss": 6.9073,
      "step": 4950
    },
    {
      "epoch": 0.5880969183721477,
      "grad_norm": 0.3305865228176117,
      "learning_rate": 0.00011187516633077986,
      "loss": 6.8692,
      "step": 5000
    },
    {
      "epoch": 0.5880969183721477,
      "eval_accuracy": 0.049740196296131814,
      "eval_loss": 6.821173667907715,
      "eval_runtime": 2.7139,
      "eval_samples_per_second": 52.692,
      "eval_steps_per_second": 3.316,
      "step": 5000
    },
    {
      "epoch": 0.5939778875558692,
      "grad_norm": 0.4578356146812439,
      "learning_rate": 0.00010916073051095276,
      "loss": 6.8252,
      "step": 5050
    },
    {
      "epoch": 0.5998588567395907,
      "grad_norm": 0.7251635193824768,
      "learning_rate": 0.0001064606641055925,
      "loss": 6.4951,
      "step": 5100
    },
    {
      "epoch": 0.6057398259233122,
      "grad_norm": 0.7875744700431824,
      "learning_rate": 0.00010377591714083226,
      "loss": 5.7678,
      "step": 5150
    },
    {
      "epoch": 0.6116207951070336,
      "grad_norm": 1.3583083152770996,
      "learning_rate": 0.00010110743425261563,
      "loss": 5.3156,
      "step": 5200
    },
    {
      "epoch": 0.6116207951070336,
      "eval_accuracy": 0.1907106083950246,
      "eval_loss": 5.164072513580322,
      "eval_runtime": 2.7254,
      "eval_samples_per_second": 52.47,
      "eval_steps_per_second": 3.302,
      "step": 5200
    },
    {
      "epoch": 0.6175017642907551,
      "grad_norm": 0.9289673566818237,
      "learning_rate": 9.845615435432428e-05,
      "loss": 5.1155,
      "step": 5250
    },
    {
      "epoch": 0.6233827334744766,
      "grad_norm": 1.0233676433563232,
      "learning_rate": 9.582301030641835e-05,
      "loss": 4.9626,
      "step": 5300
    },
    {
      "epoch": 0.6292637026581981,
      "grad_norm": 1.0836933851242065,
      "learning_rate": 9.32089285882068e-05,
      "loss": 4.8537,
      "step": 5350
    },
    {
      "epoch": 0.6351446718419196,
      "grad_norm": 1.2365642786026,
      "learning_rate": 9.061482897186307e-05,
      "loss": 4.7809,
      "step": 5400
    },
    {
      "epoch": 0.6351446718419196,
      "eval_accuracy": 0.2166807301150242,
      "eval_loss": 4.704391956329346,
      "eval_runtime": 2.7076,
      "eval_samples_per_second": 52.814,
      "eval_steps_per_second": 3.324,
      "step": 5400
    },
    {
      "epoch": 0.6410256410256411,
      "grad_norm": 1.398214340209961,
      "learning_rate": 8.804162419880056e-05,
      "loss": 4.7233,
      "step": 5450
    },
    {
      "epoch": 0.6469066102093625,
      "grad_norm": 1.2208573818206787,
      "learning_rate": 8.549021965852197e-05,
      "loss": 4.6471,
      "step": 5500
    },
    {
      "epoch": 0.652787579393084,
      "grad_norm": 1.3375165462493896,
      "learning_rate": 8.296151307005523e-05,
      "loss": 4.58,
      "step": 5550
    },
    {
      "epoch": 0.6586685485768055,
      "grad_norm": 1.3173773288726807,
      "learning_rate": 8.045639416608897e-05,
      "loss": 4.5233,
      "step": 5600
    },
    {
      "epoch": 0.6586685485768055,
      "eval_accuracy": 0.22926267674679984,
      "eval_loss": 4.497797966003418,
      "eval_runtime": 2.726,
      "eval_samples_per_second": 52.458,
      "eval_steps_per_second": 3.302,
      "step": 5600
    },
    {
      "epoch": 0.664549517760527,
      "grad_norm": 2.158308267593384,
      "learning_rate": 7.79757443799167e-05,
      "loss": 4.5088,
      "step": 5650
    },
    {
      "epoch": 0.6704304869442484,
      "grad_norm": 0.9231941103935242,
      "learning_rate": 7.552043653530291e-05,
      "loss": 4.4964,
      "step": 5700
    },
    {
      "epoch": 0.6763114561279698,
      "grad_norm": 1.2655439376831055,
      "learning_rate": 7.309133453937654e-05,
      "loss": 4.4178,
      "step": 5750
    },
    {
      "epoch": 0.6821924253116913,
      "grad_norm": 1.319623351097107,
      "learning_rate": 7.068929307866377e-05,
      "loss": 4.3777,
      "step": 5800
    },
    {
      "epoch": 0.6821924253116913,
      "eval_accuracy": 0.2635717970354023,
      "eval_loss": 4.306857109069824,
      "eval_runtime": 2.7153,
      "eval_samples_per_second": 52.665,
      "eval_steps_per_second": 3.315,
      "step": 5800
    },
    {
      "epoch": 0.6880733944954128,
      "grad_norm": 1.4762769937515259,
      "learning_rate": 6.831515731836326e-05,
      "loss": 4.3207,
      "step": 5850
    },
    {
      "epoch": 0.6939543636791343,
      "grad_norm": 1.3649251461029053,
      "learning_rate": 6.596976260497287e-05,
      "loss": 4.2987,
      "step": 5900
    },
    {
      "epoch": 0.6998353328628558,
      "grad_norm": 1.1361948251724243,
      "learning_rate": 6.365393417237033e-05,
      "loss": 4.2346,
      "step": 5950
    },
    {
      "epoch": 0.7057163020465773,
      "grad_norm": 1.7995405197143555,
      "learning_rate": 6.136848685145244e-05,
      "loss": 4.2335,
      "step": 6000
    },
    {
      "epoch": 0.7057163020465773,
      "eval_accuracy": 0.28996894653953764,
      "eval_loss": 4.144384384155273,
      "eval_runtime": 2.7187,
      "eval_samples_per_second": 52.598,
      "eval_steps_per_second": 3.31,
      "step": 6000
    },
    {
      "epoch": 0.7115972712302987,
      "grad_norm": 2.2464468479156494,
      "learning_rate": 5.911422478343446e-05,
      "loss": 4.1397,
      "step": 6050
    },
    {
      "epoch": 0.7174782404140202,
      "grad_norm": 1.8185687065124512,
      "learning_rate": 5.6891941136910654e-05,
      "loss": 4.1184,
      "step": 6100
    },
    {
      "epoch": 0.7233592095977417,
      "grad_norm": 1.2058391571044922,
      "learning_rate": 5.470241782877571e-05,
      "loss": 4.0656,
      "step": 6150
    },
    {
      "epoch": 0.7292401787814632,
      "grad_norm": 2.51297664642334,
      "learning_rate": 5.254642524910502e-05,
      "loss": 4.0578,
      "step": 6200
    },
    {
      "epoch": 0.7292401787814632,
      "eval_accuracy": 0.33366926185685347,
      "eval_loss": 3.9854564666748047,
      "eval_runtime": 2.7197,
      "eval_samples_per_second": 52.58,
      "eval_steps_per_second": 3.309,
      "step": 6200
    },
    {
      "epoch": 0.7351211479651847,
      "grad_norm": 1.9083071947097778,
      "learning_rate": 5.042472199009064e-05,
      "loss": 3.9994,
      "step": 6250
    },
    {
      "epoch": 0.7410021171489062,
      "grad_norm": 1.7173523902893066,
      "learning_rate": 4.8338054579128554e-05,
      "loss": 3.9915,
      "step": 6300
    },
    {
      "epoch": 0.7468830863326276,
      "grad_norm": 3.0731112957000732,
      "learning_rate": 4.628715721615077e-05,
      "loss": 3.9301,
      "step": 6350
    },
    {
      "epoch": 0.7527640555163491,
      "grad_norm": 2.4160947799682617,
      "learning_rate": 4.427275151529504e-05,
      "loss": 3.9136,
      "step": 6400
    },
    {
      "epoch": 0.7527640555163491,
      "eval_accuracy": 0.35143703389917363,
      "eval_loss": 3.8570971488952637,
      "eval_runtime": 2.7201,
      "eval_samples_per_second": 52.572,
      "eval_steps_per_second": 3.309,
      "step": 6400
    },
    {
      "epoch": 0.7586450247000706,
      "grad_norm": 2.0541601181030273,
      "learning_rate": 4.229554625100275e-05,
      "loss": 3.8829,
      "step": 6450
    },
    {
      "epoch": 0.764525993883792,
      "grad_norm": 2.331949234008789,
      "learning_rate": 4.035623710863471e-05,
      "loss": 3.8751,
      "step": 6500
    },
    {
      "epoch": 0.7704069630675136,
      "grad_norm": 2.7930190563201904,
      "learning_rate": 3.8455506439692175e-05,
      "loss": 3.8231,
      "step": 6550
    },
    {
      "epoch": 0.776287932251235,
      "grad_norm": 2.395653009414673,
      "learning_rate": 3.6594023021729545e-05,
      "loss": 3.7782,
      "step": 6600
    },
    {
      "epoch": 0.776287932251235,
      "eval_accuracy": 0.3723340655436405,
      "eval_loss": 3.7424895763397217,
      "eval_runtime": 2.7092,
      "eval_samples_per_second": 52.783,
      "eval_steps_per_second": 3.322,
      "step": 6600
    },
    {
      "epoch": 0.7821689014349564,
      "grad_norm": 2.225755214691162,
      "learning_rate": 3.477244182304303e-05,
      "loss": 3.7737,
      "step": 6650
    },
    {
      "epoch": 0.7880498706186779,
      "grad_norm": 2.4446072578430176,
      "learning_rate": 3.299140377221819e-05,
      "loss": 3.7513,
      "step": 6700
    },
    {
      "epoch": 0.7939308398023994,
      "grad_norm": 2.192786455154419,
      "learning_rate": 3.125153553261738e-05,
      "loss": 3.7453,
      "step": 6750
    },
    {
      "epoch": 0.7998118089861209,
      "grad_norm": 2.812220573425293,
      "learning_rate": 2.9553449281886403e-05,
      "loss": 3.6984,
      "step": 6800
    },
    {
      "epoch": 0.7998118089861209,
      "eval_accuracy": 0.3877617253288968,
      "eval_loss": 3.6417219638824463,
      "eval_runtime": 2.7016,
      "eval_samples_per_second": 52.932,
      "eval_steps_per_second": 3.331,
      "step": 6800
    },
    {
      "epoch": 0.8056927781698424,
      "grad_norm": 3.2853446006774902,
      "learning_rate": 2.7897742496558107e-05,
      "loss": 3.6746,
      "step": 6850
    },
    {
      "epoch": 0.8115737473535639,
      "grad_norm": 2.5355494022369385,
      "learning_rate": 2.6284997741828418e-05,
      "loss": 3.658,
      "step": 6900
    },
    {
      "epoch": 0.8174547165372853,
      "grad_norm": 2.459353446960449,
      "learning_rate": 2.4715782466579387e-05,
      "loss": 3.6371,
      "step": 6950
    },
    {
      "epoch": 0.8233356857210068,
      "grad_norm": 2.7350852489471436,
      "learning_rate": 2.319064880372019e-05,
      "loss": 3.6353,
      "step": 7000
    },
    {
      "epoch": 0.8233356857210068,
      "eval_accuracy": 0.40248222710362425,
      "eval_loss": 3.5697121620178223,
      "eval_runtime": 2.7028,
      "eval_samples_per_second": 52.908,
      "eval_steps_per_second": 3.33,
      "step": 7000
    },
    {
      "epoch": 0.8292166549047283,
      "grad_norm": 2.280130386352539,
      "learning_rate": 2.1710133375918166e-05,
      "loss": 3.6132,
      "step": 7050
    },
    {
      "epoch": 0.8350976240884498,
      "grad_norm": 2.1498472690582275,
      "learning_rate": 2.027475710678599e-05,
      "loss": 3.5899,
      "step": 7100
    },
    {
      "epoch": 0.8409785932721713,
      "grad_norm": 3.9020628929138184,
      "learning_rate": 1.8885025037593733e-05,
      "loss": 3.5725,
      "step": 7150
    },
    {
      "epoch": 0.8468595624558928,
      "grad_norm": 2.8917956352233887,
      "learning_rate": 1.7541426149568172e-05,
      "loss": 3.5529,
      "step": 7200
    },
    {
      "epoch": 0.8468595624558928,
      "eval_accuracy": 0.40723760850776,
      "eval_loss": 3.5093517303466797,
      "eval_runtime": 2.7287,
      "eval_samples_per_second": 52.407,
      "eval_steps_per_second": 3.298,
      "step": 7200
    },
    {
      "epoch": 0.8527405316396142,
      "grad_norm": 2.4264042377471924,
      "learning_rate": 1.624443319184383e-05,
      "loss": 3.5289,
      "step": 7250
    },
    {
      "epoch": 0.8586215008233357,
      "grad_norm": 2.2179300785064697,
      "learning_rate": 1.4994502515124251e-05,
      "loss": 3.5488,
      "step": 7300
    },
    {
      "epoch": 0.8645024700070572,
      "grad_norm": 2.904592275619507,
      "learning_rate": 1.3792073911114321e-05,
      "loss": 3.5128,
      "step": 7350
    },
    {
      "epoch": 0.8703834391907787,
      "grad_norm": 2.694324016571045,
      "learning_rate": 1.2637570457777701e-05,
      "loss": 3.5186,
      "step": 7400
    },
    {
      "epoch": 0.8703834391907787,
      "eval_accuracy": 0.41160012435049076,
      "eval_loss": 3.462404727935791,
      "eval_runtime": 2.7085,
      "eval_samples_per_second": 52.796,
      "eval_steps_per_second": 3.323,
      "step": 7400
    },
    {
      "epoch": 0.8762644083745001,
      "grad_norm": 2.29337215423584,
      "learning_rate": 1.1531398370476125e-05,
      "loss": 3.5075,
      "step": 7450
    },
    {
      "epoch": 0.8821453775582216,
      "grad_norm": 2.9482133388519287,
      "learning_rate": 1.0473946859040955e-05,
      "loss": 3.4977,
      "step": 7500
    },
    {
      "epoch": 0.888026346741943,
      "grad_norm": 2.576061487197876,
      "learning_rate": 9.465587990828915e-06,
      "loss": 3.4873,
      "step": 7550
    },
    {
      "epoch": 0.8939073159256645,
      "grad_norm": 4.373170375823975,
      "learning_rate": 8.506676559808861e-06,
      "loss": 3.4815,
      "step": 7600
    },
    {
      "epoch": 0.8939073159256645,
      "eval_accuracy": 0.41632475975416866,
      "eval_loss": 3.428917169570923,
      "eval_runtime": 2.7081,
      "eval_samples_per_second": 52.805,
      "eval_steps_per_second": 3.323,
      "step": 7600
    },
    {
      "epoch": 0.899788285109386,
      "grad_norm": 2.2598633766174316,
      "learning_rate": 7.597549961726668e-06,
      "loss": 3.4783,
      "step": 7650
    },
    {
      "epoch": 0.9056692542931075,
      "grad_norm": 2.3314521312713623,
      "learning_rate": 6.738528075391475e-06,
      "loss": 3.4633,
      "step": 7700
    },
    {
      "epoch": 0.911550223476829,
      "grad_norm": 2.2689011096954346,
      "learning_rate": 5.9299131501254534e-06,
      "loss": 3.4575,
      "step": 7750
    },
    {
      "epoch": 0.9174311926605505,
      "grad_norm": 3.443666696548462,
      "learning_rate": 5.17198969941649e-06,
      "loss": 3.4733,
      "step": 7800
    },
    {
      "epoch": 0.9174311926605505,
      "eval_accuracy": 0.42119287649331616,
      "eval_loss": 3.4066121578216553,
      "eval_runtime": 2.7252,
      "eval_samples_per_second": 52.474,
      "eval_steps_per_second": 3.303,
      "step": 7800
    },
    {
      "epoch": 0.9233121618442719,
      "grad_norm": 2.5134923458099365,
      "learning_rate": 4.465024400811312e-06,
      "loss": 3.4551,
      "step": 7850
    },
    {
      "epoch": 0.9291931310279934,
      "grad_norm": 1.494211196899414,
      "learning_rate": 3.8092660020842326e-06,
      "loss": 3.4538,
      "step": 7900
    },
    {
      "epoch": 0.9350741002117149,
      "grad_norm": 1.8422973155975342,
      "learning_rate": 3.2049452337144897e-06,
      "loss": 3.4372,
      "step": 7950
    },
    {
      "epoch": 0.9409550693954364,
      "grad_norm": 1.9858849048614502,
      "learning_rate": 2.652274727703124e-06,
      "loss": 3.4416,
      "step": 8000
    },
    {
      "epoch": 0.9409550693954364,
      "eval_accuracy": 0.4223236460657076,
      "eval_loss": 3.39039945602417,
      "eval_runtime": 2.7069,
      "eval_samples_per_second": 52.828,
      "eval_steps_per_second": 3.325,
      "step": 8000
    },
    {
      "epoch": 0.9468360385791579,
      "grad_norm": 2.525325298309326,
      "learning_rate": 2.1514489427576885e-06,
      "loss": 3.4456,
      "step": 8050
    },
    {
      "epoch": 0.9527170077628794,
      "grad_norm": 2.4124691486358643,
      "learning_rate": 1.7026440958715804e-06,
      "loss": 3.4616,
      "step": 8100
    },
    {
      "epoch": 0.9585979769466008,
      "grad_norm": 2.488292932510376,
      "learning_rate": 1.3060181003214044e-06,
      "loss": 3.4188,
      "step": 8150
    },
    {
      "epoch": 0.9644789461303223,
      "grad_norm": 2.4674930572509766,
      "learning_rate": 9.617105101048017e-07,
      "loss": 3.4265,
      "step": 8200
    },
    {
      "epoch": 0.9644789461303223,
      "eval_accuracy": 0.42152766627607857,
      "eval_loss": 3.3842904567718506,
      "eval_runtime": 2.721,
      "eval_samples_per_second": 52.554,
      "eval_steps_per_second": 3.308,
      "step": 8200
    },
    {
      "epoch": 0.9703599153140438,
      "grad_norm": 1.5315675735473633,
      "learning_rate": 6.698424708380112e-07,
      "loss": 3.421,
      "step": 8250
    },
    {
      "epoch": 0.9762408844977652,
      "grad_norm": 2.1743481159210205,
      "learning_rate": 4.3051667713033257e-07,
      "loss": 3.4281,
      "step": 8300
    },
    {
      "epoch": 0.9821218536814867,
      "grad_norm": 2.1491823196411133,
      "learning_rate": 2.438173364508633e-07,
      "loss": 3.4409,
      "step": 8350
    },
    {
      "epoch": 0.9880028228652082,
      "grad_norm": 1.9528859853744507,
      "learning_rate": 1.0981013949976636e-07,
      "loss": 3.4045,
      "step": 8400
    },
    {
      "epoch": 0.9880028228652082,
      "eval_accuracy": 0.422696014293474,
      "eval_loss": 3.381749391555786,
      "eval_runtime": 2.7134,
      "eval_samples_per_second": 52.702,
      "eval_steps_per_second": 3.317,
      "step": 8400
    }
  ],
  "logging_steps": 50,
  "max_steps": 8502,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.91219116654592e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
