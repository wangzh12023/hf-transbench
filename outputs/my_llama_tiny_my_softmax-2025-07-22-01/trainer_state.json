{
  "best_metric": 6.569685459136963,
  "best_model_checkpoint": "outputs/my_llama_tiny_my_softmax-2025-07-22-01/checkpoint-17000",
  "epoch": 1.0,
  "eval_steps": 200,
  "global_step": 17003,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.002940657531023937,
      "grad_norm": 2.1855127811431885,
      "learning_rate": 5.859375e-05,
      "loss": 9.8302,
      "step": 50
    },
    {
      "epoch": 0.005881315062047874,
      "grad_norm": 0.8136104941368103,
      "learning_rate": 0.0001171875,
      "loss": 8.0007,
      "step": 100
    },
    {
      "epoch": 0.008821972593071811,
      "grad_norm": 0.5307551622390747,
      "learning_rate": 0.00017578125,
      "loss": 7.1448,
      "step": 150
    },
    {
      "epoch": 0.011762630124095747,
      "grad_norm": 0.7700234651565552,
      "learning_rate": 0.000234375,
      "loss": 7.1382,
      "step": 200
    },
    {
      "epoch": 0.011762630124095747,
      "eval_accuracy": 0.044106845767813034,
      "eval_loss": 7.080953598022461,
      "eval_runtime": 4.0383,
      "eval_samples_per_second": 35.411,
      "eval_steps_per_second": 2.229,
      "step": 200
    },
    {
      "epoch": 0.014703287655119685,
      "grad_norm": 0.5227391123771667,
      "learning_rate": 0.00029296875,
      "loss": 7.1114,
      "step": 250
    },
    {
      "epoch": 0.017643945186143623,
      "grad_norm": 0.5545673966407776,
      "learning_rate": 0.00029999489036526523,
      "loss": 7.1655,
      "step": 300
    },
    {
      "epoch": 0.02058460271716756,
      "grad_norm": 0.5706957578659058,
      "learning_rate": 0.00029997667984557944,
      "loss": 7.0853,
      "step": 350
    },
    {
      "epoch": 0.023525260248191494,
      "grad_norm": 0.7010427713394165,
      "learning_rate": 0.00029994527502862664,
      "loss": 7.0556,
      "step": 400
    },
    {
      "epoch": 0.023525260248191494,
      "eval_accuracy": 0.045018977114726993,
      "eval_loss": 7.04550313949585,
      "eval_runtime": 3.7383,
      "eval_samples_per_second": 38.253,
      "eval_steps_per_second": 2.408,
      "step": 400
    },
    {
      "epoch": 0.026465917779215434,
      "grad_norm": 0.560810387134552,
      "learning_rate": 0.0002999006786772662,
      "loss": 7.0746,
      "step": 450
    },
    {
      "epoch": 0.02940657531023937,
      "grad_norm": 0.5689448118209839,
      "learning_rate": 0.00029984289471489167,
      "loss": 7.1026,
      "step": 500
    },
    {
      "epoch": 0.032347232841263306,
      "grad_norm": 0.6159204244613647,
      "learning_rate": 0.0002997719282250851,
      "loss": 7.0565,
      "step": 550
    },
    {
      "epoch": 0.035287890372287245,
      "grad_norm": 0.5903810858726501,
      "learning_rate": 0.0002996877854511703,
      "loss": 7.0558,
      "step": 600
    },
    {
      "epoch": 0.035287890372287245,
      "eval_accuracy": 0.04629322802258806,
      "eval_loss": 6.997507572174072,
      "eval_runtime": 3.7585,
      "eval_samples_per_second": 38.047,
      "eval_steps_per_second": 2.395,
      "step": 600
    },
    {
      "epoch": 0.03822854790331118,
      "grad_norm": 0.5352727174758911,
      "learning_rate": 0.00029959047379566326,
      "loss": 7.0057,
      "step": 650
    },
    {
      "epoch": 0.04116920543433512,
      "grad_norm": 0.5678720474243164,
      "learning_rate": 0.000299480001819621,
      "loss": 7.0089,
      "step": 700
    },
    {
      "epoch": 0.044109862965359056,
      "grad_norm": 0.656852126121521,
      "learning_rate": 0.00029935637924188835,
      "loss": 6.9912,
      "step": 750
    },
    {
      "epoch": 0.04705052049638299,
      "grad_norm": 0.5067030191421509,
      "learning_rate": 0.0002992196169382432,
      "loss": 6.9881,
      "step": 800
    },
    {
      "epoch": 0.04705052049638299,
      "eval_accuracy": 0.045042890670638595,
      "eval_loss": 6.959834098815918,
      "eval_runtime": 3.7484,
      "eval_samples_per_second": 38.15,
      "eval_steps_per_second": 2.401,
      "step": 800
    },
    {
      "epoch": 0.04999117802740693,
      "grad_norm": 0.568619966506958,
      "learning_rate": 0.00029906972694043933,
      "loss": 6.9684,
      "step": 850
    },
    {
      "epoch": 0.05293183555843087,
      "grad_norm": 0.4458712637424469,
      "learning_rate": 0.00029890672243514804,
      "loss": 6.9953,
      "step": 900
    },
    {
      "epoch": 0.0558724930894548,
      "grad_norm": 0.6098200082778931,
      "learning_rate": 0.00029873061776279815,
      "loss": 6.9795,
      "step": 950
    },
    {
      "epoch": 0.05881315062047874,
      "grad_norm": 0.4644296169281006,
      "learning_rate": 0.00029854142841631435,
      "loss": 6.9739,
      "step": 1000
    },
    {
      "epoch": 0.05881315062047874,
      "eval_accuracy": 0.04780661448956515,
      "eval_loss": 6.934957027435303,
      "eval_runtime": 3.7525,
      "eval_samples_per_second": 38.108,
      "eval_steps_per_second": 2.398,
      "step": 1000
    },
    {
      "epoch": 0.06175380815150268,
      "grad_norm": 0.6638198494911194,
      "learning_rate": 0.00029833917103975403,
      "loss": 6.9573,
      "step": 1050
    },
    {
      "epoch": 0.06469446568252661,
      "grad_norm": 0.44555240869522095,
      "learning_rate": 0.0002981238634268432,
      "loss": 6.9713,
      "step": 1100
    },
    {
      "epoch": 0.06763512321355054,
      "grad_norm": 0.4437525272369385,
      "learning_rate": 0.00029789552451941115,
      "loss": 6.9381,
      "step": 1150
    },
    {
      "epoch": 0.07057578074457449,
      "grad_norm": 0.5332106947898865,
      "learning_rate": 0.0002976541744057236,
      "loss": 6.9408,
      "step": 1200
    },
    {
      "epoch": 0.07057578074457449,
      "eval_accuracy": 0.04918676828789188,
      "eval_loss": 6.910732269287109,
      "eval_runtime": 3.7549,
      "eval_samples_per_second": 38.083,
      "eval_steps_per_second": 2.397,
      "step": 1200
    },
    {
      "epoch": 0.07351643827559842,
      "grad_norm": 0.5865761637687683,
      "learning_rate": 0.00029739983431871606,
      "loss": 6.9384,
      "step": 1250
    },
    {
      "epoch": 0.07645709580662235,
      "grad_norm": 0.4820745289325714,
      "learning_rate": 0.00029713252663412517,
      "loss": 6.9566,
      "step": 1300
    },
    {
      "epoch": 0.0793977533376463,
      "grad_norm": 0.5492568612098694,
      "learning_rate": 0.00029685227486852075,
      "loss": 6.8992,
      "step": 1350
    },
    {
      "epoch": 0.08233841086867023,
      "grad_norm": 0.4377913475036621,
      "learning_rate": 0.00029655910367723667,
      "loss": 6.939,
      "step": 1400
    },
    {
      "epoch": 0.08233841086867023,
      "eval_accuracy": 0.04916627095425337,
      "eval_loss": 6.890541076660156,
      "eval_runtime": 3.7562,
      "eval_samples_per_second": 38.07,
      "eval_steps_per_second": 2.396,
      "step": 1400
    },
    {
      "epoch": 0.08527906839969417,
      "grad_norm": 0.5430355072021484,
      "learning_rate": 0.0002962530388522016,
      "loss": 6.9378,
      "step": 1450
    },
    {
      "epoch": 0.08821972593071811,
      "grad_norm": 0.4975426495075226,
      "learning_rate": 0.0002959341073196704,
      "loss": 6.921,
      "step": 1500
    },
    {
      "epoch": 0.09116038346174204,
      "grad_norm": 0.4933285713195801,
      "learning_rate": 0.00029560233713785475,
      "loss": 6.9192,
      "step": 1550
    },
    {
      "epoch": 0.09410104099276598,
      "grad_norm": 0.5458227396011353,
      "learning_rate": 0.0002952577574944552,
      "loss": 6.9279,
      "step": 1600
    },
    {
      "epoch": 0.09410104099276598,
      "eval_accuracy": 0.04938490917973087,
      "eval_loss": 6.883150100708008,
      "eval_runtime": 3.7603,
      "eval_samples_per_second": 38.029,
      "eval_steps_per_second": 2.393,
      "step": 1600
    },
    {
      "epoch": 0.09704169852378992,
      "grad_norm": 0.4886394739151001,
      "learning_rate": 0.0002949003987040929,
      "loss": 6.9177,
      "step": 1650
    },
    {
      "epoch": 0.09998235605481386,
      "grad_norm": 0.4503047466278076,
      "learning_rate": 0.0002945302922056431,
      "loss": 6.9002,
      "step": 1700
    },
    {
      "epoch": 0.10292301358583779,
      "grad_norm": 0.49767547845840454,
      "learning_rate": 0.0002941474705594688,
      "loss": 6.9394,
      "step": 1750
    },
    {
      "epoch": 0.10586367111686174,
      "grad_norm": 0.5406110286712646,
      "learning_rate": 0.0002937519674445568,
      "loss": 6.8691,
      "step": 1800
    },
    {
      "epoch": 0.10586367111686174,
      "eval_accuracy": 0.0488178162823986,
      "eval_loss": 6.871473789215088,
      "eval_runtime": 3.7664,
      "eval_samples_per_second": 37.968,
      "eval_steps_per_second": 2.39,
      "step": 1800
    },
    {
      "epoch": 0.10880432864788567,
      "grad_norm": 0.49990227818489075,
      "learning_rate": 0.00029334381765555427,
      "loss": 6.8958,
      "step": 1850
    },
    {
      "epoch": 0.1117449861789096,
      "grad_norm": 0.4519423842430115,
      "learning_rate": 0.00029292305709970794,
      "loss": 6.8977,
      "step": 1900
    },
    {
      "epoch": 0.11468564370993355,
      "grad_norm": 0.4854774475097656,
      "learning_rate": 0.0002924897227937051,
      "loss": 6.89,
      "step": 1950
    },
    {
      "epoch": 0.11762630124095748,
      "grad_norm": 0.48968902230262756,
      "learning_rate": 0.0002920438528604169,
      "loss": 6.914,
      "step": 2000
    },
    {
      "epoch": 0.11762630124095748,
      "eval_accuracy": 0.04965479073930466,
      "eval_loss": 6.860280513763428,
      "eval_runtime": 3.7633,
      "eval_samples_per_second": 37.999,
      "eval_steps_per_second": 2.392,
      "step": 2000
    },
    {
      "epoch": 0.12056695877198141,
      "grad_norm": 0.6337583065032959,
      "learning_rate": 0.0002915854865255446,
      "loss": 6.9201,
      "step": 2050
    },
    {
      "epoch": 0.12350761630300536,
      "grad_norm": 0.5013818144798279,
      "learning_rate": 0.0002911146641141687,
      "loss": 6.8761,
      "step": 2100
    },
    {
      "epoch": 0.1264482738340293,
      "grad_norm": 0.5118243098258972,
      "learning_rate": 0.00029063142704720117,
      "loss": 6.8835,
      "step": 2150
    },
    {
      "epoch": 0.12938893136505322,
      "grad_norm": 0.5614389181137085,
      "learning_rate": 0.0002901358178377415,
      "loss": 6.9053,
      "step": 2200
    },
    {
      "epoch": 0.12938893136505322,
      "eval_accuracy": 0.04975386118522416,
      "eval_loss": 6.851925373077393,
      "eval_runtime": 3.7771,
      "eval_samples_per_second": 37.86,
      "eval_steps_per_second": 2.383,
      "step": 2200
    },
    {
      "epoch": 0.13232958889607715,
      "grad_norm": 0.4832138121128082,
      "learning_rate": 0.00028962788008733654,
      "loss": 6.9065,
      "step": 2250
    },
    {
      "epoch": 0.1352702464271011,
      "grad_norm": 0.46394944190979004,
      "learning_rate": 0.0002891076584821447,
      "loss": 6.8699,
      "step": 2300
    },
    {
      "epoch": 0.13821090395812505,
      "grad_norm": 0.5172914862632751,
      "learning_rate": 0.00028857519878900474,
      "loss": 6.8878,
      "step": 2350
    },
    {
      "epoch": 0.14115156148914898,
      "grad_norm": 0.6362140774726868,
      "learning_rate": 0.0002880305478514089,
      "loss": 6.8876,
      "step": 2400
    },
    {
      "epoch": 0.14115156148914898,
      "eval_accuracy": 0.04861284294601344,
      "eval_loss": 6.8465352058410645,
      "eval_runtime": 3.7782,
      "eval_samples_per_second": 37.849,
      "eval_steps_per_second": 2.382,
      "step": 2400
    },
    {
      "epoch": 0.1440922190201729,
      "grad_norm": 0.4836786687374115,
      "learning_rate": 0.00028747375358538263,
      "loss": 6.8454,
      "step": 2450
    },
    {
      "epoch": 0.14703287655119684,
      "grad_norm": 0.43974632024765015,
      "learning_rate": 0.0002869048649752683,
      "loss": 6.9005,
      "step": 2500
    },
    {
      "epoch": 0.14997353408222078,
      "grad_norm": 0.5140190720558167,
      "learning_rate": 0.00028632393206941655,
      "loss": 6.8893,
      "step": 2550
    },
    {
      "epoch": 0.1529141916132447,
      "grad_norm": 0.6476656198501587,
      "learning_rate": 0.00028573100597578265,
      "loss": 6.8862,
      "step": 2600
    },
    {
      "epoch": 0.1529141916132447,
      "eval_accuracy": 0.04981876940841279,
      "eval_loss": 6.833844184875488,
      "eval_runtime": 3.7699,
      "eval_samples_per_second": 37.932,
      "eval_steps_per_second": 2.387,
      "step": 2600
    },
    {
      "epoch": 0.15585484914426867,
      "grad_norm": 0.44507449865341187,
      "learning_rate": 0.00028512613885743046,
      "loss": 6.9098,
      "step": 2650
    },
    {
      "epoch": 0.1587955066752926,
      "grad_norm": 0.5287269949913025,
      "learning_rate": 0.00028450938392794343,
      "loss": 6.855,
      "step": 2700
    },
    {
      "epoch": 0.16173616420631654,
      "grad_norm": 0.5535247325897217,
      "learning_rate": 0.00028388079544674306,
      "loss": 6.8918,
      "step": 2750
    },
    {
      "epoch": 0.16467682173734047,
      "grad_norm": 0.4846900701522827,
      "learning_rate": 0.00028324042871431533,
      "loss": 6.8656,
      "step": 2800
    },
    {
      "epoch": 0.16467682173734047,
      "eval_accuracy": 0.05026287830391397,
      "eval_loss": 6.826918125152588,
      "eval_runtime": 3.7771,
      "eval_samples_per_second": 37.86,
      "eval_steps_per_second": 2.383,
      "step": 2800
    },
    {
      "epoch": 0.1676174792683644,
      "grad_norm": 0.41224703192710876,
      "learning_rate": 0.00028258834006734555,
      "loss": 6.8794,
      "step": 2850
    },
    {
      "epoch": 0.17055813679938833,
      "grad_norm": 0.47377917170524597,
      "learning_rate": 0.00028192458687376234,
      "loss": 6.8483,
      "step": 2900
    },
    {
      "epoch": 0.1734987943304123,
      "grad_norm": 0.5182028412818909,
      "learning_rate": 0.00028124922752769034,
      "loss": 6.8938,
      "step": 2950
    },
    {
      "epoch": 0.17643945186143623,
      "grad_norm": 0.6657410860061646,
      "learning_rate": 0.0002805623214443132,
      "loss": 6.8816,
      "step": 3000
    },
    {
      "epoch": 0.17643945186143623,
      "eval_accuracy": 0.04995200207706314,
      "eval_loss": 6.806928634643555,
      "eval_runtime": 3.7697,
      "eval_samples_per_second": 37.934,
      "eval_steps_per_second": 2.387,
      "step": 3000
    },
    {
      "epoch": 0.17938010939246016,
      "grad_norm": 0.4419063627719879,
      "learning_rate": 0.0002798639290546465,
      "loss": 6.8533,
      "step": 3050
    },
    {
      "epoch": 0.1823207669234841,
      "grad_norm": 0.46611011028289795,
      "learning_rate": 0.00027915411180022093,
      "loss": 6.8337,
      "step": 3100
    },
    {
      "epoch": 0.18526142445450802,
      "grad_norm": 0.45406049489974976,
      "learning_rate": 0.0002784329321276774,
      "loss": 6.8658,
      "step": 3150
    },
    {
      "epoch": 0.18820208198553195,
      "grad_norm": 0.4781796336174011,
      "learning_rate": 0.00027770045348327293,
      "loss": 6.8793,
      "step": 3200
    },
    {
      "epoch": 0.18820208198553195,
      "eval_accuracy": 0.05038586230574506,
      "eval_loss": 6.802262306213379,
      "eval_runtime": 3.7709,
      "eval_samples_per_second": 37.922,
      "eval_steps_per_second": 2.387,
      "step": 3200
    },
    {
      "epoch": 0.19114273951655592,
      "grad_norm": 0.5376166701316833,
      "learning_rate": 0.0002769567403072991,
      "loss": 6.8505,
      "step": 3250
    },
    {
      "epoch": 0.19408339704757985,
      "grad_norm": 0.42998895049095154,
      "learning_rate": 0.0002762018580284128,
      "loss": 6.8326,
      "step": 3300
    },
    {
      "epoch": 0.19702405457860378,
      "grad_norm": 0.4480940103530884,
      "learning_rate": 0.0002754358730578801,
      "loss": 6.8649,
      "step": 3350
    },
    {
      "epoch": 0.1999647121096277,
      "grad_norm": 0.46081429719924927,
      "learning_rate": 0.00027465885278373366,
      "loss": 6.842,
      "step": 3400
    },
    {
      "epoch": 0.1999647121096277,
      "eval_accuracy": 0.04985976407568982,
      "eval_loss": 6.80544376373291,
      "eval_runtime": 3.7727,
      "eval_samples_per_second": 37.904,
      "eval_steps_per_second": 2.386,
      "step": 3400
    },
    {
      "epoch": 0.20290536964065164,
      "grad_norm": 0.470138281583786,
      "learning_rate": 0.0002738708655648442,
      "loss": 6.823,
      "step": 3450
    },
    {
      "epoch": 0.20584602717167558,
      "grad_norm": 0.5044403672218323,
      "learning_rate": 0.0002730719807249069,
      "loss": 6.8368,
      "step": 3500
    },
    {
      "epoch": 0.2087866847026995,
      "grad_norm": 0.4339946508407593,
      "learning_rate": 0.00027226226854634196,
      "loss": 6.8669,
      "step": 3550
    },
    {
      "epoch": 0.21172734223372347,
      "grad_norm": 0.4283192455768585,
      "learning_rate": 0.00027144180026411206,
      "loss": 6.872,
      "step": 3600
    },
    {
      "epoch": 0.21172734223372347,
      "eval_accuracy": 0.05073773319987292,
      "eval_loss": 6.797695159912109,
      "eval_runtime": 3.7696,
      "eval_samples_per_second": 37.935,
      "eval_steps_per_second": 2.388,
      "step": 3600
    },
    {
      "epoch": 0.2146679997647474,
      "grad_norm": 0.44354939460754395,
      "learning_rate": 0.0002706106480594552,
      "loss": 6.8059,
      "step": 3650
    },
    {
      "epoch": 0.21760865729577133,
      "grad_norm": 0.5731734037399292,
      "learning_rate": 0.0002697688850535344,
      "loss": 6.8172,
      "step": 3700
    },
    {
      "epoch": 0.22054931482679527,
      "grad_norm": 0.409938782453537,
      "learning_rate": 0.000268916585301005,
      "loss": 6.8271,
      "step": 3750
    },
    {
      "epoch": 0.2234899723578192,
      "grad_norm": 0.4155042767524719,
      "learning_rate": 0.0002680538237834994,
      "loss": 6.8322,
      "step": 3800
    },
    {
      "epoch": 0.2234899723578192,
      "eval_accuracy": 0.05090512809125413,
      "eval_loss": 6.783161163330078,
      "eval_runtime": 3.7803,
      "eval_samples_per_second": 37.827,
      "eval_steps_per_second": 2.381,
      "step": 3800
    },
    {
      "epoch": 0.22643062988884313,
      "grad_norm": 0.5553823709487915,
      "learning_rate": 0.0002671806764030309,
      "loss": 6.8238,
      "step": 3850
    },
    {
      "epoch": 0.2293712874198671,
      "grad_norm": 0.4932727515697479,
      "learning_rate": 0.0002662972199753159,
      "loss": 6.8256,
      "step": 3900
    },
    {
      "epoch": 0.23231194495089103,
      "grad_norm": 0.44035422801971436,
      "learning_rate": 0.0002654035322230158,
      "loss": 6.8369,
      "step": 3950
    },
    {
      "epoch": 0.23525260248191496,
      "grad_norm": 0.4209370017051697,
      "learning_rate": 0.0002644996917688998,
      "loss": 6.8248,
      "step": 4000
    },
    {
      "epoch": 0.23525260248191496,
      "eval_accuracy": 0.05087779831306944,
      "eval_loss": 6.779897212982178,
      "eval_runtime": 3.7763,
      "eval_samples_per_second": 37.868,
      "eval_steps_per_second": 2.383,
      "step": 4000
    },
    {
      "epoch": 0.2381932600129389,
      "grad_norm": 0.5162338018417358,
      "learning_rate": 0.0002635857781289275,
      "loss": 6.8216,
      "step": 4050
    },
    {
      "epoch": 0.24113391754396282,
      "grad_norm": 0.4557769298553467,
      "learning_rate": 0.00026266187170525396,
      "loss": 6.8441,
      "step": 4100
    },
    {
      "epoch": 0.24407457507498675,
      "grad_norm": 0.40998536348342896,
      "learning_rate": 0.0002617280537791557,
      "loss": 6.8374,
      "step": 4150
    },
    {
      "epoch": 0.24701523260601072,
      "grad_norm": 0.4636562764644623,
      "learning_rate": 0.00026078440650388027,
      "loss": 6.8112,
      "step": 4200
    },
    {
      "epoch": 0.24701523260601072,
      "eval_accuracy": 0.050570338308491704,
      "eval_loss": 6.77365255355835,
      "eval_runtime": 3.7798,
      "eval_samples_per_second": 37.833,
      "eval_steps_per_second": 2.381,
      "step": 4200
    },
    {
      "epoch": 0.24995589013703465,
      "grad_norm": 0.628173291683197,
      "learning_rate": 0.0002598310128974188,
      "loss": 6.804,
      "step": 4250
    },
    {
      "epoch": 0.2528965476680586,
      "grad_norm": 0.45309245586395264,
      "learning_rate": 0.00025886795683520214,
      "loss": 6.8517,
      "step": 4300
    },
    {
      "epoch": 0.25583720519908254,
      "grad_norm": 0.4676499366760254,
      "learning_rate": 0.0002578953230427223,
      "loss": 6.8328,
      "step": 4350
    },
    {
      "epoch": 0.25877786273010644,
      "grad_norm": 0.5049955248832703,
      "learning_rate": 0.0002569131970880782,
      "loss": 6.7857,
      "step": 4400
    },
    {
      "epoch": 0.25877786273010644,
      "eval_accuracy": 0.051482469655405656,
      "eval_loss": 6.765329360961914,
      "eval_runtime": 3.7742,
      "eval_samples_per_second": 37.888,
      "eval_steps_per_second": 2.385,
      "step": 4400
    },
    {
      "epoch": 0.2617185202611304,
      "grad_norm": 0.4561099708080292,
      "learning_rate": 0.000255921665374448,
      "loss": 6.8329,
      "step": 4450
    },
    {
      "epoch": 0.2646591777921543,
      "grad_norm": 0.5663382411003113,
      "learning_rate": 0.00025492081513248804,
      "loss": 6.7892,
      "step": 4500
    },
    {
      "epoch": 0.26759983532317827,
      "grad_norm": 0.45340460538864136,
      "learning_rate": 0.0002539107344126578,
      "loss": 6.8026,
      "step": 4550
    },
    {
      "epoch": 0.2705404928542022,
      "grad_norm": 0.5723482370376587,
      "learning_rate": 0.00025289151207747454,
      "loss": 6.8206,
      "step": 4600
    },
    {
      "epoch": 0.2705404928542022,
      "eval_accuracy": 0.052193043888207544,
      "eval_loss": 6.753929138183594,
      "eval_runtime": 3.7709,
      "eval_samples_per_second": 37.922,
      "eval_steps_per_second": 2.387,
      "step": 4600
    },
    {
      "epoch": 0.27348115038522613,
      "grad_norm": 0.52837073802948,
      "learning_rate": 0.00025186323779369496,
      "loss": 6.8156,
      "step": 4650
    },
    {
      "epoch": 0.2764218079162501,
      "grad_norm": 0.4886631965637207,
      "learning_rate": 0.000250826002024427,
      "loss": 6.7879,
      "step": 4700
    },
    {
      "epoch": 0.279362465447274,
      "grad_norm": 0.4321250915527344,
      "learning_rate": 0.0002497798960211711,
      "loss": 6.8054,
      "step": 4750
    },
    {
      "epoch": 0.28230312297829796,
      "grad_norm": 0.5445161461830139,
      "learning_rate": 0.0002487250118157925,
      "loss": 6.7997,
      "step": 4800
    },
    {
      "epoch": 0.28230312297829796,
      "eval_accuracy": 0.05205981121955719,
      "eval_loss": 6.747229099273682,
      "eval_runtime": 3.7746,
      "eval_samples_per_second": 37.884,
      "eval_steps_per_second": 2.384,
      "step": 4800
    },
    {
      "epoch": 0.28524378050932186,
      "grad_norm": 0.5700226426124573,
      "learning_rate": 0.00024766144221242454,
      "loss": 6.8012,
      "step": 4850
    },
    {
      "epoch": 0.2881844380403458,
      "grad_norm": 0.5912756323814392,
      "learning_rate": 0.0002465892807793041,
      "loss": 6.7871,
      "step": 4900
    },
    {
      "epoch": 0.2911250955713698,
      "grad_norm": 0.46681833267211914,
      "learning_rate": 0.0002455086218405399,
      "loss": 6.7753,
      "step": 4950
    },
    {
      "epoch": 0.2940657531023937,
      "grad_norm": 0.4749049246311188,
      "learning_rate": 0.0002444195604678145,
      "loss": 6.8058,
      "step": 5000
    },
    {
      "epoch": 0.2940657531023937,
      "eval_accuracy": 0.05199148677409547,
      "eval_loss": 6.7381978034973145,
      "eval_runtime": 3.7796,
      "eval_samples_per_second": 37.835,
      "eval_steps_per_second": 2.381,
      "step": 5000
    },
    {
      "epoch": 0.29700641063341765,
      "grad_norm": 0.5639589428901672,
      "learning_rate": 0.00024332219247201998,
      "loss": 6.8104,
      "step": 5050
    },
    {
      "epoch": 0.29994706816444155,
      "grad_norm": 0.5349103212356567,
      "learning_rate": 0.0002422166143948291,
      "loss": 6.7767,
      "step": 5100
    },
    {
      "epoch": 0.3028877256954655,
      "grad_norm": 0.5100760459899902,
      "learning_rate": 0.00024110292350020194,
      "loss": 6.7984,
      "step": 5150
    },
    {
      "epoch": 0.3058283832264894,
      "grad_norm": 0.5216646790504456,
      "learning_rate": 0.00023998121776582903,
      "loss": 6.7433,
      "step": 5200
    },
    {
      "epoch": 0.3058283832264894,
      "eval_accuracy": 0.05179334588225648,
      "eval_loss": 6.737788677215576,
      "eval_runtime": 3.7653,
      "eval_samples_per_second": 37.978,
      "eval_steps_per_second": 2.39,
      "step": 5200
    },
    {
      "epoch": 0.3087690407575134,
      "grad_norm": 0.452055960893631,
      "learning_rate": 0.00023885159587451178,
      "loss": 6.7193,
      "step": 5250
    },
    {
      "epoch": 0.31170969828853734,
      "grad_norm": 0.47307154536247253,
      "learning_rate": 0.00023771415720548068,
      "loss": 6.7824,
      "step": 5300
    },
    {
      "epoch": 0.31465035581956124,
      "grad_norm": 0.4392111301422119,
      "learning_rate": 0.00023656900182565232,
      "loss": 6.7955,
      "step": 5350
    },
    {
      "epoch": 0.3175910133505852,
      "grad_norm": 0.49037259817123413,
      "learning_rate": 0.00023541623048082609,
      "loss": 6.7748,
      "step": 5400
    },
    {
      "epoch": 0.3175910133505852,
      "eval_accuracy": 0.05196757321818387,
      "eval_loss": 6.727882385253906,
      "eval_runtime": 3.7705,
      "eval_samples_per_second": 37.926,
      "eval_steps_per_second": 2.387,
      "step": 5400
    },
    {
      "epoch": 0.3205316708816091,
      "grad_norm": 0.44309982657432556,
      "learning_rate": 0.00023425594458682095,
      "loss": 6.7545,
      "step": 5450
    },
    {
      "epoch": 0.32347232841263307,
      "grad_norm": 0.4473807215690613,
      "learning_rate": 0.00023308824622055323,
      "loss": 6.745,
      "step": 5500
    },
    {
      "epoch": 0.326412985943657,
      "grad_norm": 0.4490123391151428,
      "learning_rate": 0.0002319132381110563,
      "loss": 6.7453,
      "step": 5550
    },
    {
      "epoch": 0.32935364347468093,
      "grad_norm": 0.4600462019443512,
      "learning_rate": 0.00023073102363044322,
      "loss": 6.793,
      "step": 5600
    },
    {
      "epoch": 0.32935364347468093,
      "eval_accuracy": 0.05212813566501891,
      "eval_loss": 6.7204461097717285,
      "eval_runtime": 3.7615,
      "eval_samples_per_second": 38.016,
      "eval_steps_per_second": 2.393,
      "step": 5600
    },
    {
      "epoch": 0.3322943010057049,
      "grad_norm": 0.4242006242275238,
      "learning_rate": 0.00022954170678481212,
      "loss": 6.7563,
      "step": 5650
    },
    {
      "epoch": 0.3352349585367288,
      "grad_norm": 0.48855993151664734,
      "learning_rate": 0.00022834539220509644,
      "loss": 6.7598,
      "step": 5700
    },
    {
      "epoch": 0.33817561606775276,
      "grad_norm": 0.491813600063324,
      "learning_rate": 0.00022714218513785988,
      "loss": 6.77,
      "step": 5750
    },
    {
      "epoch": 0.34111627359877666,
      "grad_norm": 0.6278067231178284,
      "learning_rate": 0.0002259321914360373,
      "loss": 6.767,
      "step": 5800
    },
    {
      "epoch": 0.34111627359877666,
      "eval_accuracy": 0.05270206100689735,
      "eval_loss": 6.715151309967041,
      "eval_runtime": 3.777,
      "eval_samples_per_second": 37.86,
      "eval_steps_per_second": 2.383,
      "step": 5800
    },
    {
      "epoch": 0.3440569311298006,
      "grad_norm": 0.5180249810218811,
      "learning_rate": 0.0002247155175496222,
      "loss": 6.7603,
      "step": 5850
    },
    {
      "epoch": 0.3469975886608246,
      "grad_norm": 0.5072271823883057,
      "learning_rate": 0.00022349227051630168,
      "loss": 6.7175,
      "step": 5900
    },
    {
      "epoch": 0.3499382461918485,
      "grad_norm": 0.49927255511283875,
      "learning_rate": 0.00022226255795203986,
      "loss": 6.7331,
      "step": 5950
    },
    {
      "epoch": 0.35287890372287245,
      "grad_norm": 0.520595908164978,
      "learning_rate": 0.00022102648804161006,
      "loss": 6.7375,
      "step": 6000
    },
    {
      "epoch": 0.35287890372287245,
      "eval_accuracy": 0.05300268856692892,
      "eval_loss": 6.714601993560791,
      "eval_runtime": 3.7727,
      "eval_samples_per_second": 37.904,
      "eval_steps_per_second": 2.386,
      "step": 6000
    },
    {
      "epoch": 0.35581956125389635,
      "grad_norm": 0.4856310784816742,
      "learning_rate": 0.00021978416952907748,
      "loss": 6.7526,
      "step": 6050
    },
    {
      "epoch": 0.3587602187849203,
      "grad_norm": 0.4943985044956207,
      "learning_rate": 0.00021853571170823207,
      "loss": 6.7597,
      "step": 6100
    },
    {
      "epoch": 0.3617008763159442,
      "grad_norm": 0.4061800539493561,
      "learning_rate": 0.00021728122441297363,
      "loss": 6.7333,
      "step": 6150
    },
    {
      "epoch": 0.3646415338469682,
      "grad_norm": 0.4549274444580078,
      "learning_rate": 0.0002160208180076488,
      "loss": 6.7286,
      "step": 6200
    },
    {
      "epoch": 0.3646415338469682,
      "eval_accuracy": 0.05232969277913098,
      "eval_loss": 6.706660747528076,
      "eval_runtime": 3.7821,
      "eval_samples_per_second": 37.81,
      "eval_steps_per_second": 2.38,
      "step": 6200
    },
    {
      "epoch": 0.36758219137799214,
      "grad_norm": 0.46060872077941895,
      "learning_rate": 0.0002147546033773419,
      "loss": 6.7604,
      "step": 6250
    },
    {
      "epoch": 0.37052284890901604,
      "grad_norm": 0.46614938974380493,
      "learning_rate": 0.0002134826919181197,
      "loss": 6.7761,
      "step": 6300
    },
    {
      "epoch": 0.37346350644004,
      "grad_norm": 0.4747503995895386,
      "learning_rate": 0.00021220519552723116,
      "loss": 6.7295,
      "step": 6350
    },
    {
      "epoch": 0.3764041639710639,
      "grad_norm": 0.5201101899147034,
      "learning_rate": 0.00021092222659326336,
      "loss": 6.7261,
      "step": 6400
    },
    {
      "epoch": 0.3764041639710639,
      "eval_accuracy": 0.052336525223677155,
      "eval_loss": 6.7046895027160645,
      "eval_runtime": 3.7703,
      "eval_samples_per_second": 37.928,
      "eval_steps_per_second": 2.387,
      "step": 6400
    },
    {
      "epoch": 0.37934482150208787,
      "grad_norm": 0.5432513356208801,
      "learning_rate": 0.0002096338979862539,
      "loss": 6.7479,
      "step": 6450
    },
    {
      "epoch": 0.38228547903311183,
      "grad_norm": 0.5172119736671448,
      "learning_rate": 0.00020834032304776129,
      "loss": 6.7115,
      "step": 6500
    },
    {
      "epoch": 0.38522613656413573,
      "grad_norm": 0.4546700119972229,
      "learning_rate": 0.0002070416155808933,
      "loss": 6.7503,
      "step": 6550
    },
    {
      "epoch": 0.3881667940951597,
      "grad_norm": 0.5952747464179993,
      "learning_rate": 0.0002057378898402954,
      "loss": 6.7093,
      "step": 6600
    },
    {
      "epoch": 0.3881667940951597,
      "eval_accuracy": 0.05204956255273793,
      "eval_loss": 6.7061848640441895,
      "eval_runtime": 3.7555,
      "eval_samples_per_second": 38.078,
      "eval_steps_per_second": 2.397,
      "step": 6600
    },
    {
      "epoch": 0.3911074516261836,
      "grad_norm": 0.4902401864528656,
      "learning_rate": 0.00020442926052209896,
      "loss": 6.7516,
      "step": 6650
    },
    {
      "epoch": 0.39404810915720756,
      "grad_norm": 0.5545822978019714,
      "learning_rate": 0.00020311584275383088,
      "loss": 6.7265,
      "step": 6700
    },
    {
      "epoch": 0.39698876668823146,
      "grad_norm": 0.4992270767688751,
      "learning_rate": 0.0002017977520842851,
      "loss": 6.7573,
      "step": 6750
    },
    {
      "epoch": 0.3999294242192554,
      "grad_norm": 0.4781055748462677,
      "learning_rate": 0.00020047510447335703,
      "loss": 6.7369,
      "step": 6800
    },
    {
      "epoch": 0.3999294242192554,
      "eval_accuracy": 0.05296511012192497,
      "eval_loss": 6.692348957061768,
      "eval_runtime": 3.7665,
      "eval_samples_per_second": 37.966,
      "eval_steps_per_second": 2.389,
      "step": 6800
    },
    {
      "epoch": 0.4028700817502794,
      "grad_norm": 0.4724729657173157,
      "learning_rate": 0.00019914801628184207,
      "loss": 6.7438,
      "step": 6850
    },
    {
      "epoch": 0.4058107392813033,
      "grad_norm": 0.6550954580307007,
      "learning_rate": 0.00019781660426119863,
      "loss": 6.7377,
      "step": 6900
    },
    {
      "epoch": 0.40875139681232725,
      "grad_norm": 0.5398455262184143,
      "learning_rate": 0.00019648098554327686,
      "loss": 6.7595,
      "step": 6950
    },
    {
      "epoch": 0.41169205434335115,
      "grad_norm": 0.6820765733718872,
      "learning_rate": 0.00019514127763001378,
      "loss": 6.7342,
      "step": 7000
    },
    {
      "epoch": 0.41169205434335115,
      "eval_accuracy": 0.05277380167463216,
      "eval_loss": 6.689470291137695,
      "eval_runtime": 3.7734,
      "eval_samples_per_second": 37.897,
      "eval_steps_per_second": 2.385,
      "step": 7000
    },
    {
      "epoch": 0.4146327118743751,
      "grad_norm": 0.5076305866241455,
      "learning_rate": 0.00019379759838309622,
      "loss": 6.7116,
      "step": 7050
    },
    {
      "epoch": 0.417573369405399,
      "grad_norm": 0.5368788242340088,
      "learning_rate": 0.00019245006601359155,
      "loss": 6.7354,
      "step": 7100
    },
    {
      "epoch": 0.420514026936423,
      "grad_norm": 0.5482035875320435,
      "learning_rate": 0.00019109879907154825,
      "loss": 6.728,
      "step": 7150
    },
    {
      "epoch": 0.42345468446744694,
      "grad_norm": 0.5212873220443726,
      "learning_rate": 0.00018974391643556624,
      "loss": 6.7044,
      "step": 7200
    },
    {
      "epoch": 0.42345468446744694,
      "eval_accuracy": 0.05327257012650271,
      "eval_loss": 6.681213855743408,
      "eval_runtime": 3.7745,
      "eval_samples_per_second": 37.886,
      "eval_steps_per_second": 2.384,
      "step": 7200
    },
    {
      "epoch": 0.42639534199847084,
      "grad_norm": 0.4777159094810486,
      "learning_rate": 0.00018838553730233845,
      "loss": 6.73,
      "step": 7250
    },
    {
      "epoch": 0.4293359995294948,
      "grad_norm": 0.6026988625526428,
      "learning_rate": 0.00018702378117616458,
      "loss": 6.7386,
      "step": 7300
    },
    {
      "epoch": 0.4322766570605187,
      "grad_norm": 0.49766653776168823,
      "learning_rate": 0.00018565876785843735,
      "loss": 6.6988,
      "step": 7350
    },
    {
      "epoch": 0.43521731459154267,
      "grad_norm": 0.5180650949478149,
      "learning_rate": 0.00018429061743710314,
      "loss": 6.763,
      "step": 7400
    },
    {
      "epoch": 0.43521731459154267,
      "eval_accuracy": 0.05330331612696049,
      "eval_loss": 6.681197643280029,
      "eval_runtime": 3.7691,
      "eval_samples_per_second": 37.94,
      "eval_steps_per_second": 2.388,
      "step": 7400
    },
    {
      "epoch": 0.43815797212256663,
      "grad_norm": 0.5388149619102478,
      "learning_rate": 0.0001829194502760972,
      "loss": 6.7093,
      "step": 7450
    },
    {
      "epoch": 0.44109862965359053,
      "grad_norm": 0.5866626501083374,
      "learning_rate": 0.00018154538700475422,
      "loss": 6.7019,
      "step": 7500
    },
    {
      "epoch": 0.4440392871846145,
      "grad_norm": 0.5119150876998901,
      "learning_rate": 0.00018016854850719623,
      "loss": 6.7467,
      "step": 7550
    },
    {
      "epoch": 0.4469799447156384,
      "grad_norm": 0.49537599086761475,
      "learning_rate": 0.0001787890559116977,
      "loss": 6.6769,
      "step": 7600
    },
    {
      "epoch": 0.4469799447156384,
      "eval_accuracy": 0.053139337457852355,
      "eval_loss": 6.67676305770874,
      "eval_runtime": 3.7663,
      "eval_samples_per_second": 37.968,
      "eval_steps_per_second": 2.39,
      "step": 7600
    },
    {
      "epoch": 0.44992060224666236,
      "grad_norm": 0.46597862243652344,
      "learning_rate": 0.00017740703058002888,
      "loss": 6.7318,
      "step": 7650
    },
    {
      "epoch": 0.45286125977768626,
      "grad_norm": 0.5036544799804688,
      "learning_rate": 0.00017602259409677933,
      "loss": 6.7374,
      "step": 7700
    },
    {
      "epoch": 0.4558019173087102,
      "grad_norm": 0.5541653633117676,
      "learning_rate": 0.0001746358682586613,
      "loss": 6.7282,
      "step": 7750
    },
    {
      "epoch": 0.4587425748397342,
      "grad_norm": 0.5821933150291443,
      "learning_rate": 0.00017324697506379436,
      "loss": 6.7346,
      "step": 7800
    },
    {
      "epoch": 0.4587425748397342,
      "eval_accuracy": 0.05305051567875212,
      "eval_loss": 6.670054912567139,
      "eval_runtime": 3.7582,
      "eval_samples_per_second": 38.051,
      "eval_steps_per_second": 2.395,
      "step": 7800
    },
    {
      "epoch": 0.4616832323707581,
      "grad_norm": 0.487291544675827,
      "learning_rate": 0.00017185603670097284,
      "loss": 6.7345,
      "step": 7850
    },
    {
      "epoch": 0.46462388990178205,
      "grad_norm": 0.5726376175880432,
      "learning_rate": 0.00017046317553891612,
      "loss": 6.7102,
      "step": 7900
    },
    {
      "epoch": 0.46756454743280595,
      "grad_norm": 0.5045293569564819,
      "learning_rate": 0.00016906851411550294,
      "loss": 6.7256,
      "step": 7950
    },
    {
      "epoch": 0.4705052049638299,
      "grad_norm": 0.5178611278533936,
      "learning_rate": 0.00016767217512699147,
      "loss": 6.7251,
      "step": 8000
    },
    {
      "epoch": 0.4705052049638299,
      "eval_accuracy": 0.05382941435701572,
      "eval_loss": 6.665796279907227,
      "eval_runtime": 3.7656,
      "eval_samples_per_second": 37.975,
      "eval_steps_per_second": 2.39,
      "step": 8000
    },
    {
      "epoch": 0.4734458624948539,
      "grad_norm": 0.517649233341217,
      "learning_rate": 0.00016627428141722443,
      "loss": 6.7254,
      "step": 8050
    },
    {
      "epoch": 0.4763865200258778,
      "grad_norm": 0.45830658078193665,
      "learning_rate": 0.00016487495596682254,
      "loss": 6.6873,
      "step": 8100
    },
    {
      "epoch": 0.47932717755690174,
      "grad_norm": 0.44764798879623413,
      "learning_rate": 0.00016347432188236455,
      "loss": 6.6996,
      "step": 8150
    },
    {
      "epoch": 0.48226783508792564,
      "grad_norm": 0.44829660654067993,
      "learning_rate": 0.00016207250238555737,
      "loss": 6.7041,
      "step": 8200
    },
    {
      "epoch": 0.48226783508792564,
      "eval_accuracy": 0.05395581458111991,
      "eval_loss": 6.6635847091674805,
      "eval_runtime": 3.7623,
      "eval_samples_per_second": 38.008,
      "eval_steps_per_second": 2.392,
      "step": 8200
    },
    {
      "epoch": 0.4852084926189496,
      "grad_norm": 0.5902312397956848,
      "learning_rate": 0.0001606696208023951,
      "loss": 6.7152,
      "step": 8250
    },
    {
      "epoch": 0.4881491501499735,
      "grad_norm": 0.4963186979293823,
      "learning_rate": 0.00015926580055230987,
      "loss": 6.7196,
      "step": 8300
    },
    {
      "epoch": 0.49108980768099747,
      "grad_norm": 0.5687589645385742,
      "learning_rate": 0.00015786116513731346,
      "loss": 6.7007,
      "step": 8350
    },
    {
      "epoch": 0.49403046521202143,
      "grad_norm": 0.557108461856842,
      "learning_rate": 0.00015645583813113237,
      "loss": 6.7207,
      "step": 8400
    },
    {
      "epoch": 0.49403046521202143,
      "eval_accuracy": 0.053819165690196465,
      "eval_loss": 6.654449939727783,
      "eval_runtime": 3.7689,
      "eval_samples_per_second": 37.942,
      "eval_steps_per_second": 2.388,
      "step": 8400
    },
    {
      "epoch": 0.49697112274304533,
      "grad_norm": 0.5543016195297241,
      "learning_rate": 0.00015504994316833636,
      "loss": 6.6683,
      "step": 8450
    },
    {
      "epoch": 0.4999117802740693,
      "grad_norm": 0.5010974407196045,
      "learning_rate": 0.00015364360393346137,
      "loss": 6.6956,
      "step": 8500
    },
    {
      "epoch": 0.5028524378050933,
      "grad_norm": 0.5373649597167969,
      "learning_rate": 0.0001522369441501287,
      "loss": 6.675,
      "step": 8550
    },
    {
      "epoch": 0.5057930953361172,
      "grad_norm": 0.4768063426017761,
      "learning_rate": 0.00015083008757015985,
      "loss": 6.7053,
      "step": 8600
    },
    {
      "epoch": 0.5057930953361172,
      "eval_accuracy": 0.05409587969431643,
      "eval_loss": 6.646999359130859,
      "eval_runtime": 3.7695,
      "eval_samples_per_second": 37.936,
      "eval_steps_per_second": 2.388,
      "step": 8600
    },
    {
      "epoch": 0.5087337528671411,
      "grad_norm": 0.6090303063392639,
      "learning_rate": 0.00014942315796268992,
      "loss": 6.6633,
      "step": 8650
    },
    {
      "epoch": 0.5116744103981651,
      "grad_norm": 0.5475082993507385,
      "learning_rate": 0.0001480162791032784,
      "loss": 6.6923,
      "step": 8700
    },
    {
      "epoch": 0.514615067929189,
      "grad_norm": 0.5698074698448181,
      "learning_rate": 0.00014660957476302043,
      "loss": 6.6808,
      "step": 8750
    },
    {
      "epoch": 0.5175557254602129,
      "grad_norm": 0.6154096722602844,
      "learning_rate": 0.00014520316869765743,
      "loss": 6.6534,
      "step": 8800
    },
    {
      "epoch": 0.5175557254602129,
      "eval_accuracy": 0.05380550080110412,
      "eval_loss": 6.642385005950928,
      "eval_runtime": 3.7714,
      "eval_samples_per_second": 37.917,
      "eval_steps_per_second": 2.386,
      "step": 8800
    },
    {
      "epoch": 0.5204963829912368,
      "grad_norm": 0.7071791887283325,
      "learning_rate": 0.0001437971846366901,
      "loss": 6.6429,
      "step": 8850
    },
    {
      "epoch": 0.5234370405222608,
      "grad_norm": 0.5718021988868713,
      "learning_rate": 0.000142391746272493,
      "loss": 6.6446,
      "step": 8900
    },
    {
      "epoch": 0.5263776980532847,
      "grad_norm": 0.5997073650360107,
      "learning_rate": 0.00014098697724943256,
      "loss": 6.722,
      "step": 8950
    },
    {
      "epoch": 0.5293183555843086,
      "grad_norm": 0.6321143507957458,
      "learning_rate": 0.0001395830011529896,
      "loss": 6.7075,
      "step": 9000
    },
    {
      "epoch": 0.5293183555843086,
      "eval_accuracy": 0.053754257467007835,
      "eval_loss": 6.635729789733887,
      "eval_runtime": 3.7656,
      "eval_samples_per_second": 37.976,
      "eval_steps_per_second": 2.39,
      "step": 9000
    },
    {
      "epoch": 0.5322590131153326,
      "grad_norm": 0.528388500213623,
      "learning_rate": 0.00013817994149888655,
      "loss": 6.7016,
      "step": 9050
    },
    {
      "epoch": 0.5351996706463565,
      "grad_norm": 0.4401354193687439,
      "learning_rate": 0.00013677792172222137,
      "loss": 6.6733,
      "step": 9100
    },
    {
      "epoch": 0.5381403281773804,
      "grad_norm": 0.745905876159668,
      "learning_rate": 0.00013537706516660811,
      "loss": 6.6767,
      "step": 9150
    },
    {
      "epoch": 0.5410809857084043,
      "grad_norm": 0.4979218542575836,
      "learning_rate": 0.0001339774950733255,
      "loss": 6.6374,
      "step": 9200
    },
    {
      "epoch": 0.5410809857084043,
      "eval_accuracy": 0.05364493835426908,
      "eval_loss": 6.635415554046631,
      "eval_runtime": 3.763,
      "eval_samples_per_second": 38.002,
      "eval_steps_per_second": 2.392,
      "step": 9200
    },
    {
      "epoch": 0.5440216432394284,
      "grad_norm": 0.5832518935203552,
      "learning_rate": 0.00013257933457047518,
      "loss": 6.7005,
      "step": 9250
    },
    {
      "epoch": 0.5469623007704523,
      "grad_norm": 0.6723625659942627,
      "learning_rate": 0.00013118270666214886,
      "loss": 6.7057,
      "step": 9300
    },
    {
      "epoch": 0.5499029583014762,
      "grad_norm": 0.8439173698425293,
      "learning_rate": 0.00012978773421760744,
      "loss": 6.6635,
      "step": 9350
    },
    {
      "epoch": 0.5528436158325002,
      "grad_norm": 0.5647844672203064,
      "learning_rate": 0.00012839453996047118,
      "loss": 6.666,
      "step": 9400
    },
    {
      "epoch": 0.5528436158325002,
      "eval_accuracy": 0.053576613908807365,
      "eval_loss": 6.632201671600342,
      "eval_runtime": 3.7697,
      "eval_samples_per_second": 37.934,
      "eval_steps_per_second": 2.387,
      "step": 9400
    },
    {
      "epoch": 0.5557842733635241,
      "grad_norm": 0.5095217823982239,
      "learning_rate": 0.00012700324645792318,
      "loss": 6.6964,
      "step": 9450
    },
    {
      "epoch": 0.558724930894548,
      "grad_norm": 0.5941935181617737,
      "learning_rate": 0.00012561397610992645,
      "loss": 6.6678,
      "step": 9500
    },
    {
      "epoch": 0.5616655884255719,
      "grad_norm": 0.5581185221672058,
      "learning_rate": 0.00012422685113845563,
      "loss": 6.6894,
      "step": 9550
    },
    {
      "epoch": 0.5646062459565959,
      "grad_norm": 0.44504356384277344,
      "learning_rate": 0.00012284199357674432,
      "loss": 6.6741,
      "step": 9600
    },
    {
      "epoch": 0.5646062459565959,
      "eval_accuracy": 0.054321350364340104,
      "eval_loss": 6.629406929016113,
      "eval_runtime": 3.7673,
      "eval_samples_per_second": 37.959,
      "eval_steps_per_second": 2.389,
      "step": 9600
    },
    {
      "epoch": 0.5675469034876198,
      "grad_norm": 0.5717852711677551,
      "learning_rate": 0.00012145952525854939,
      "loss": 6.652,
      "step": 9650
    },
    {
      "epoch": 0.5704875610186437,
      "grad_norm": 0.584712028503418,
      "learning_rate": 0.0001200795678074324,
      "loss": 6.6326,
      "step": 9700
    },
    {
      "epoch": 0.5734282185496677,
      "grad_norm": 0.5154294967651367,
      "learning_rate": 0.00011870224262605968,
      "loss": 6.6537,
      "step": 9750
    },
    {
      "epoch": 0.5763688760806917,
      "grad_norm": 0.52849942445755,
      "learning_rate": 0.00011732767088552198,
      "loss": 6.6429,
      "step": 9800
    },
    {
      "epoch": 0.5763688760806917,
      "eval_accuracy": 0.05376792235610018,
      "eval_loss": 6.628525733947754,
      "eval_runtime": 3.7677,
      "eval_samples_per_second": 37.954,
      "eval_steps_per_second": 2.389,
      "step": 9800
    },
    {
      "epoch": 0.5793095336117156,
      "grad_norm": 0.5080894827842712,
      "learning_rate": 0.00011595597351467419,
      "loss": 6.7079,
      "step": 9850
    },
    {
      "epoch": 0.5822501911427396,
      "grad_norm": 0.5383790731430054,
      "learning_rate": 0.00011458727118949665,
      "loss": 6.6657,
      "step": 9900
    },
    {
      "epoch": 0.5851908486737635,
      "grad_norm": 0.5817769169807434,
      "learning_rate": 0.00011322168432247867,
      "loss": 6.6618,
      "step": 9950
    },
    {
      "epoch": 0.5881315062047874,
      "grad_norm": 0.5238139629364014,
      "learning_rate": 0.00011185933305202495,
      "loss": 6.6703,
      "step": 10000
    },
    {
      "epoch": 0.5881315062047874,
      "eval_accuracy": 0.05451607503390601,
      "eval_loss": 6.623036861419678,
      "eval_runtime": 3.7732,
      "eval_samples_per_second": 37.898,
      "eval_steps_per_second": 2.385,
      "step": 10000
    },
    {
      "epoch": 0.5910721637358113,
      "grad_norm": 0.49424082040786743,
      "learning_rate": 0.00011050033723188653,
      "loss": 6.7095,
      "step": 10050
    },
    {
      "epoch": 0.5940128212668353,
      "grad_norm": 0.5406872034072876,
      "learning_rate": 0.00010914481642061645,
      "loss": 6.6487,
      "step": 10100
    },
    {
      "epoch": 0.5969534787978592,
      "grad_norm": 0.8169222474098206,
      "learning_rate": 0.00010779288987105163,
      "loss": 6.6644,
      "step": 10150
    },
    {
      "epoch": 0.5998941363288831,
      "grad_norm": 0.6125259399414062,
      "learning_rate": 0.00010644467651982131,
      "loss": 6.6593,
      "step": 10200
    },
    {
      "epoch": 0.5998941363288831,
      "eval_accuracy": 0.054140290583866546,
      "eval_loss": 6.621211528778076,
      "eval_runtime": 3.7672,
      "eval_samples_per_second": 37.959,
      "eval_steps_per_second": 2.389,
      "step": 10200
    },
    {
      "epoch": 0.6028347938599071,
      "grad_norm": 0.5081136226654053,
      "learning_rate": 0.00010510029497688383,
      "loss": 6.6818,
      "step": 10250
    },
    {
      "epoch": 0.605775451390931,
      "grad_norm": 0.5932812094688416,
      "learning_rate": 0.00010375986351509155,
      "loss": 6.6568,
      "step": 10300
    },
    {
      "epoch": 0.6087161089219549,
      "grad_norm": 0.6447010636329651,
      "learning_rate": 0.00010242350005978581,
      "loss": 6.6574,
      "step": 10350
    },
    {
      "epoch": 0.6116567664529788,
      "grad_norm": 0.6050657033920288,
      "learning_rate": 0.00010109132217842253,
      "loss": 6.6461,
      "step": 10400
    },
    {
      "epoch": 0.6116567664529788,
      "eval_accuracy": 0.054321350364340104,
      "eval_loss": 6.621662139892578,
      "eval_runtime": 3.7696,
      "eval_samples_per_second": 37.936,
      "eval_steps_per_second": 2.388,
      "step": 10400
    },
    {
      "epoch": 0.6145974239840029,
      "grad_norm": 0.6047544479370117,
      "learning_rate": 9.976344707022895e-05,
      "loss": 6.6666,
      "step": 10450
    },
    {
      "epoch": 0.6175380815150268,
      "grad_norm": 0.588030993938446,
      "learning_rate": 9.843999155589296e-05,
      "loss": 6.6607,
      "step": 10500
    },
    {
      "epoch": 0.6204787390460507,
      "grad_norm": 0.545454740524292,
      "learning_rate": 9.712107206728578e-05,
      "loss": 6.6654,
      "step": 10550
    },
    {
      "epoch": 0.6234193965770747,
      "grad_norm": 0.5384374856948853,
      "learning_rate": 9.580680463721883e-05,
      "loss": 6.6309,
      "step": 10600
    },
    {
      "epoch": 0.6234193965770747,
      "eval_accuracy": 0.0542496096966053,
      "eval_loss": 6.6149067878723145,
      "eval_runtime": 3.7763,
      "eval_samples_per_second": 37.867,
      "eval_steps_per_second": 2.383,
      "step": 10600
    },
    {
      "epoch": 0.6263600541080986,
      "grad_norm": 0.637662410736084,
      "learning_rate": 9.44973048892355e-05,
      "loss": 6.6687,
      "step": 10650
    },
    {
      "epoch": 0.6293007116391225,
      "grad_norm": 0.6157167553901672,
      "learning_rate": 9.319268802743935e-05,
      "loss": 6.6068,
      "step": 10700
    },
    {
      "epoch": 0.6322413691701464,
      "grad_norm": 0.5085574984550476,
      "learning_rate": 9.18930688263587e-05,
      "loss": 6.6836,
      "step": 10750
    },
    {
      "epoch": 0.6351820267011704,
      "grad_norm": 0.5978559255599976,
      "learning_rate": 9.059856162084942e-05,
      "loss": 6.6371,
      "step": 10800
    },
    {
      "epoch": 0.6351820267011704,
      "eval_accuracy": 0.054406755921167255,
      "eval_loss": 6.6116156578063965,
      "eval_runtime": 3.7693,
      "eval_samples_per_second": 37.938,
      "eval_steps_per_second": 2.388,
      "step": 10800
    },
    {
      "epoch": 0.6381226842321943,
      "grad_norm": 0.6294593214988708,
      "learning_rate": 8.930928029603623e-05,
      "loss": 6.6499,
      "step": 10850
    },
    {
      "epoch": 0.6410633417632182,
      "grad_norm": 0.6276775002479553,
      "learning_rate": 8.802533827729344e-05,
      "loss": 6.6455,
      "step": 10900
    },
    {
      "epoch": 0.6440039992942422,
      "grad_norm": 0.6079921722412109,
      "learning_rate": 8.674684852026654e-05,
      "loss": 6.6364,
      "step": 10950
    },
    {
      "epoch": 0.6469446568252661,
      "grad_norm": 0.5387592911720276,
      "learning_rate": 8.54739235009346e-05,
      "loss": 6.6492,
      "step": 11000
    },
    {
      "epoch": 0.6469446568252661,
      "eval_accuracy": 0.054960183929407186,
      "eval_loss": 6.607571601867676,
      "eval_runtime": 3.7555,
      "eval_samples_per_second": 38.078,
      "eval_steps_per_second": 2.396,
      "step": 11000
    },
    {
      "epoch": 0.64988531435629,
      "grad_norm": 0.5849438905715942,
      "learning_rate": 8.420667520571518e-05,
      "loss": 6.6128,
      "step": 11050
    },
    {
      "epoch": 0.652825971887314,
      "grad_norm": 0.5412368178367615,
      "learning_rate": 8.294521512161247e-05,
      "loss": 6.6327,
      "step": 11100
    },
    {
      "epoch": 0.655766629418338,
      "grad_norm": 0.5371454954147339,
      "learning_rate": 8.168965422640883e-05,
      "loss": 6.584,
      "step": 11150
    },
    {
      "epoch": 0.6587072869493619,
      "grad_norm": 0.5869489312171936,
      "learning_rate": 8.044010297890155e-05,
      "loss": 6.623,
      "step": 11200
    },
    {
      "epoch": 0.6587072869493619,
      "eval_accuracy": 0.05474837814847585,
      "eval_loss": 6.604480266571045,
      "eval_runtime": 3.7637,
      "eval_samples_per_second": 37.995,
      "eval_steps_per_second": 2.391,
      "step": 11200
    },
    {
      "epoch": 0.6616479444803858,
      "grad_norm": 0.6081547737121582,
      "learning_rate": 7.919667130918534e-05,
      "loss": 6.6568,
      "step": 11250
    },
    {
      "epoch": 0.6645886020114098,
      "grad_norm": 0.5849598050117493,
      "learning_rate": 7.795946860898101e-05,
      "loss": 6.6386,
      "step": 11300
    },
    {
      "epoch": 0.6675292595424337,
      "grad_norm": 0.5784180164337158,
      "learning_rate": 7.672860372201154e-05,
      "loss": 6.6525,
      "step": 11350
    },
    {
      "epoch": 0.6704699170734576,
      "grad_norm": 0.5746318697929382,
      "learning_rate": 7.550418493442667e-05,
      "loss": 6.6915,
      "step": 11400
    },
    {
      "epoch": 0.6704699170734576,
      "eval_accuracy": 0.05492260548440324,
      "eval_loss": 6.6034836769104,
      "eval_runtime": 3.7607,
      "eval_samples_per_second": 38.025,
      "eval_steps_per_second": 2.393,
      "step": 11400
    },
    {
      "epoch": 0.6734105746044816,
      "grad_norm": 0.5503734946250916,
      "learning_rate": 7.42863199652764e-05,
      "loss": 6.635,
      "step": 11450
    },
    {
      "epoch": 0.6763512321355055,
      "grad_norm": 0.5551260113716125,
      "learning_rate": 7.307511595703411e-05,
      "loss": 6.6372,
      "step": 11500
    },
    {
      "epoch": 0.6792918896665294,
      "grad_norm": 0.5753714442253113,
      "learning_rate": 7.18706794661708e-05,
      "loss": 6.6749,
      "step": 11550
    },
    {
      "epoch": 0.6822325471975533,
      "grad_norm": 0.5873203277587891,
      "learning_rate": 7.067311645378057e-05,
      "loss": 6.6167,
      "step": 11600
    },
    {
      "epoch": 0.6822325471975533,
      "eval_accuracy": 0.05483719992757609,
      "eval_loss": 6.600874423980713,
      "eval_runtime": 3.7667,
      "eval_samples_per_second": 37.965,
      "eval_steps_per_second": 2.389,
      "step": 11600
    },
    {
      "epoch": 0.6851732047285773,
      "grad_norm": 0.5208781957626343,
      "learning_rate": 6.948253227625897e-05,
      "loss": 6.6321,
      "step": 11650
    },
    {
      "epoch": 0.6881138622596012,
      "grad_norm": 0.5090872049331665,
      "learning_rate": 6.829903167603372e-05,
      "loss": 6.6297,
      "step": 11700
    },
    {
      "epoch": 0.6910545197906252,
      "grad_norm": 0.7219273447990417,
      "learning_rate": 6.712271877235016e-05,
      "loss": 6.6388,
      "step": 11750
    },
    {
      "epoch": 0.6939951773216492,
      "grad_norm": 0.506710946559906,
      "learning_rate": 6.59536970521115e-05,
      "loss": 6.6529,
      "step": 11800
    },
    {
      "epoch": 0.6939951773216492,
      "eval_accuracy": 0.05471763214801808,
      "eval_loss": 6.598871231079102,
      "eval_runtime": 3.7821,
      "eval_samples_per_second": 37.809,
      "eval_steps_per_second": 2.38,
      "step": 11800
    },
    {
      "epoch": 0.6969358348526731,
      "grad_norm": 0.7117921710014343,
      "learning_rate": 6.47920693607741e-05,
      "loss": 6.6392,
      "step": 11850
    },
    {
      "epoch": 0.699876492383697,
      "grad_norm": 0.6237744688987732,
      "learning_rate": 6.363793789329969e-05,
      "loss": 6.6104,
      "step": 11900
    },
    {
      "epoch": 0.7028171499147209,
      "grad_norm": 0.5486372709274292,
      "learning_rate": 6.249140418516501e-05,
      "loss": 6.6558,
      "step": 11950
    },
    {
      "epoch": 0.7057578074457449,
      "grad_norm": 0.6952378153800964,
      "learning_rate": 6.135256910342873e-05,
      "loss": 6.6579,
      "step": 12000
    },
    {
      "epoch": 0.7057578074457449,
      "eval_accuracy": 0.05496360015168027,
      "eval_loss": 6.598115921020508,
      "eval_runtime": 3.7656,
      "eval_samples_per_second": 37.975,
      "eval_steps_per_second": 2.39,
      "step": 12000
    },
    {
      "epoch": 0.7086984649767688,
      "grad_norm": 0.5764899849891663,
      "learning_rate": 6.022153283785782e-05,
      "loss": 6.5948,
      "step": 12050
    },
    {
      "epoch": 0.7116391225077927,
      "grad_norm": 0.5920060873031616,
      "learning_rate": 5.909839489211321e-05,
      "loss": 6.605,
      "step": 12100
    },
    {
      "epoch": 0.7145797800388167,
      "grad_norm": 0.5453311800956726,
      "learning_rate": 5.7983254074996065e-05,
      "loss": 6.6422,
      "step": 12150
    },
    {
      "epoch": 0.7175204375698406,
      "grad_norm": 0.5573760867118835,
      "learning_rate": 5.687620849175486e-05,
      "loss": 6.6218,
      "step": 12200
    },
    {
      "epoch": 0.7175204375698406,
      "eval_accuracy": 0.055236897933527145,
      "eval_loss": 6.594794750213623,
      "eval_runtime": 3.7672,
      "eval_samples_per_second": 37.96,
      "eval_steps_per_second": 2.389,
      "step": 12200
    },
    {
      "epoch": 0.7204610951008645,
      "grad_norm": 0.5983932018280029,
      "learning_rate": 5.5777355535454435e-05,
      "loss": 6.6126,
      "step": 12250
    },
    {
      "epoch": 0.7234017526318884,
      "grad_norm": 0.7924493551254272,
      "learning_rate": 5.46867918784079e-05,
      "loss": 6.6164,
      "step": 12300
    },
    {
      "epoch": 0.7263424101629125,
      "grad_norm": 0.6648438572883606,
      "learning_rate": 5.360461346367194e-05,
      "loss": 6.6284,
      "step": 12350
    },
    {
      "epoch": 0.7292830676939364,
      "grad_norm": 0.6424073576927185,
      "learning_rate": 5.2530915496605845e-05,
      "loss": 6.6478,
      "step": 12400
    },
    {
      "epoch": 0.7292830676939364,
      "eval_accuracy": 0.05515832482124617,
      "eval_loss": 6.591912269592285,
      "eval_runtime": 3.7675,
      "eval_samples_per_second": 37.956,
      "eval_steps_per_second": 2.389,
      "step": 12400
    },
    {
      "epoch": 0.7322237252249603,
      "grad_norm": 0.5354288220405579,
      "learning_rate": 5.146579243649595e-05,
      "loss": 6.6168,
      "step": 12450
    },
    {
      "epoch": 0.7351643827559843,
      "grad_norm": 0.5544461607933044,
      "learning_rate": 5.040933798824564e-05,
      "loss": 6.6194,
      "step": 12500
    },
    {
      "epoch": 0.7381050402870082,
      "grad_norm": 0.5314022302627563,
      "learning_rate": 4.936164509413134e-05,
      "loss": 6.6497,
      "step": 12550
    },
    {
      "epoch": 0.7410456978180321,
      "grad_norm": 0.624889075756073,
      "learning_rate": 4.832280592562599e-05,
      "loss": 6.6347,
      "step": 12600
    },
    {
      "epoch": 0.7410456978180321,
      "eval_accuracy": 0.0551754059326116,
      "eval_loss": 6.5916032791137695,
      "eval_runtime": 3.7738,
      "eval_samples_per_second": 37.893,
      "eval_steps_per_second": 2.385,
      "step": 12600
    },
    {
      "epoch": 0.743986355349056,
      "grad_norm": 0.649406373500824,
      "learning_rate": 4.729291187529012e-05,
      "loss": 6.6132,
      "step": 12650
    },
    {
      "epoch": 0.74692701288008,
      "grad_norm": 0.6940988898277283,
      "learning_rate": 4.6272053548731794e-05,
      "loss": 6.5905,
      "step": 12700
    },
    {
      "epoch": 0.7498676704111039,
      "grad_norm": 0.6008250117301941,
      "learning_rate": 4.5260320756635144e-05,
      "loss": 6.6429,
      "step": 12750
    },
    {
      "epoch": 0.7528083279421278,
      "grad_norm": 0.664162278175354,
      "learning_rate": 4.4257802506859366e-05,
      "loss": 6.6059,
      "step": 12800
    },
    {
      "epoch": 0.7528083279421278,
      "eval_accuracy": 0.055260811489438746,
      "eval_loss": 6.588126182556152,
      "eval_runtime": 3.7722,
      "eval_samples_per_second": 37.909,
      "eval_steps_per_second": 2.386,
      "step": 12800
    },
    {
      "epoch": 0.7557489854731518,
      "grad_norm": 0.5518006682395935,
      "learning_rate": 4.326458699660842e-05,
      "loss": 6.6155,
      "step": 12850
    },
    {
      "epoch": 0.7586896430041757,
      "grad_norm": 0.5648961663246155,
      "learning_rate": 4.228076160467145e-05,
      "loss": 6.6139,
      "step": 12900
    },
    {
      "epoch": 0.7616303005351996,
      "grad_norm": 0.6403347849845886,
      "learning_rate": 4.13064128837358e-05,
      "loss": 6.6251,
      "step": 12950
    },
    {
      "epoch": 0.7645709580662237,
      "grad_norm": 0.5344410538673401,
      "learning_rate": 4.034162655277234e-05,
      "loss": 6.6233,
      "step": 13000
    },
    {
      "epoch": 0.7645709580662237,
      "eval_accuracy": 0.05530863860126195,
      "eval_loss": 6.585954666137695,
      "eval_runtime": 3.7725,
      "eval_samples_per_second": 37.906,
      "eval_steps_per_second": 2.386,
      "step": 13000
    },
    {
      "epoch": 0.7675116155972476,
      "grad_norm": 0.48467880487442017,
      "learning_rate": 3.9386487489494666e-05,
      "loss": 6.6006,
      "step": 13050
    },
    {
      "epoch": 0.7704522731282715,
      "grad_norm": 0.6284646987915039,
      "learning_rate": 3.8441079722891374e-05,
      "loss": 6.6107,
      "step": 13100
    },
    {
      "epoch": 0.7733929306592954,
      "grad_norm": 0.7283042073249817,
      "learning_rate": 3.750548642583389e-05,
      "loss": 6.5781,
      "step": 13150
    },
    {
      "epoch": 0.7763335881903194,
      "grad_norm": 0.5897166132926941,
      "learning_rate": 3.657978990775916e-05,
      "loss": 6.6012,
      "step": 13200
    },
    {
      "epoch": 0.7763335881903194,
      "eval_accuracy": 0.055376963046723675,
      "eval_loss": 6.583528995513916,
      "eval_runtime": 3.771,
      "eval_samples_per_second": 37.921,
      "eval_steps_per_second": 2.387,
      "step": 13200
    },
    {
      "epoch": 0.7792742457213433,
      "grad_norm": 0.6095075607299805,
      "learning_rate": 3.566407160742866e-05,
      "loss": 6.6412,
      "step": 13250
    },
    {
      "epoch": 0.7822149032523672,
      "grad_norm": 0.5295169353485107,
      "learning_rate": 3.475841208576338e-05,
      "loss": 6.6166,
      "step": 13300
    },
    {
      "epoch": 0.7851555607833912,
      "grad_norm": 0.679550051689148,
      "learning_rate": 3.3862891018756704e-05,
      "loss": 6.6194,
      "step": 13350
    },
    {
      "epoch": 0.7880962183144151,
      "grad_norm": 0.6251754760742188,
      "learning_rate": 3.2977587190464844e-05,
      "loss": 6.6211,
      "step": 13400
    },
    {
      "epoch": 0.7880962183144151,
      "eval_accuracy": 0.055230065488980976,
      "eval_loss": 6.583924770355225,
      "eval_runtime": 3.7706,
      "eval_samples_per_second": 37.925,
      "eval_steps_per_second": 2.387,
      "step": 13400
    },
    {
      "epoch": 0.791036875845439,
      "grad_norm": 0.6151144504547119,
      "learning_rate": 3.2102578486075616e-05,
      "loss": 6.6706,
      "step": 13450
    },
    {
      "epoch": 0.7939775333764629,
      "grad_norm": 0.5238258242607117,
      "learning_rate": 3.1237941885056534e-05,
      "loss": 6.6127,
      "step": 13500
    },
    {
      "epoch": 0.796918190907487,
      "grad_norm": 0.5305435657501221,
      "learning_rate": 3.0383753454382486e-05,
      "loss": 6.5983,
      "step": 13550
    },
    {
      "epoch": 0.7998588484385108,
      "grad_norm": 0.5658185482025146,
      "learning_rate": 2.9540088341843764e-05,
      "loss": 6.6212,
      "step": 13600
    },
    {
      "epoch": 0.7998588484385108,
      "eval_accuracy": 0.05532913593490047,
      "eval_loss": 6.5811638832092285,
      "eval_runtime": 3.777,
      "eval_samples_per_second": 37.861,
      "eval_steps_per_second": 2.383,
      "step": 13600
    },
    {
      "epoch": 0.8027995059695348,
      "grad_norm": 0.5371483564376831,
      "learning_rate": 2.870702076943472e-05,
      "loss": 6.6496,
      "step": 13650
    },
    {
      "epoch": 0.8057401635005588,
      "grad_norm": 0.45666182041168213,
      "learning_rate": 2.78846240268241e-05,
      "loss": 6.5985,
      "step": 13700
    },
    {
      "epoch": 0.8086808210315827,
      "grad_norm": 0.6700092554092407,
      "learning_rate": 2.707297046490753e-05,
      "loss": 6.5845,
      "step": 13750
    },
    {
      "epoch": 0.8116214785626066,
      "grad_norm": 0.7738019227981567,
      "learning_rate": 2.627213148944205e-05,
      "loss": 6.6222,
      "step": 13800
    },
    {
      "epoch": 0.8116214785626066,
      "eval_accuracy": 0.05528472504535035,
      "eval_loss": 6.579554557800293,
      "eval_runtime": 3.767,
      "eval_samples_per_second": 37.961,
      "eval_steps_per_second": 2.389,
      "step": 13800
    },
    {
      "epoch": 0.8145621360936305,
      "grad_norm": 0.7786877155303955,
      "learning_rate": 2.5482177554764376e-05,
      "loss": 6.5832,
      "step": 13850
    },
    {
      "epoch": 0.8175027936246545,
      "grad_norm": 0.5579903721809387,
      "learning_rate": 2.4703178157592656e-05,
      "loss": 6.6224,
      "step": 13900
    },
    {
      "epoch": 0.8204434511556784,
      "grad_norm": 0.7711299657821655,
      "learning_rate": 2.3935201830912376e-05,
      "loss": 6.611,
      "step": 13950
    },
    {
      "epoch": 0.8233841086867023,
      "grad_norm": 0.635906994342804,
      "learning_rate": 2.317831613794705e-05,
      "loss": 6.6467,
      "step": 14000
    },
    {
      "epoch": 0.8233841086867023,
      "eval_accuracy": 0.055585352605381916,
      "eval_loss": 6.578184127807617,
      "eval_runtime": 3.78,
      "eval_samples_per_second": 37.831,
      "eval_steps_per_second": 2.381,
      "step": 14000
    },
    {
      "epoch": 0.8263247662177263,
      "grad_norm": 0.5741470456123352,
      "learning_rate": 2.2432587666214412e-05,
      "loss": 6.5979,
      "step": 14050
    },
    {
      "epoch": 0.8292654237487502,
      "grad_norm": 0.6035732626914978,
      "learning_rate": 2.1698082021668284e-05,
      "loss": 6.6403,
      "step": 14100
    },
    {
      "epoch": 0.8322060812797741,
      "grad_norm": 0.5710121989250183,
      "learning_rate": 2.097486382292697e-05,
      "loss": 6.589,
      "step": 14150
    },
    {
      "epoch": 0.835146738810798,
      "grad_norm": 0.6022469997406006,
      "learning_rate": 2.0262996695588157e-05,
      "loss": 6.6133,
      "step": 14200
    },
    {
      "epoch": 0.835146738810798,
      "eval_accuracy": 0.055670758162209066,
      "eval_loss": 6.577629089355469,
      "eval_runtime": 3.7644,
      "eval_samples_per_second": 37.988,
      "eval_steps_per_second": 2.391,
      "step": 14200
    },
    {
      "epoch": 0.838087396341822,
      "grad_norm": 0.7917432188987732,
      "learning_rate": 1.95625432666316e-05,
      "loss": 6.6057,
      "step": 14250
    },
    {
      "epoch": 0.841028053872846,
      "grad_norm": 0.5617625117301941,
      "learning_rate": 1.8873565158909475e-05,
      "loss": 6.6021,
      "step": 14300
    },
    {
      "epoch": 0.8439687114038699,
      "grad_norm": 0.6929910182952881,
      "learning_rate": 1.819612298572492e-05,
      "loss": 6.5823,
      "step": 14350
    },
    {
      "epoch": 0.8469093689348939,
      "grad_norm": 0.6986140012741089,
      "learning_rate": 1.7530276345499618e-05,
      "loss": 6.6278,
      "step": 14400
    },
    {
      "epoch": 0.8469093689348939,
      "eval_accuracy": 0.05537354682445059,
      "eval_loss": 6.575969696044922,
      "eval_runtime": 3.7665,
      "eval_samples_per_second": 37.967,
      "eval_steps_per_second": 2.39,
      "step": 14400
    },
    {
      "epoch": 0.8498500264659178,
      "grad_norm": 0.7028462886810303,
      "learning_rate": 1.6876083816530694e-05,
      "loss": 6.5993,
      "step": 14450
    },
    {
      "epoch": 0.8527906839969417,
      "grad_norm": 0.5278813242912292,
      "learning_rate": 1.6233602951837088e-05,
      "loss": 6.6016,
      "step": 14500
    },
    {
      "epoch": 0.8557313415279657,
      "grad_norm": 0.5766250491142273,
      "learning_rate": 1.5602890274096354e-05,
      "loss": 6.6062,
      "step": 14550
    },
    {
      "epoch": 0.8586719990589896,
      "grad_norm": 0.6419174671173096,
      "learning_rate": 1.4984001270672008e-05,
      "loss": 6.6399,
      "step": 14600
    },
    {
      "epoch": 0.8586719990589896,
      "eval_accuracy": 0.05537354682445059,
      "eval_loss": 6.575506687164307,
      "eval_runtime": 3.7867,
      "eval_samples_per_second": 37.764,
      "eval_steps_per_second": 2.377,
      "step": 14600
    },
    {
      "epoch": 0.8616126565900135,
      "grad_norm": 0.6043870449066162,
      "learning_rate": 1.4376990388732162e-05,
      "loss": 6.6083,
      "step": 14650
    },
    {
      "epoch": 0.8645533141210374,
      "grad_norm": 0.6200549006462097,
      "learning_rate": 1.3781911030459208e-05,
      "loss": 6.5876,
      "step": 14700
    },
    {
      "epoch": 0.8674939716520614,
      "grad_norm": 0.5845454335212708,
      "learning_rate": 1.3198815548351933e-05,
      "loss": 6.6084,
      "step": 14750
    },
    {
      "epoch": 0.8704346291830853,
      "grad_norm": 0.6255987286567688,
      "learning_rate": 1.262775524061973e-05,
      "loss": 6.6371,
      "step": 14800
    },
    {
      "epoch": 0.8704346291830853,
      "eval_accuracy": 0.055588768827655004,
      "eval_loss": 6.573821067810059,
      "eval_runtime": 3.7799,
      "eval_samples_per_second": 37.832,
      "eval_steps_per_second": 2.381,
      "step": 14800
    },
    {
      "epoch": 0.8733752867141092,
      "grad_norm": 0.6388164758682251,
      "learning_rate": 1.2068780346669637e-05,
      "loss": 6.6231,
      "step": 14850
    },
    {
      "epoch": 0.8763159442451333,
      "grad_norm": 0.569858193397522,
      "learning_rate": 1.1521940042686361e-05,
      "loss": 6.6145,
      "step": 14900
    },
    {
      "epoch": 0.8792566017761572,
      "grad_norm": 0.5706650614738464,
      "learning_rate": 1.0987282437306061e-05,
      "loss": 6.6336,
      "step": 14950
    },
    {
      "epoch": 0.8821972593071811,
      "grad_norm": 0.6888250708580017,
      "learning_rate": 1.0464854567384062e-05,
      "loss": 6.5941,
      "step": 15000
    },
    {
      "epoch": 0.8821972593071811,
      "eval_accuracy": 0.05550336327082785,
      "eval_loss": 6.572869777679443,
      "eval_runtime": 3.7766,
      "eval_samples_per_second": 37.865,
      "eval_steps_per_second": 2.383,
      "step": 15000
    },
    {
      "epoch": 0.885137916838205,
      "grad_norm": 0.6462174654006958,
      "learning_rate": 9.95470239385654e-06,
      "loss": 6.6493,
      "step": 15050
    },
    {
      "epoch": 0.888078574369229,
      "grad_norm": 0.5259022116661072,
      "learning_rate": 9.456870797697246e-06,
      "loss": 6.5897,
      "step": 15100
    },
    {
      "epoch": 0.8910192319002529,
      "grad_norm": 0.5587084293365479,
      "learning_rate": 8.97140357596896e-06,
      "loss": 6.6011,
      "step": 15150
    },
    {
      "epoch": 0.8939598894312768,
      "grad_norm": 0.613127589225769,
      "learning_rate": 8.498343437970561e-06,
      "loss": 6.6257,
      "step": 15200
    },
    {
      "epoch": 0.8939598894312768,
      "eval_accuracy": 0.055414541491727615,
      "eval_loss": 6.572213172912598,
      "eval_runtime": 3.7692,
      "eval_samples_per_second": 37.939,
      "eval_steps_per_second": 2.388,
      "step": 15200
    },
    {
      "epoch": 0.8969005469623008,
      "grad_norm": 0.565463662147522,
      "learning_rate": 8.03773200147949e-06,
      "loss": 6.6345,
      "step": 15250
    },
    {
      "epoch": 0.8998412044933247,
      "grad_norm": 0.6562389135360718,
      "learning_rate": 7.589609789090478e-06,
      "loss": 6.5759,
      "step": 15300
    },
    {
      "epoch": 0.9027818620243486,
      "grad_norm": 0.577299177646637,
      "learning_rate": 7.154016224650544e-06,
      "loss": 6.5623,
      "step": 15350
    },
    {
      "epoch": 0.9057225195553725,
      "grad_norm": 0.5751253962516785,
      "learning_rate": 6.730989629790656e-06,
      "loss": 6.6233,
      "step": 15400
    },
    {
      "epoch": 0.9057225195553725,
      "eval_accuracy": 0.05566050949538981,
      "eval_loss": 6.571430683135986,
      "eval_runtime": 3.7685,
      "eval_samples_per_second": 37.946,
      "eval_steps_per_second": 2.388,
      "step": 15400
    },
    {
      "epoch": 0.9086631770863965,
      "grad_norm": 0.5452491044998169,
      "learning_rate": 6.320567220554329e-06,
      "loss": 6.6062,
      "step": 15450
    },
    {
      "epoch": 0.9116038346174204,
      "grad_norm": 0.7727105617523193,
      "learning_rate": 5.922785104123523e-06,
      "loss": 6.6188,
      "step": 15500
    },
    {
      "epoch": 0.9145444921484444,
      "grad_norm": 0.6365629434585571,
      "learning_rate": 5.537678275642171e-06,
      "loss": 6.6394,
      "step": 15550
    },
    {
      "epoch": 0.9174851496794684,
      "grad_norm": 0.5755324363708496,
      "learning_rate": 5.1652806151373235e-06,
      "loss": 6.6185,
      "step": 15600
    },
    {
      "epoch": 0.9174851496794684,
      "eval_accuracy": 0.05557852016083575,
      "eval_loss": 6.570916652679443,
      "eval_runtime": 3.7781,
      "eval_samples_per_second": 37.85,
      "eval_steps_per_second": 2.382,
      "step": 15600
    },
    {
      "epoch": 0.9204258072104923,
      "grad_norm": 0.5550854802131653,
      "learning_rate": 4.805624884538634e-06,
      "loss": 6.6214,
      "step": 15650
    },
    {
      "epoch": 0.9233664647415162,
      "grad_norm": 0.6059187650680542,
      "learning_rate": 4.458742724796061e-06,
      "loss": 6.604,
      "step": 15700
    },
    {
      "epoch": 0.9263071222725402,
      "grad_norm": 0.5476981997489929,
      "learning_rate": 4.124664653096299e-06,
      "loss": 6.6445,
      "step": 15750
    },
    {
      "epoch": 0.9292477798035641,
      "grad_norm": 0.5047135353088379,
      "learning_rate": 3.803420060177892e-06,
      "loss": 6.5971,
      "step": 15800
    },
    {
      "epoch": 0.9292477798035641,
      "eval_accuracy": 0.05557852016083575,
      "eval_loss": 6.570337295532227,
      "eval_runtime": 3.7792,
      "eval_samples_per_second": 37.839,
      "eval_steps_per_second": 2.381,
      "step": 15800
    },
    {
      "epoch": 0.932188437334588,
      "grad_norm": 0.5093027949333191,
      "learning_rate": 3.4950372077456325e-06,
      "loss": 6.5944,
      "step": 15850
    },
    {
      "epoch": 0.9351290948656119,
      "grad_norm": 0.6617786884307861,
      "learning_rate": 3.1995432259842523e-06,
      "loss": 6.6033,
      "step": 15900
    },
    {
      "epoch": 0.9380697523966359,
      "grad_norm": 0.615634024143219,
      "learning_rate": 2.916964111171566e-06,
      "loss": 6.5954,
      "step": 15950
    },
    {
      "epoch": 0.9410104099276598,
      "grad_norm": 0.6756373643875122,
      "learning_rate": 2.647324723391481e-06,
      "loss": 6.6104,
      "step": 16000
    },
    {
      "epoch": 0.9410104099276598,
      "eval_accuracy": 0.05557852016083575,
      "eval_loss": 6.570274353027344,
      "eval_runtime": 3.7718,
      "eval_samples_per_second": 37.913,
      "eval_steps_per_second": 2.386,
      "step": 16000
    },
    {
      "epoch": 0.9439510674586837,
      "grad_norm": 0.5450949668884277,
      "learning_rate": 2.3906487843468324e-06,
      "loss": 6.6408,
      "step": 16050
    },
    {
      "epoch": 0.9468917249897078,
      "grad_norm": 0.6508326530456543,
      "learning_rate": 2.146958875272586e-06,
      "loss": 6.6141,
      "step": 16100
    },
    {
      "epoch": 0.9498323825207317,
      "grad_norm": 0.6981250643730164,
      "learning_rate": 1.9162764349491098e-06,
      "loss": 6.6206,
      "step": 16150
    },
    {
      "epoch": 0.9527730400517556,
      "grad_norm": 0.5892021059989929,
      "learning_rate": 1.6986217578161154e-06,
      "loss": 6.6543,
      "step": 16200
    },
    {
      "epoch": 0.9527730400517556,
      "eval_accuracy": 0.055616098605839694,
      "eval_loss": 6.5700812339782715,
      "eval_runtime": 3.7686,
      "eval_samples_per_second": 37.945,
      "eval_steps_per_second": 2.388,
      "step": 16200
    },
    {
      "epoch": 0.9557136975827795,
      "grad_norm": 0.7165849804878235,
      "learning_rate": 1.4940139921873374e-06,
      "loss": 6.5867,
      "step": 16250
    },
    {
      "epoch": 0.9586543551138035,
      "grad_norm": 0.6046167612075806,
      "learning_rate": 1.3024711385658137e-06,
      "loss": 6.6003,
      "step": 16300
    },
    {
      "epoch": 0.9615950126448274,
      "grad_norm": 0.6078298091888428,
      "learning_rate": 1.1240100480603197e-06,
      "loss": 6.5954,
      "step": 16350
    },
    {
      "epoch": 0.9645356701758513,
      "grad_norm": 0.5760063529014587,
      "learning_rate": 9.586464209029533e-07,
      "loss": 6.5834,
      "step": 16400
    },
    {
      "epoch": 0.9645356701758513,
      "eval_accuracy": 0.05562976349493203,
      "eval_loss": 6.569756031036377,
      "eval_runtime": 3.7598,
      "eval_samples_per_second": 38.034,
      "eval_steps_per_second": 2.394,
      "step": 16400
    },
    {
      "epoch": 0.9674763277068753,
      "grad_norm": 0.6219493746757507,
      "learning_rate": 8.06394805067806e-07,
      "loss": 6.5922,
      "step": 16450
    },
    {
      "epoch": 0.9704169852378992,
      "grad_norm": 0.5728452801704407,
      "learning_rate": 6.672685949911383e-07,
      "loss": 6.5931,
      "step": 16500
    },
    {
      "epoch": 0.9733576427689231,
      "grad_norm": 0.6293670535087585,
      "learning_rate": 5.41280030392971e-07,
      "loss": 6.5941,
      "step": 16550
    },
    {
      "epoch": 0.976298300299947,
      "grad_norm": 0.6203575134277344,
      "learning_rate": 4.284401952003469e-07,
      "loss": 6.6161,
      "step": 16600
    },
    {
      "epoch": 0.976298300299947,
      "eval_accuracy": 0.05553752549355871,
      "eval_loss": 6.569704532623291,
      "eval_runtime": 3.7718,
      "eval_samples_per_second": 37.913,
      "eval_steps_per_second": 2.386,
      "step": 16600
    },
    {
      "epoch": 0.979238957830971,
      "grad_norm": 0.6079541444778442,
      "learning_rate": 3.287590165721443e-07,
      "loss": 6.6227,
      "step": 16650
    },
    {
      "epoch": 0.9821796153619949,
      "grad_norm": 0.8275851607322693,
      "learning_rate": 2.422452640257422e-07,
      "loss": 6.6335,
      "step": 16700
    },
    {
      "epoch": 0.9851202728930188,
      "grad_norm": 0.552193284034729,
      "learning_rate": 1.6890654866555386e-07,
      "loss": 6.6146,
      "step": 16750
    },
    {
      "epoch": 0.9880609304240429,
      "grad_norm": 0.8978299498558044,
      "learning_rate": 1.0874932251339619e-07,
      "loss": 6.5482,
      "step": 16800
    },
    {
      "epoch": 0.9880609304240429,
      "eval_accuracy": 0.05548969838173551,
      "eval_loss": 6.569736003875732,
      "eval_runtime": 3.7682,
      "eval_samples_per_second": 37.95,
      "eval_steps_per_second": 2.388,
      "step": 16800
    },
    {
      "epoch": 0.9910015879550668,
      "grad_norm": 0.6752353310585022,
      "learning_rate": 6.177887794091008e-08,
      "loss": 6.6108,
      "step": 16850
    },
    {
      "epoch": 0.9939422454860907,
      "grad_norm": 0.6836730241775513,
      "learning_rate": 2.7999347203899736e-08,
      "loss": 6.6261,
      "step": 16900
    },
    {
      "epoch": 0.9968829030171146,
      "grad_norm": 0.5775653719902039,
      "learning_rate": 7.4137020788567205e-09,
      "loss": 6.6064,
      "step": 16950
    },
    {
      "epoch": 0.9998235605481386,
      "grad_norm": 0.47212526202201843,
      "learning_rate": 2.3753601485765327e-11,
      "loss": 6.6005,
      "step": 17000
    },
    {
      "epoch": 0.9998235605481386,
      "eval_accuracy": 0.05551019571537402,
      "eval_loss": 6.569685459136963,
      "eval_runtime": 3.7678,
      "eval_samples_per_second": 37.954,
      "eval_steps_per_second": 2.389,
      "step": 17000
    },
    {
      "epoch": 1.0,
      "step": 17003,
      "total_flos": 2.947596824032051e+16,
      "train_loss": 0.0012855073224023771,
      "train_runtime": 6.5646,
      "train_samples_per_second": 10359.937,
      "train_steps_per_second": 2590.099
    }
  ],
  "logging_steps": 50,
  "max_steps": 17003,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.947596824032051e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
