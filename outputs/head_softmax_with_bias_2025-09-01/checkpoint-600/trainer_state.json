{
  "best_metric": 7.075796127319336,
  "best_model_checkpoint": "outputs/head_softmax_with_bias_2025-09-01/checkpoint-600",
  "epoch": 0.13233348037053375,
  "eval_steps": 200,
  "global_step": 600,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.011027790030877812,
      "grad_norm": 1.0007328987121582,
      "learning_rate": 0.00021739130434782607,
      "loss": 8.9873,
      "step": 50
    },
    {
      "epoch": 0.022055580061755623,
      "grad_norm": 487.9046325683594,
      "learning_rate": 0.0002999643200487839,
      "loss": 7.0653,
      "step": 100
    },
    {
      "epoch": 0.033083370092633436,
      "grad_norm": 6092.947265625,
      "learning_rate": 0.0002997564598523867,
      "loss": 7.0664,
      "step": 150
    },
    {
      "epoch": 0.044111160123511246,
      "grad_norm": 8381.12890625,
      "learning_rate": 0.0002993632731234018,
      "loss": 7.1088,
      "step": 200
    },
    {
      "epoch": 0.044111160123511246,
      "eval_accuracy": 0.0635553991684915,
      "eval_loss": 7.0970306396484375,
      "eval_runtime": 5.7843,
      "eval_samples_per_second": 24.722,
      "eval_steps_per_second": 1.556,
      "step": 200
    },
    {
      "epoch": 0.05513895015438906,
      "grad_norm": 19362.427734375,
      "learning_rate": 0.0002987852464380559,
      "loss": 7.0965,
      "step": 250
    },
    {
      "epoch": 0.06616674018526687,
      "grad_norm": 57384.49609375,
      "learning_rate": 0.0002980230951156177,
      "loss": 7.0984,
      "step": 300
    },
    {
      "epoch": 0.07719453021614468,
      "grad_norm": 27564.693359375,
      "learning_rate": 0.0002970777623331765,
      "loss": 7.0729,
      "step": 350
    },
    {
      "epoch": 0.08822232024702249,
      "grad_norm": 25329.400390625,
      "learning_rate": 0.0002959504179584418,
      "loss": 7.0807,
      "step": 400
    },
    {
      "epoch": 0.08822232024702249,
      "eval_accuracy": 0.06291656560342442,
      "eval_loss": 7.079625606536865,
      "eval_runtime": 5.0813,
      "eval_samples_per_second": 28.143,
      "eval_steps_per_second": 1.771,
      "step": 400
    },
    {
      "epoch": 0.0992501102779003,
      "grad_norm": 26975.65625,
      "learning_rate": 0.00029464245710201007,
      "loss": 7.0952,
      "step": 450
    },
    {
      "epoch": 0.11027790030877813,
      "grad_norm": 95654.890625,
      "learning_rate": 0.00029315549839088755,
      "loss": 7.07,
      "step": 500
    },
    {
      "epoch": 0.12130569033965594,
      "grad_norm": 104285.390625,
      "learning_rate": 0.00029149138196540815,
      "loss": 7.0908,
      "step": 550
    },
    {
      "epoch": 0.13233348037053375,
      "grad_norm": 44958.609375,
      "learning_rate": 0.00028965216720202387,
      "loss": 7.1002,
      "step": 600
    },
    {
      "epoch": 0.13233348037053375,
      "eval_accuracy": 0.06308737671707872,
      "eval_loss": 7.075796127319336,
      "eval_runtime": 5.067,
      "eval_samples_per_second": 28.222,
      "eval_steps_per_second": 1.776,
      "step": 600
    }
  ],
  "logging_steps": 50,
  "max_steps": 4534,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4132184260608000.0,
  "train_batch_size": 15,
  "trial_name": null,
  "trial_params": null
}
