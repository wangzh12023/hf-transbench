{
  "best_metric": 6.468602657318115,
  "best_model_checkpoint": "outputs/my_llama_tiny_sigmoid-eager-2025-08-21/checkpoint-4400",
  "epoch": 1.0,
  "eval_steps": 200,
  "global_step": 4534,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.011027790030877812,
      "grad_norm": 0.8513587117195129,
      "learning_rate": 0.00021739130434782607,
      "loss": 9.0519,
      "step": 50
    },
    {
      "epoch": 0.022055580061755623,
      "grad_norm": 0.3464672863483429,
      "learning_rate": 0.0002999643200487839,
      "loss": 7.1407,
      "step": 100
    },
    {
      "epoch": 0.033083370092633436,
      "grad_norm": 0.3007606863975525,
      "learning_rate": 0.0002997564598523867,
      "loss": 7.1097,
      "step": 150
    },
    {
      "epoch": 0.044111160123511246,
      "grad_norm": 0.31448134779930115,
      "learning_rate": 0.0002993632731234018,
      "loss": 7.0733,
      "step": 200
    },
    {
      "epoch": 0.044111160123511246,
      "eval_accuracy": 0.04620099002121474,
      "eval_loss": 7.022199630737305,
      "eval_runtime": 4.6529,
      "eval_samples_per_second": 30.734,
      "eval_steps_per_second": 1.934,
      "step": 200
    },
    {
      "epoch": 0.05513895015438906,
      "grad_norm": 0.319120854139328,
      "learning_rate": 0.0002987852464380559,
      "loss": 7.0412,
      "step": 250
    },
    {
      "epoch": 0.06616674018526687,
      "grad_norm": 0.33626630902290344,
      "learning_rate": 0.0002980230951156177,
      "loss": 7.0498,
      "step": 300
    },
    {
      "epoch": 0.07719453021614468,
      "grad_norm": 0.39289921522140503,
      "learning_rate": 0.0002970777623331765,
      "loss": 7.0387,
      "step": 350
    },
    {
      "epoch": 0.08822232024702249,
      "grad_norm": 0.30816155672073364,
      "learning_rate": 0.0002959504179584418,
      "loss": 7.009,
      "step": 400
    },
    {
      "epoch": 0.08822232024702249,
      "eval_accuracy": 0.048503523833274685,
      "eval_loss": 6.964056015014648,
      "eval_runtime": 4.3009,
      "eval_samples_per_second": 33.249,
      "eval_steps_per_second": 2.093,
      "step": 400
    },
    {
      "epoch": 0.0992501102779003,
      "grad_norm": 0.3163999617099762,
      "learning_rate": 0.00029464245710201007,
      "loss": 6.9946,
      "step": 450
    },
    {
      "epoch": 0.11027790030877813,
      "grad_norm": 0.33016467094421387,
      "learning_rate": 0.00029315549839088755,
      "loss": 6.9648,
      "step": 500
    },
    {
      "epoch": 0.12130569033965594,
      "grad_norm": 0.3269060254096985,
      "learning_rate": 0.00029149138196540815,
      "loss": 6.9794,
      "step": 550
    },
    {
      "epoch": 0.13233348037053375,
      "grad_norm": 0.31312501430511475,
      "learning_rate": 0.00028965216720202387,
      "loss": 6.9539,
      "step": 600
    },
    {
      "epoch": 0.13233348037053375,
      "eval_accuracy": 0.04971628274022021,
      "eval_loss": 6.913626194000244,
      "eval_runtime": 4.3054,
      "eval_samples_per_second": 33.214,
      "eval_steps_per_second": 2.09,
      "step": 600
    },
    {
      "epoch": 0.14336127040141156,
      "grad_norm": 0.44195976853370667,
      "learning_rate": 0.00028764013016478637,
      "loss": 6.9311,
      "step": 650
    },
    {
      "epoch": 0.15438906043228937,
      "grad_norm": 0.3082457184791565,
      "learning_rate": 0.00028545776078867357,
      "loss": 6.9541,
      "step": 700
    },
    {
      "epoch": 0.16541685046316718,
      "grad_norm": 0.3426285982131958,
      "learning_rate": 0.00028310775979824656,
      "loss": 6.93,
      "step": 750
    },
    {
      "epoch": 0.17644464049404499,
      "grad_norm": 0.40368619561195374,
      "learning_rate": 0.0002805930353654503,
      "loss": 6.9297,
      "step": 800
    },
    {
      "epoch": 0.17644464049404499,
      "eval_accuracy": 0.050365364972106544,
      "eval_loss": 6.868529319763184,
      "eval_runtime": 4.3084,
      "eval_samples_per_second": 33.191,
      "eval_steps_per_second": 2.089,
      "step": 800
    },
    {
      "epoch": 0.1874724305249228,
      "grad_norm": 0.29232674837112427,
      "learning_rate": 0.00027791669951069455,
      "loss": 6.903,
      "step": 850
    },
    {
      "epoch": 0.1985002205558006,
      "grad_norm": 0.33918625116348267,
      "learning_rate": 0.00027508206425166785,
      "loss": 6.8922,
      "step": 900
    },
    {
      "epoch": 0.20952801058667844,
      "grad_norm": 0.31950315833091736,
      "learning_rate": 0.0002720926375046512,
      "loss": 6.8962,
      "step": 950
    },
    {
      "epoch": 0.22055580061755625,
      "grad_norm": 0.3606322705745697,
      "learning_rate": 0.00026895211874340344,
      "loss": 6.8734,
      "step": 1000
    },
    {
      "epoch": 0.22055580061755625,
      "eval_accuracy": 0.05078556031169612,
      "eval_loss": 6.849676609039307,
      "eval_runtime": 4.3073,
      "eval_samples_per_second": 33.2,
      "eval_steps_per_second": 2.089,
      "step": 1000
    },
    {
      "epoch": 0.23158359064843406,
      "grad_norm": 0.3368569612503052,
      "learning_rate": 0.00026566439442099064,
      "loss": 6.8754,
      "step": 1050
    },
    {
      "epoch": 0.24261138067931187,
      "grad_norm": 0.3114999532699585,
      "learning_rate": 0.0002622335331602247,
      "loss": 6.8773,
      "step": 1100
    },
    {
      "epoch": 0.25363917071018965,
      "grad_norm": 0.34510141611099243,
      "learning_rate": 0.00025866378071866334,
      "loss": 6.8664,
      "step": 1150
    },
    {
      "epoch": 0.2646669607410675,
      "grad_norm": 0.3305264115333557,
      "learning_rate": 0.0002549595547344027,
      "loss": 6.8461,
      "step": 1200
    },
    {
      "epoch": 0.2646669607410675,
      "eval_accuracy": 0.050594251864403306,
      "eval_loss": 6.806196689605713,
      "eval_runtime": 4.3168,
      "eval_samples_per_second": 33.127,
      "eval_steps_per_second": 2.085,
      "step": 1200
    },
    {
      "epoch": 0.27569475077194533,
      "grad_norm": 0.3180464506149292,
      "learning_rate": 0.0002511254392591643,
      "loss": 6.8511,
      "step": 1250
    },
    {
      "epoch": 0.2867225408028231,
      "grad_norm": 0.3637934625148773,
      "learning_rate": 0.0002471661790854417,
      "loss": 6.8403,
      "step": 1300
    },
    {
      "epoch": 0.29775033083370095,
      "grad_norm": 0.3118212819099426,
      "learning_rate": 0.0002430866738747273,
      "loss": 6.8375,
      "step": 1350
    },
    {
      "epoch": 0.30877812086457873,
      "grad_norm": 0.3607952892780304,
      "learning_rate": 0.00023889197209408657,
      "loss": 6.7896,
      "step": 1400
    },
    {
      "epoch": 0.30877812086457873,
      "eval_accuracy": 0.0515952049904175,
      "eval_loss": 6.766511917114258,
      "eval_runtime": 4.3077,
      "eval_samples_per_second": 33.196,
      "eval_steps_per_second": 2.089,
      "step": 1400
    },
    {
      "epoch": 0.31980591089545657,
      "grad_norm": 0.36638617515563965,
      "learning_rate": 0.0002345872647685812,
      "loss": 6.8144,
      "step": 1450
    },
    {
      "epoch": 0.33083370092633435,
      "grad_norm": 0.4045431613922119,
      "learning_rate": 0.00023017787905727475,
      "loss": 6.7828,
      "step": 1500
    },
    {
      "epoch": 0.3418614909572122,
      "grad_norm": 0.5390697717666626,
      "learning_rate": 0.00022566927166076982,
      "loss": 6.7936,
      "step": 1550
    },
    {
      "epoch": 0.35288928098808997,
      "grad_norm": 0.3465181887149811,
      "learning_rate": 0.00022106702206843478,
      "loss": 6.7535,
      "step": 1600
    },
    {
      "epoch": 0.35288928098808997,
      "eval_accuracy": 0.05225795211139617,
      "eval_loss": 6.73048734664917,
      "eval_runtime": 4.3079,
      "eval_samples_per_second": 33.195,
      "eval_steps_per_second": 2.089,
      "step": 1600
    },
    {
      "epoch": 0.3639170710189678,
      "grad_norm": 0.43811744451522827,
      "learning_rate": 0.00021637682565367724,
      "loss": 6.7577,
      "step": 1650
    },
    {
      "epoch": 0.3749448610498456,
      "grad_norm": 0.33419525623321533,
      "learning_rate": 0.00021160448662580836,
      "loss": 6.7563,
      "step": 1700
    },
    {
      "epoch": 0.38597265108072343,
      "grad_norm": 0.49778667092323303,
      "learning_rate": 0.0002067559108472214,
      "loss": 6.7487,
      "step": 1750
    },
    {
      "epoch": 0.3970004411116012,
      "grad_norm": 0.4649738669395447,
      "learning_rate": 0.00020183709852477158,
      "loss": 6.7449,
      "step": 1800
    },
    {
      "epoch": 0.3970004411116012,
      "eval_accuracy": 0.05208714099774188,
      "eval_loss": 6.703537464141846,
      "eval_runtime": 4.3118,
      "eval_samples_per_second": 33.165,
      "eval_steps_per_second": 2.087,
      "step": 1800
    },
    {
      "epoch": 0.40802823114247905,
      "grad_norm": 0.4027666747570038,
      "learning_rate": 0.00019685413678440376,
      "loss": 6.7445,
      "step": 1850
    },
    {
      "epoch": 0.4190560211733569,
      "grad_norm": 0.46580931544303894,
      "learning_rate": 0.00019181319213821537,
      "loss": 6.7232,
      "step": 1900
    },
    {
      "epoch": 0.43008381120423467,
      "grad_norm": 0.46430718898773193,
      "learning_rate": 0.00018672050285327795,
      "loss": 6.7151,
      "step": 1950
    },
    {
      "epoch": 0.4411116012351125,
      "grad_norm": 0.4521784484386444,
      "learning_rate": 0.0001815823712316602,
      "loss": 6.7104,
      "step": 2000
    },
    {
      "epoch": 0.4411116012351125,
      "eval_accuracy": 0.053405802795153064,
      "eval_loss": 6.668132781982422,
      "eval_runtime": 4.3056,
      "eval_samples_per_second": 33.212,
      "eval_steps_per_second": 2.09,
      "step": 2000
    },
    {
      "epoch": 0.4521393912659903,
      "grad_norm": 0.4197689890861511,
      "learning_rate": 0.00017640515581120644,
      "loss": 6.7054,
      "step": 2050
    },
    {
      "epoch": 0.4631671812968681,
      "grad_norm": 0.5404365062713623,
      "learning_rate": 0.00017119526349672259,
      "loss": 6.7142,
      "step": 2100
    },
    {
      "epoch": 0.4741949713277459,
      "grad_norm": 0.7306869029998779,
      "learning_rate": 0.00016595914163130646,
      "loss": 6.6955,
      "step": 2150
    },
    {
      "epoch": 0.48522276135862374,
      "grad_norm": 0.6045269966125488,
      "learning_rate": 0.0001607032700176357,
      "loss": 6.6798,
      "step": 2200
    },
    {
      "epoch": 0.48522276135862374,
      "eval_accuracy": 0.054526323700725264,
      "eval_loss": 6.637426853179932,
      "eval_runtime": 4.3055,
      "eval_samples_per_second": 33.213,
      "eval_steps_per_second": 2.09,
      "step": 2200
    },
    {
      "epoch": 0.4962505513895015,
      "grad_norm": 0.6385287642478943,
      "learning_rate": 0.0001554341528990853,
      "loss": 6.6743,
      "step": 2250
    },
    {
      "epoch": 0.5072783414203793,
      "grad_norm": 0.5246338248252869,
      "learning_rate": 0.00015015831091060055,
      "loss": 6.6518,
      "step": 2300
    },
    {
      "epoch": 0.5183061314512571,
      "grad_norm": 0.69890958070755,
      "learning_rate": 0.000144882273009284,
      "loss": 6.6417,
      "step": 2350
    },
    {
      "epoch": 0.529333921482135,
      "grad_norm": 0.6994766592979431,
      "learning_rate": 0.00013961256839468416,
      "loss": 6.6436,
      "step": 2400
    },
    {
      "epoch": 0.529333921482135,
      "eval_accuracy": 0.05557852016083575,
      "eval_loss": 6.598006248474121,
      "eval_runtime": 4.3108,
      "eval_samples_per_second": 33.172,
      "eval_steps_per_second": 2.088,
      "step": 2400
    },
    {
      "epoch": 0.5403617115130128,
      "grad_norm": 0.7670834064483643,
      "learning_rate": 0.00013435571842878392,
      "loss": 6.6338,
      "step": 2450
    },
    {
      "epoch": 0.5513895015438907,
      "grad_norm": 0.6355029940605164,
      "learning_rate": 0.0001291182285656884,
      "loss": 6.6394,
      "step": 2500
    },
    {
      "epoch": 0.5624172915747684,
      "grad_norm": 0.775061845779419,
      "learning_rate": 0.00012390658030099895,
      "loss": 6.6346,
      "step": 2550
    },
    {
      "epoch": 0.5734450816056462,
      "grad_norm": 0.865074872970581,
      "learning_rate": 0.0001187272231508359,
      "loss": 6.5996,
      "step": 2600
    },
    {
      "epoch": 0.5734450816056462,
      "eval_accuracy": 0.05639841350637638,
      "eval_loss": 6.57561731338501,
      "eval_runtime": 4.3078,
      "eval_samples_per_second": 33.196,
      "eval_steps_per_second": 2.089,
      "step": 2600
    },
    {
      "epoch": 0.5844728716365241,
      "grad_norm": 0.9899889230728149,
      "learning_rate": 0.00011358656667043725,
      "loss": 6.6165,
      "step": 2650
    },
    {
      "epoch": 0.5955006616674019,
      "grad_norm": 1.227537989616394,
      "learning_rate": 0.0001084909725222094,
      "loss": 6.6247,
      "step": 2700
    },
    {
      "epoch": 0.6065284516982796,
      "grad_norm": 0.9616556167602539,
      "learning_rate": 0.00010344674660304565,
      "loss": 6.6,
      "step": 2750
    },
    {
      "epoch": 0.6175562417291575,
      "grad_norm": 1.3141530752182007,
      "learning_rate": 9.846013124065688e-05,
      "loss": 6.5893,
      "step": 2800
    },
    {
      "epoch": 0.6175562417291575,
      "eval_accuracy": 0.057057744405081975,
      "eval_loss": 6.5488409996032715,
      "eval_runtime": 4.2994,
      "eval_samples_per_second": 33.26,
      "eval_steps_per_second": 2.093,
      "step": 2800
    },
    {
      "epoch": 0.6285840317600353,
      "grad_norm": 1.2102229595184326,
      "learning_rate": 9.353729746856871e-05,
      "loss": 6.5784,
      "step": 2850
    },
    {
      "epoch": 0.6396118217909131,
      "grad_norm": 0.8062734603881836,
      "learning_rate": 8.868433738934824e-05,
      "loss": 6.5898,
      "step": 2900
    },
    {
      "epoch": 0.6506396118217909,
      "grad_norm": 1.1301463842391968,
      "learning_rate": 8.390725663550809e-05,
      "loss": 6.5665,
      "step": 2950
    },
    {
      "epoch": 0.6616674018526687,
      "grad_norm": 1.2459251880645752,
      "learning_rate": 7.921196693741947e-05,
      "loss": 6.5466,
      "step": 3000
    },
    {
      "epoch": 0.6616674018526687,
      "eval_accuracy": 0.05777856730470311,
      "eval_loss": 6.526881694793701,
      "eval_runtime": 4.3107,
      "eval_samples_per_second": 33.173,
      "eval_steps_per_second": 2.088,
      "step": 3000
    },
    {
      "epoch": 0.6726951918835465,
      "grad_norm": 1.4741783142089844,
      "learning_rate": 7.460427880743091e-05,
      "loss": 6.5786,
      "step": 3050
    },
    {
      "epoch": 0.6837229819144244,
      "grad_norm": 0.8463401794433594,
      "learning_rate": 7.008989434924615e-05,
      "loss": 6.5688,
      "step": 3100
    },
    {
      "epoch": 0.6947507719453022,
      "grad_norm": 1.113832712173462,
      "learning_rate": 6.567440020145965e-05,
      "loss": 6.5632,
      "step": 3150
    },
    {
      "epoch": 0.7057785619761799,
      "grad_norm": 1.401835322380066,
      "learning_rate": 6.136326062398313e-05,
      "loss": 6.5569,
      "step": 3200
    },
    {
      "epoch": 0.7057785619761799,
      "eval_accuracy": 0.05837982242476625,
      "eval_loss": 6.511488437652588,
      "eval_runtime": 4.3024,
      "eval_samples_per_second": 33.237,
      "eval_steps_per_second": 2.092,
      "step": 3200
    },
    {
      "epoch": 0.7168063520070578,
      "grad_norm": 1.110710859298706,
      "learning_rate": 5.7161810735917166e-05,
      "loss": 6.5341,
      "step": 3250
    },
    {
      "epoch": 0.7278341420379356,
      "grad_norm": 2.8372480869293213,
      "learning_rate": 5.307524991323758e-05,
      "loss": 6.5426,
      "step": 3300
    },
    {
      "epoch": 0.7388619320688135,
      "grad_norm": 1.818996787071228,
      "learning_rate": 4.9108635354466776e-05,
      "loss": 6.549,
      "step": 3350
    },
    {
      "epoch": 0.7498897220996912,
      "grad_norm": 0.9527994394302368,
      "learning_rate": 4.526687582229192e-05,
      "loss": 6.529,
      "step": 3400
    },
    {
      "epoch": 0.7498897220996912,
      "eval_accuracy": 0.058779520430717304,
      "eval_loss": 6.496919631958008,
      "eval_runtime": 4.3079,
      "eval_samples_per_second": 33.195,
      "eval_steps_per_second": 2.089,
      "step": 3400
    },
    {
      "epoch": 0.760917512130569,
      "grad_norm": 1.3063650131225586,
      "learning_rate": 4.155472556887574e-05,
      "loss": 6.5262,
      "step": 3450
    },
    {
      "epoch": 0.7719453021614469,
      "grad_norm": 1.4947333335876465,
      "learning_rate": 3.797677845237696e-05,
      "loss": 6.5167,
      "step": 3500
    },
    {
      "epoch": 0.7829730921923247,
      "grad_norm": 1.1663118600845337,
      "learning_rate": 3.453746225196131e-05,
      "loss": 6.5259,
      "step": 3550
    },
    {
      "epoch": 0.7940008822232024,
      "grad_norm": 1.0180985927581787,
      "learning_rate": 3.124103318833892e-05,
      "loss": 6.5428,
      "step": 3600
    },
    {
      "epoch": 0.7940008822232024,
      "eval_accuracy": 0.05887517465436371,
      "eval_loss": 6.486329555511475,
      "eval_runtime": 4.3234,
      "eval_samples_per_second": 33.076,
      "eval_steps_per_second": 2.082,
      "step": 3600
    },
    {
      "epoch": 0.8050286722540803,
      "grad_norm": 1.3093219995498657,
      "learning_rate": 2.809157065660834e-05,
      "loss": 6.5251,
      "step": 3650
    },
    {
      "epoch": 0.8160564622849581,
      "grad_norm": 1.1126399040222168,
      "learning_rate": 2.5092972177925425e-05,
      "loss": 6.5147,
      "step": 3700
    },
    {
      "epoch": 0.8270842523158359,
      "grad_norm": 0.8443101048469543,
      "learning_rate": 2.2248948576245517e-05,
      "loss": 6.5282,
      "step": 3750
    },
    {
      "epoch": 0.8381120423467138,
      "grad_norm": 1.271957278251648,
      "learning_rate": 1.95630193861063e-05,
      "loss": 6.5166,
      "step": 3800
    },
    {
      "epoch": 0.8381120423467138,
      "eval_accuracy": 0.059367110661688094,
      "eval_loss": 6.478497505187988,
      "eval_runtime": 4.3011,
      "eval_samples_per_second": 33.247,
      "eval_steps_per_second": 2.092,
      "step": 3800
    },
    {
      "epoch": 0.8491398323775915,
      "grad_norm": 1.3246791362762451,
      "learning_rate": 1.703850849713549e-05,
      "loss": 6.5106,
      "step": 3850
    },
    {
      "epoch": 0.8601676224084693,
      "grad_norm": 1.3414795398712158,
      "learning_rate": 1.4678540040672682e-05,
      "loss": 6.525,
      "step": 3900
    },
    {
      "epoch": 0.8711954124393472,
      "grad_norm": 1.537520170211792,
      "learning_rate": 1.2486034523596095e-05,
      "loss": 6.5085,
      "step": 3950
    },
    {
      "epoch": 0.882223202470225,
      "grad_norm": 0.8658350706100464,
      "learning_rate": 1.0463705214138369e-05,
      "loss": 6.5266,
      "step": 4000
    },
    {
      "epoch": 0.882223202470225,
      "eval_accuracy": 0.059332948438957235,
      "eval_loss": 6.472494125366211,
      "eval_runtime": 4.298,
      "eval_samples_per_second": 33.271,
      "eval_steps_per_second": 2.094,
      "step": 4000
    },
    {
      "epoch": 0.8932509925011027,
      "grad_norm": 1.5269098281860352,
      "learning_rate": 8.614054784164514e-06,
      "loss": 6.5232,
      "step": 4050
    },
    {
      "epoch": 0.9042787825319806,
      "grad_norm": 1.253065586090088,
      "learning_rate": 6.93937221206668e-06,
      "loss": 6.5032,
      "step": 4100
    },
    {
      "epoch": 0.9153065725628584,
      "grad_norm": 0.9762714505195618,
      "learning_rate": 5.4417299501088975e-06,
      "loss": 6.5304,
      "step": 4150
    },
    {
      "epoch": 0.9263343625937362,
      "grad_norm": 0.9003109931945801,
      "learning_rate": 4.122981359727024e-06,
      "loss": 6.5253,
      "step": 4200
    },
    {
      "epoch": 0.9263343625937362,
      "eval_accuracy": 0.059363694439415006,
      "eval_loss": 6.470187187194824,
      "eval_runtime": 4.293,
      "eval_samples_per_second": 33.31,
      "eval_steps_per_second": 2.096,
      "step": 4200
    },
    {
      "epoch": 0.937362152624614,
      "grad_norm": 1.3396832942962646,
      "learning_rate": 2.984758417958e-06,
      "loss": 6.505,
      "step": 4250
    },
    {
      "epoch": 0.9483899426554918,
      "grad_norm": 1.08112633228302,
      "learning_rate": 2.028469697836438e-06,
      "loss": 6.5262,
      "step": 4300
    },
    {
      "epoch": 0.9594177326863697,
      "grad_norm": 1.0041908025741577,
      "learning_rate": 1.2552986252581664e-06,
      "loss": 6.5098,
      "step": 4350
    },
    {
      "epoch": 0.9704455227172475,
      "grad_norm": 1.141650676727295,
      "learning_rate": 6.662020144675539e-07,
      "loss": 6.4967,
      "step": 4400
    },
    {
      "epoch": 0.9704455227172475,
      "eval_accuracy": 0.05942860266260364,
      "eval_loss": 6.468602657318115,
      "eval_runtime": 4.3054,
      "eval_samples_per_second": 33.214,
      "eval_steps_per_second": 2.09,
      "step": 4400
    },
    {
      "epoch": 0.9814733127481253,
      "grad_norm": 0.7848618626594543,
      "learning_rate": 2.6190888398138764e-07,
      "loss": 6.5209,
      "step": 4450
    },
    {
      "epoch": 0.992501102779003,
      "grad_norm": 1.220009684562683,
      "learning_rate": 4.291955441418915e-08,
      "loss": 6.5006,
      "step": 4500
    },
    {
      "epoch": 1.0,
      "step": 4534,
      "total_flos": 2.9479868496347136e+16,
      "train_loss": 6.731673945295269,
      "train_runtime": 3402.1029,
      "train_samples_per_second": 19.99,
      "train_steps_per_second": 1.333
    }
  ],
  "logging_steps": 50,
  "max_steps": 4534,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.9479868496347136e+16,
  "train_batch_size": 15,
  "trial_name": null,
  "trial_params": null
}
